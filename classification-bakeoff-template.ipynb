{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Classification Modeling\n",
    "The goal of this week's assessment is to find the model which best predicts whether or not a person will default on their bank loan. In doing so, we want to utilize all of the different tools we have learned over the course: data cleaning, EDA, feature engineering/transformation, feature selection, hyperparameter tuning, and model evaluation. \n",
    "\n",
    "\n",
    "#### Data Set Information:\n",
    "\n",
    "This research aimed at the case of customers default payments in Taiwan and compares the predictive accuracy of probability of default among six data mining methods. From the perspective of risk management, the result of predictive accuracy of the estimated probability of default will be more valuable than the binary result of classification - credible or not credible clients. Because the real probability of default is unknown, this study presented the novel Sorting Smoothing Method to estimate the real probability of default. With the real probability of default as the response variable (Y), and the predictive probability of default as the independent variable (X), the simple linear regression result (Y = A + BX) shows that the forecasting model produced by artificial neural network has the highest coefficient of determination; its regression intercept (A) is close to zero, and regression coefficient (B) to one. Therefore, among the six data mining techniques, artificial neural network is the only one that can accurately estimate the real probability of default. \n",
    "\n",
    "- NT is the abbreviation for New Taiwain. \n",
    "\n",
    "\n",
    "#### Attribute Information:\n",
    "\n",
    "This research employed a binary variable, default payment (Yes = 1, No = 0), as the response variable. This study reviewed the literature and used the following 23 variables as explanatory variables: \n",
    "- X1: Amount of the given credit (NT dollar): it includes both the individual consumer credit and his/her family (supplementary) credit. \n",
    "- X2: Gender (1 = male; 2 = female). \n",
    "- X3: Education (1 = graduate school; 2 = university; 3 = high school; 4 = others). \n",
    "- X4: Marital status (1 = married; 2 = single; 3 = others). \n",
    "- X5: Age (year). \n",
    "- X6 - X11: History of past payment. We tracked the past monthly payment records (from April to September, 2005) as follows: \n",
    "    - X6 = the repayment status in September, 2005; \n",
    "    - X7 = the repayment status in August, 2005; . . .;\n",
    "    - etc...\n",
    "    - X11 = the repayment status in April, 2005. \n",
    "    - The measurement scale for the repayment status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above. \n",
    "- X12-X17: Amount of bill statement (NT dollar). \n",
    "    - X12 = amount of bill statement in September, 2005;\n",
    "    - etc...\n",
    "    - X13 = amount of bill statement in August, 2005; . . .; \n",
    "    - X17 = amount of bill statement in April, 2005. \n",
    "- X18-X23: Amount of previous payment (NT dollar). \n",
    "    - X18 = amount paid in September, 2005; \n",
    "    - X19 = amount paid in August, 2005; . . .;\n",
    "    - etc...\n",
    "    - X23 = amount paid in April, 2005. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "You will fit three different models (KNN, Logistic Regression, and Decision Tree Classifier) to predict credit card defaults and use gridsearch to find the best hyperparameters for those models. Then you will compare the performance of those three models on a test set to find the best one.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process/Expectations\n",
    "\n",
    "- You will be working in pairs for this assessment\n",
    "\n",
    "### Please have ONE notebook and be prepared to explain how you worked in your pair.\n",
    "\n",
    "1. Clean up your data set so that you can perform an EDA. \n",
    "    - This includes handling null values, categorical variables, removing unimportant columns, and removing outliers.\n",
    "2. Perform EDA to identify opportunities to create new features.\n",
    "    - [Great Example of EDA for classification](https://www.kaggle.com/stephaniestallworth/titanic-eda-classification-end-to-end) \n",
    "    - [Using Pairplots with Classification](https://towardsdatascience.com/visualizing-data-with-pair-plots-in-python-f228cf529166)\n",
    "3. Engineer new features. \n",
    "    - Create polynomial and/or interaction features. \n",
    "    - Additionaly, you must also create **at least 2 new features** that are not interactions or polynomial transformations. \n",
    "        - *For example, you can create a new dummy variable that based on the value of a continuous variable (billamount6 >2000) or take the average of some past amounts.*\n",
    "4. Perform some feature selection. \n",
    "    \n",
    "5. You must fit **three** models to your data and tune **at least 1 hyperparameter** per model. \n",
    "6. Using the F-1 Score, evaluate how well your models perform and identify your best model.\n",
    "7. Using information from your EDA process and your model(s) output provide insight as to which borrowers are more likely to deafult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.rcParams.update({'font.size': 12})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('training_data.csv' , index_col=0)\n",
    "hold = pd.read_csv('holdout_data.csv' , index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             17471\n",
       "1                              5028\n",
       "default payment next month        1\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data to be used in the models\n",
    "# Create matrix of features\n",
    "X = df.drop('Y', axis = 1) # grabs everything else but 'Survived'\n",
    "\n",
    "\n",
    "# Create target variable\n",
    "y = df['Y'] # y is the column we're trying to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2            10516\n",
       "1             7919\n",
       "3             3713\n",
       "5              208\n",
       "4               90\n",
       "6               42\n",
       "0               11\n",
       "EDUCATION        1\n",
       "Name: X3, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['X3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X1': 'LIMIT_BAL',\n",
       " 'X2': 'SEX',\n",
       " 'X3': 'EDUCATION',\n",
       " 'X4': 'MARRIAGE',\n",
       " 'X5': 'AGE',\n",
       " 'X6': 'PAY_0',\n",
       " 'X7': 'PAY_2',\n",
       " 'X8': 'PAY_3',\n",
       " 'X9': 'PAY_4',\n",
       " 'X10': 'PAY_5',\n",
       " 'X11': 'PAY_6',\n",
       " 'X12': 'BILL_AMT1',\n",
       " 'X13': 'BILL_AMT2',\n",
       " 'X14': 'BILL_AMT3',\n",
       " 'X15': 'BILL_AMT4',\n",
       " 'X16': 'BILL_AMT5',\n",
       " 'X17': 'BILL_AMT6',\n",
       " 'X18': 'PAY_AMT1',\n",
       " 'X19': 'PAY_AMT2',\n",
       " 'X20': 'PAY_AMT3',\n",
       " 'X21': 'PAY_AMT4',\n",
       " 'X22': 'PAY_AMT5',\n",
       " 'X23': 'PAY_AMT6',\n",
       " 'Y': 'default payment next month'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Putting names of columns in from the row in dictionary to change later\n",
    "names = dict(df.loc['ID'])\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "df = df.rename(columns = names)\n",
    "df = df.rename(columns = {'PAY_0': 'PAY_1'})\n",
    "df = df.rename(columns = {'default payment next month': 'default'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.names = [\"ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28835</th>\n",
       "      <td>220000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>222598</td>\n",
       "      <td>222168</td>\n",
       "      <td>217900</td>\n",
       "      <td>221193</td>\n",
       "      <td>181859</td>\n",
       "      <td>184605</td>\n",
       "      <td>10000</td>\n",
       "      <td>8018</td>\n",
       "      <td>10121</td>\n",
       "      <td>6006</td>\n",
       "      <td>10987</td>\n",
       "      <td>143779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25329</th>\n",
       "      <td>200000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18894</th>\n",
       "      <td>180000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>80000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51372</td>\n",
       "      <td>51872</td>\n",
       "      <td>47593</td>\n",
       "      <td>43882</td>\n",
       "      <td>42256</td>\n",
       "      <td>42527</td>\n",
       "      <td>1853</td>\n",
       "      <td>1700</td>\n",
       "      <td>1522</td>\n",
       "      <td>1548</td>\n",
       "      <td>1488</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239</th>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8257</td>\n",
       "      <td>7995</td>\n",
       "      <td>4878</td>\n",
       "      <td>5444</td>\n",
       "      <td>2639</td>\n",
       "      <td>2697</td>\n",
       "      <td>2000</td>\n",
       "      <td>1100</td>\n",
       "      <td>600</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      LIMIT_BAL SEX EDUCATION MARRIAGE AGE PAY_1 PAY_2 PAY_3 PAY_4 PAY_5  \\\n",
       "ID                                                                         \n",
       "28835    220000   2         1        2  36     0     0     0     0     0   \n",
       "25329    200000   2         3        2  29    -1    -1    -1    -1    -1   \n",
       "18894    180000   2         1        2  27    -2    -2    -2    -2    -2   \n",
       "690       80000   1         2        2  32     0     0     0     0     0   \n",
       "6239      10000   1         2        2  27     0     0     0     0     0   \n",
       "\n",
       "      PAY_6 BILL_AMT1 BILL_AMT2 BILL_AMT3 BILL_AMT4 BILL_AMT5 BILL_AMT6  \\\n",
       "ID                                                                        \n",
       "28835     0    222598    222168    217900    221193    181859    184605   \n",
       "25329    -1       326       326       326       326       326       326   \n",
       "18894    -2         0         0         0         0         0         0   \n",
       "690       0     51372     51872     47593     43882     42256     42527   \n",
       "6239      0      8257      7995      4878      5444      2639      2697   \n",
       "\n",
       "      PAY_AMT1 PAY_AMT2 PAY_AMT3 PAY_AMT4 PAY_AMT5 PAY_AMT6 default  \n",
       "ID                                                                   \n",
       "28835    10000     8018    10121     6006    10987   143779       1  \n",
       "25329      326      326      326      326      326      326       0  \n",
       "18894        0        0        0        0        0        0       0  \n",
       "690       1853     1700     1522     1548     1488     1500       0  \n",
       "6239      2000     1100      600      300      300     1000       1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22500, 24)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing row with columns names to convert to number \n",
    "df = df.drop('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting datatype of whole dataset to int \n",
    "df = df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22499, 24)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>3913</td>\n",
       "      <td>3102</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13007</td>\n",
       "      <td>13912</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13007</td>\n",
       "      <td>1122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>17973</td>\n",
       "      <td>19367</td>\n",
       "      <td>19559</td>\n",
       "      <td>18240</td>\n",
       "      <td>17928</td>\n",
       "      <td>150</td>\n",
       "      <td>1699</td>\n",
       "      <td>1460</td>\n",
       "      <td>626</td>\n",
       "      <td>1750</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>120000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113348</td>\n",
       "      <td>110119</td>\n",
       "      <td>111700</td>\n",
       "      <td>83858</td>\n",
       "      <td>86434</td>\n",
       "      <td>88802</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>3158</td>\n",
       "      <td>3934</td>\n",
       "      <td>3802</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>260000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  \\\n",
       "ID                                                                            \n",
       "1          20000    2          2         1   24      2      2     -1     -1   \n",
       "10         20000    1          3         2   35     -2     -2     -2     -2   \n",
       "100        20000    1          2         1   38      0      0      0      0   \n",
       "1000      120000    1          2         2   25      2      2      0      0   \n",
       "10001     260000    2          1         1   40     -2     -2     -2     -2   \n",
       "\n",
       "       PAY_5  PAY_6  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  BILL_AMT5  \\\n",
       "ID                                                                           \n",
       "1         -2     -2       3913       3102        689          0          0   \n",
       "10        -1     -1          0          0          0          0      13007   \n",
       "100        0     -1      17973      19367      19559      18240      17928   \n",
       "1000       0      0     113348     110119     111700      83858      86434   \n",
       "10001     -2     -2       2500          0          0          0          0   \n",
       "\n",
       "       BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "ID                                                                             \n",
       "1              0         0       689         0         0         0         0   \n",
       "10         13912         0         0         0     13007      1122         0   \n",
       "100          150      1699      1460       626      1750       150         0   \n",
       "1000       88802         0      5000      3158      3934      3802      2000   \n",
       "10001          0         0         0         0         0         0         0   \n",
       "\n",
       "       default  \n",
       "ID              \n",
       "1            1  \n",
       "10           0  \n",
       "100          1  \n",
       "1000         0  \n",
       "10001        0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    10516\n",
       "1     7919\n",
       "3     3713\n",
       "5      208\n",
       "4       90\n",
       "6       42\n",
       "0       11\n",
       "Name: EDUCATION, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.EDUCATION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['EDUCATION'] = df['EDUCATION'].replace(0,4)\n",
    "df['EDUCATION'] = df['EDUCATION'].replace(5,4)\n",
    "df['EDUCATION'] = df['EDUCATION'].replace(6,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    10516\n",
       "1     7919\n",
       "3     3713\n",
       "4      351\n",
       "Name: EDUCATION, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.EDUCATION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MARRIAGE'] = df['MARRIAGE'].replace(0,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    12026\n",
       "1    10195\n",
       "3      278\n",
       "Name: MARRIAGE, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MARRIAGE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PAY_1'] = df['PAY_1'].replace(-2,-1)\n",
    "df['PAY_2'] = df['PAY_2'].replace(-2,-1)\n",
    "df['PAY_3'] = df['PAY_3'].replace(-2,-1)\n",
    "df['PAY_4'] = df['PAY_4'].replace(-2,-1)\n",
    "df['PAY_5'] = df['PAY_5'].replace(-2,-1)\n",
    "df['PAY_6'] = df['PAY_6'].replace(-2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Variable\n",
      "0    17471\n",
      "1     5028\n",
      "Name: default, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Target Variable')\n",
    "print(df['default'].value_counts())\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize = (10,5))\n",
    "sns.countplot(df['default'])\n",
    "plt.title('Default vs Non-Default')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Default')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default          0          1\n",
      "SEX                          \n",
      "1        38.681243  43.138425\n",
      "2        61.318757  56.861575\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = df.groupby(['SEX', 'default'])['SEX'].count().unstack()\n",
    "print((d/d.sum())*100)\n",
    "((d/d.sum())*100).transpose().plot(kind = 'bar', stacked = True, figsize = (10,7))\n",
    "plt.xlabel('Default')\n",
    "plt.ylabel('Percentage of Sex')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default           0          1\n",
      "MARRIAGE                      \n",
      "1         44.473699  48.229912\n",
      "2         54.232729  50.735879\n",
      "3          1.293572   1.034208\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = df.groupby(['MARRIAGE', 'default'])['MARRIAGE'].count().unstack()\n",
    "print((f/f.sum())*100)\n",
    "((f/f.sum())*100).transpose().plot(kind = 'bar', stacked = True, figsize = (10,7))\n",
    "plt.xlabel('Default')\n",
    "plt.ylabel('Percentage of Marriage Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default            0          1\n",
      "EDUCATION                      \n",
      "1          36.563448  30.449483\n",
      "2          45.778719  50.079554\n",
      "3          15.820503  18.874304\n",
      "4           1.837330   0.596659\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "e = df.groupby(['EDUCATION', 'default'])['EDUCATION'].count().unstack()\n",
    "print((e/e.sum())*100)\n",
    "((e/e.sum())*100).transpose().plot(kind = 'bar', stacked = True, figsize = (10,7))\n",
    "plt.xlabel('Default')\n",
    "plt.ylabel('Percentage of Education Status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>1000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>964511</td>\n",
       "      <td>983931</td>\n",
       "      <td>535020</td>\n",
       "      <td>891586</td>\n",
       "      <td>927171</td>\n",
       "      <td>961664</td>\n",
       "      <td>50784</td>\n",
       "      <td>50723</td>\n",
       "      <td>896040</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  \\\n",
       "ID                                                                           \n",
       "2198    1000000    2          1         1   47      0      0      0     -1   \n",
       "\n",
       "      PAY_5  PAY_6  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  BILL_AMT5  \\\n",
       "ID                                                                          \n",
       "2198      0      0     964511     983931     535020     891586     927171   \n",
       "\n",
       "      BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "ID                                                                            \n",
       "2198     961664     50784     50723    896040     50000     50000     50256   \n",
       "\n",
       "      default  \n",
       "ID             \n",
       "2198        0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.LIMIT_BAL > 800000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3913</td>\n",
       "      <td>3102</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13007</td>\n",
       "      <td>13912</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13007</td>\n",
       "      <td>1122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>17973</td>\n",
       "      <td>19367</td>\n",
       "      <td>19559</td>\n",
       "      <td>18240</td>\n",
       "      <td>17928</td>\n",
       "      <td>150</td>\n",
       "      <td>1699</td>\n",
       "      <td>1460</td>\n",
       "      <td>626</td>\n",
       "      <td>1750</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>120000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113348</td>\n",
       "      <td>110119</td>\n",
       "      <td>111700</td>\n",
       "      <td>83858</td>\n",
       "      <td>86434</td>\n",
       "      <td>88802</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>3158</td>\n",
       "      <td>3934</td>\n",
       "      <td>3802</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>260000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  \\\n",
       "ID                                                                            \n",
       "1          20000    2          2         1   24      2      2     -1     -1   \n",
       "10         20000    1          3         2   35     -1     -1     -1     -1   \n",
       "100        20000    1          2         1   38      0      0      0      0   \n",
       "1000      120000    1          2         2   25      2      2      0      0   \n",
       "10001     260000    2          1         1   40     -1     -1     -1     -1   \n",
       "\n",
       "       PAY_5  PAY_6  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  BILL_AMT5  \\\n",
       "ID                                                                           \n",
       "1         -1     -1       3913       3102        689          0          0   \n",
       "10        -1     -1          0          0          0          0      13007   \n",
       "100        0     -1      17973      19367      19559      18240      17928   \n",
       "1000       0      0     113348     110119     111700      83858      86434   \n",
       "10001     -1     -1       2500          0          0          0          0   \n",
       "\n",
       "       BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "ID                                                                             \n",
       "1              0         0       689         0         0         0         0   \n",
       "10         13912         0         0         0     13007      1122         0   \n",
       "100          150      1699      1460       626      1750       150         0   \n",
       "1000       88802         0      5000      3158      3934      3802      2000   \n",
       "10001          0         0         0         0         0         0         0   \n",
       "\n",
       "       default  \n",
       "ID              \n",
       "1            1  \n",
       "10           0  \n",
       "100          1  \n",
       "1000         0  \n",
       "10001        0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_bill'] = round((df['BILL_AMT1'] + df['BILL_AMT2'] + df['BILL_AMT3'] + df['BILL_AMT4'] + df['BILL_AMT5'] + df['BILL_AMT6'])/6,2 )\n",
    "df['avg_pay'] = round((df['PAY_AMT1'] + df['PAY_AMT2'] + df['PAY_AMT3'] + df['PAY_AMT4'] + df['PAY_AMT5'] + df['PAY_AMT6'])/6,2 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bill = ['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']\n",
    "paid = ['PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "new_cols = ['out1', 'out2', 'out3', 'out4', 'out5', 'out6']\n",
    "for i in range(len(bill)):\n",
    "    df[new_cols[i]] = round(df[bill[i]] - df[paid[i]],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Percentage used for every month\n",
    "cols = ['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']\n",
    "new_cols = ['per1', 'per2', 'per3', 'per4', 'per5', 'per6']\n",
    "for i in range(len(cols)):\n",
    "    df[new_cols[i]] = round(df[cols[i]]/df['LIMIT_BAL']*100,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default</th>\n",
       "      <th>avg_bill</th>\n",
       "      <th>avg_pay</th>\n",
       "      <th>out1</th>\n",
       "      <th>out2</th>\n",
       "      <th>out3</th>\n",
       "      <th>out4</th>\n",
       "      <th>out5</th>\n",
       "      <th>out6</th>\n",
       "      <th>per1</th>\n",
       "      <th>per2</th>\n",
       "      <th>per3</th>\n",
       "      <th>per4</th>\n",
       "      <th>per5</th>\n",
       "      <th>per6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3913</td>\n",
       "      <td>3102</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1284.00</td>\n",
       "      <td>114.83</td>\n",
       "      <td>3913</td>\n",
       "      <td>2413</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.56</td>\n",
       "      <td>15.51</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13007</td>\n",
       "      <td>13912</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13007</td>\n",
       "      <td>1122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4486.50</td>\n",
       "      <td>2354.83</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-13007</td>\n",
       "      <td>11885</td>\n",
       "      <td>13912</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>65.04</td>\n",
       "      <td>69.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>17973</td>\n",
       "      <td>19367</td>\n",
       "      <td>19559</td>\n",
       "      <td>18240</td>\n",
       "      <td>17928</td>\n",
       "      <td>150</td>\n",
       "      <td>1699</td>\n",
       "      <td>1460</td>\n",
       "      <td>626</td>\n",
       "      <td>1750</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15536.17</td>\n",
       "      <td>947.50</td>\n",
       "      <td>16274</td>\n",
       "      <td>17907</td>\n",
       "      <td>18933</td>\n",
       "      <td>16490</td>\n",
       "      <td>17778</td>\n",
       "      <td>150</td>\n",
       "      <td>89.86</td>\n",
       "      <td>96.84</td>\n",
       "      <td>97.80</td>\n",
       "      <td>91.20</td>\n",
       "      <td>89.64</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>120000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113348</td>\n",
       "      <td>110119</td>\n",
       "      <td>111700</td>\n",
       "      <td>83858</td>\n",
       "      <td>86434</td>\n",
       "      <td>88802</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>3158</td>\n",
       "      <td>3934</td>\n",
       "      <td>3802</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>99043.50</td>\n",
       "      <td>2982.33</td>\n",
       "      <td>113348</td>\n",
       "      <td>105119</td>\n",
       "      <td>108542</td>\n",
       "      <td>79924</td>\n",
       "      <td>82632</td>\n",
       "      <td>86802</td>\n",
       "      <td>94.46</td>\n",
       "      <td>91.77</td>\n",
       "      <td>93.08</td>\n",
       "      <td>69.88</td>\n",
       "      <td>72.03</td>\n",
       "      <td>74.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>260000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>416.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  \\\n",
       "ID                                                                            \n",
       "1          20000    2          2         1   24      2      2     -1     -1   \n",
       "10         20000    1          3         2   35     -1     -1     -1     -1   \n",
       "100        20000    1          2         1   38      0      0      0      0   \n",
       "1000      120000    1          2         2   25      2      2      0      0   \n",
       "10001     260000    2          1         1   40     -1     -1     -1     -1   \n",
       "\n",
       "       PAY_5  PAY_6  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  BILL_AMT5  \\\n",
       "ID                                                                           \n",
       "1         -1     -1       3913       3102        689          0          0   \n",
       "10        -1     -1          0          0          0          0      13007   \n",
       "100        0     -1      17973      19367      19559      18240      17928   \n",
       "1000       0      0     113348     110119     111700      83858      86434   \n",
       "10001     -1     -1       2500          0          0          0          0   \n",
       "\n",
       "       BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "ID                                                                             \n",
       "1              0         0       689         0         0         0         0   \n",
       "10         13912         0         0         0     13007      1122         0   \n",
       "100          150      1699      1460       626      1750       150         0   \n",
       "1000       88802         0      5000      3158      3934      3802      2000   \n",
       "10001          0         0         0         0         0         0         0   \n",
       "\n",
       "       default  avg_bill  avg_pay    out1    out2    out3   out4   out5  \\\n",
       "ID                                                                        \n",
       "1            1   1284.00   114.83    3913    2413     689      0      0   \n",
       "10           0   4486.50  2354.83       0       0       0 -13007  11885   \n",
       "100          1  15536.17   947.50   16274   17907   18933  16490  17778   \n",
       "1000         0  99043.50  2982.33  113348  105119  108542  79924  82632   \n",
       "10001        0    416.67     0.00    2500       0       0      0      0   \n",
       "\n",
       "        out6   per1   per2   per3   per4   per5   per6  \n",
       "ID                                                      \n",
       "1          0  19.56  15.51   3.44   0.00   0.00   0.00  \n",
       "10     13912   0.00   0.00   0.00   0.00  65.04  69.56  \n",
       "100      150  89.86  96.84  97.80  91.20  89.64   0.75  \n",
       "1000   86802  94.46  91.77  93.08  69.88  72.03  74.00  \n",
       "10001      0   0.96   0.00   0.00   0.00   0.00   0.00  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbc9039be10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.boxplot(['LIMIT_BAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = ['LIMIT_BAL', 'AGE', 'BILL_AMT1', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',\n",
    "       'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'per1', 'per2', 'per3', 'per4', 'per5', 'per6']\n",
    "poly_df = df[cont]\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly_data = poly.fit_transform(poly_df)\n",
    "poly_columns = poly.get_feature_names(poly_df.columns)\n",
    "df_poly = pd.DataFrame(poly_data, columns=poly_columns, index = df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>AGE</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>per1</th>\n",
       "      <th>per2</th>\n",
       "      <th>per3</th>\n",
       "      <th>per4</th>\n",
       "      <th>per5</th>\n",
       "      <th>per6</th>\n",
       "      <th>LIMIT_BAL^2</th>\n",
       "      <th>LIMIT_BAL AGE</th>\n",
       "      <th>LIMIT_BAL BILL_AMT1</th>\n",
       "      <th>LIMIT_BAL PAY_AMT1</th>\n",
       "      <th>LIMIT_BAL PAY_AMT2</th>\n",
       "      <th>LIMIT_BAL PAY_AMT3</th>\n",
       "      <th>LIMIT_BAL PAY_AMT4</th>\n",
       "      <th>LIMIT_BAL PAY_AMT5</th>\n",
       "      <th>LIMIT_BAL PAY_AMT6</th>\n",
       "      <th>LIMIT_BAL per1</th>\n",
       "      <th>LIMIT_BAL per2</th>\n",
       "      <th>LIMIT_BAL per3</th>\n",
       "      <th>LIMIT_BAL per4</th>\n",
       "      <th>LIMIT_BAL per5</th>\n",
       "      <th>LIMIT_BAL per6</th>\n",
       "      <th>AGE^2</th>\n",
       "      <th>AGE BILL_AMT1</th>\n",
       "      <th>AGE PAY_AMT1</th>\n",
       "      <th>AGE PAY_AMT2</th>\n",
       "      <th>AGE PAY_AMT3</th>\n",
       "      <th>AGE PAY_AMT4</th>\n",
       "      <th>AGE PAY_AMT5</th>\n",
       "      <th>AGE PAY_AMT6</th>\n",
       "      <th>AGE per1</th>\n",
       "      <th>AGE per2</th>\n",
       "      <th>AGE per3</th>\n",
       "      <th>AGE per4</th>\n",
       "      <th>AGE per5</th>\n",
       "      <th>AGE per6</th>\n",
       "      <th>BILL_AMT1^2</th>\n",
       "      <th>BILL_AMT1 PAY_AMT1</th>\n",
       "      <th>BILL_AMT1 PAY_AMT2</th>\n",
       "      <th>BILL_AMT1 PAY_AMT3</th>\n",
       "      <th>BILL_AMT1 PAY_AMT4</th>\n",
       "      <th>BILL_AMT1 PAY_AMT5</th>\n",
       "      <th>BILL_AMT1 PAY_AMT6</th>\n",
       "      <th>BILL_AMT1 per1</th>\n",
       "      <th>BILL_AMT1 per2</th>\n",
       "      <th>BILL_AMT1 per3</th>\n",
       "      <th>BILL_AMT1 per4</th>\n",
       "      <th>BILL_AMT1 per5</th>\n",
       "      <th>BILL_AMT1 per6</th>\n",
       "      <th>PAY_AMT1^2</th>\n",
       "      <th>PAY_AMT1 PAY_AMT2</th>\n",
       "      <th>PAY_AMT1 PAY_AMT3</th>\n",
       "      <th>PAY_AMT1 PAY_AMT4</th>\n",
       "      <th>PAY_AMT1 PAY_AMT5</th>\n",
       "      <th>PAY_AMT1 PAY_AMT6</th>\n",
       "      <th>PAY_AMT1 per1</th>\n",
       "      <th>PAY_AMT1 per2</th>\n",
       "      <th>PAY_AMT1 per3</th>\n",
       "      <th>PAY_AMT1 per4</th>\n",
       "      <th>PAY_AMT1 per5</th>\n",
       "      <th>PAY_AMT1 per6</th>\n",
       "      <th>PAY_AMT2^2</th>\n",
       "      <th>PAY_AMT2 PAY_AMT3</th>\n",
       "      <th>PAY_AMT2 PAY_AMT4</th>\n",
       "      <th>PAY_AMT2 PAY_AMT5</th>\n",
       "      <th>PAY_AMT2 PAY_AMT6</th>\n",
       "      <th>PAY_AMT2 per1</th>\n",
       "      <th>PAY_AMT2 per2</th>\n",
       "      <th>PAY_AMT2 per3</th>\n",
       "      <th>PAY_AMT2 per4</th>\n",
       "      <th>PAY_AMT2 per5</th>\n",
       "      <th>PAY_AMT2 per6</th>\n",
       "      <th>PAY_AMT3^2</th>\n",
       "      <th>PAY_AMT3 PAY_AMT4</th>\n",
       "      <th>PAY_AMT3 PAY_AMT5</th>\n",
       "      <th>PAY_AMT3 PAY_AMT6</th>\n",
       "      <th>PAY_AMT3 per1</th>\n",
       "      <th>PAY_AMT3 per2</th>\n",
       "      <th>PAY_AMT3 per3</th>\n",
       "      <th>PAY_AMT3 per4</th>\n",
       "      <th>PAY_AMT3 per5</th>\n",
       "      <th>PAY_AMT3 per6</th>\n",
       "      <th>PAY_AMT4^2</th>\n",
       "      <th>PAY_AMT4 PAY_AMT5</th>\n",
       "      <th>PAY_AMT4 PAY_AMT6</th>\n",
       "      <th>PAY_AMT4 per1</th>\n",
       "      <th>PAY_AMT4 per2</th>\n",
       "      <th>PAY_AMT4 per3</th>\n",
       "      <th>PAY_AMT4 per4</th>\n",
       "      <th>PAY_AMT4 per5</th>\n",
       "      <th>PAY_AMT4 per6</th>\n",
       "      <th>PAY_AMT5^2</th>\n",
       "      <th>PAY_AMT5 PAY_AMT6</th>\n",
       "      <th>PAY_AMT5 per1</th>\n",
       "      <th>PAY_AMT5 per2</th>\n",
       "      <th>PAY_AMT5 per3</th>\n",
       "      <th>PAY_AMT5 per4</th>\n",
       "      <th>PAY_AMT5 per5</th>\n",
       "      <th>PAY_AMT5 per6</th>\n",
       "      <th>PAY_AMT6^2</th>\n",
       "      <th>PAY_AMT6 per1</th>\n",
       "      <th>PAY_AMT6 per2</th>\n",
       "      <th>PAY_AMT6 per3</th>\n",
       "      <th>PAY_AMT6 per4</th>\n",
       "      <th>PAY_AMT6 per5</th>\n",
       "      <th>PAY_AMT6 per6</th>\n",
       "      <th>per1^2</th>\n",
       "      <th>per1 per2</th>\n",
       "      <th>per1 per3</th>\n",
       "      <th>per1 per4</th>\n",
       "      <th>per1 per5</th>\n",
       "      <th>per1 per6</th>\n",
       "      <th>per2^2</th>\n",
       "      <th>per2 per3</th>\n",
       "      <th>per2 per4</th>\n",
       "      <th>per2 per5</th>\n",
       "      <th>per2 per6</th>\n",
       "      <th>per3^2</th>\n",
       "      <th>per3 per4</th>\n",
       "      <th>per3 per5</th>\n",
       "      <th>per3 per6</th>\n",
       "      <th>per4^2</th>\n",
       "      <th>per4 per5</th>\n",
       "      <th>per4 per6</th>\n",
       "      <th>per5^2</th>\n",
       "      <th>per5 per6</th>\n",
       "      <th>per6^2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3913.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.56</td>\n",
       "      <td>15.51</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.000000e+08</td>\n",
       "      <td>480000.0</td>\n",
       "      <td>7.826000e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13780000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>391200.0</td>\n",
       "      <td>310200.0</td>\n",
       "      <td>68800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>93912.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16536.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>469.44</td>\n",
       "      <td>372.24</td>\n",
       "      <td>82.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.531157e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2696057.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76538.28</td>\n",
       "      <td>60690.63</td>\n",
       "      <td>13460.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>474721.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13476.84</td>\n",
       "      <td>10686.39</td>\n",
       "      <td>2370.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>382.5936</td>\n",
       "      <td>303.3756</td>\n",
       "      <td>67.2864</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>240.5601</td>\n",
       "      <td>53.3544</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.8336</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13007.0</td>\n",
       "      <td>1122.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>65.04</td>\n",
       "      <td>69.56</td>\n",
       "      <td>4.000000e+08</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>260140000.0</td>\n",
       "      <td>22440000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1300800.0</td>\n",
       "      <td>1391200.0</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>455245.0</td>\n",
       "      <td>39270.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2276.40</td>\n",
       "      <td>2434.6</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169182049.0</td>\n",
       "      <td>14593854.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>845975.28</td>\n",
       "      <td>904766.92</td>\n",
       "      <td>1258884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72974.88</td>\n",
       "      <td>78046.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4230.2016</td>\n",
       "      <td>4524.1824</td>\n",
       "      <td>4838.5936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17973.0</td>\n",
       "      <td>1699.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>626.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.86</td>\n",
       "      <td>96.84</td>\n",
       "      <td>97.80</td>\n",
       "      <td>91.20</td>\n",
       "      <td>89.64</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4.000000e+08</td>\n",
       "      <td>760000.0</td>\n",
       "      <td>3.594600e+08</td>\n",
       "      <td>33980000.0</td>\n",
       "      <td>29200000.0</td>\n",
       "      <td>12520000.0</td>\n",
       "      <td>35000000.0</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1797200.0</td>\n",
       "      <td>1936800.0</td>\n",
       "      <td>1956000.0</td>\n",
       "      <td>1824000.0</td>\n",
       "      <td>1792800.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>682974.0</td>\n",
       "      <td>64562.0</td>\n",
       "      <td>55480.0</td>\n",
       "      <td>23788.0</td>\n",
       "      <td>66500.0</td>\n",
       "      <td>5700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3414.68</td>\n",
       "      <td>3679.92</td>\n",
       "      <td>3716.40</td>\n",
       "      <td>3465.6</td>\n",
       "      <td>3406.32</td>\n",
       "      <td>28.5</td>\n",
       "      <td>3.230287e+08</td>\n",
       "      <td>30536127.0</td>\n",
       "      <td>26240580.0</td>\n",
       "      <td>11251098.0</td>\n",
       "      <td>31452750.0</td>\n",
       "      <td>2695950.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1615053.78</td>\n",
       "      <td>1740505.32</td>\n",
       "      <td>1757759.40</td>\n",
       "      <td>1639137.60</td>\n",
       "      <td>1611099.72</td>\n",
       "      <td>13479.75</td>\n",
       "      <td>2886601.0</td>\n",
       "      <td>2480540.0</td>\n",
       "      <td>1063574.0</td>\n",
       "      <td>2973250.0</td>\n",
       "      <td>254850.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152672.14</td>\n",
       "      <td>164531.16</td>\n",
       "      <td>166162.2</td>\n",
       "      <td>154948.8</td>\n",
       "      <td>152298.36</td>\n",
       "      <td>1274.25</td>\n",
       "      <td>2131600.0</td>\n",
       "      <td>913960.0</td>\n",
       "      <td>2555000.0</td>\n",
       "      <td>219000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131195.60</td>\n",
       "      <td>141386.40</td>\n",
       "      <td>142788.00</td>\n",
       "      <td>133152.0</td>\n",
       "      <td>130874.4</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>391876.0</td>\n",
       "      <td>1095500.0</td>\n",
       "      <td>93900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56252.36</td>\n",
       "      <td>60621.84</td>\n",
       "      <td>61222.80</td>\n",
       "      <td>57091.20</td>\n",
       "      <td>56114.64</td>\n",
       "      <td>469.5</td>\n",
       "      <td>3062500.0</td>\n",
       "      <td>262500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157255.00</td>\n",
       "      <td>169470.00</td>\n",
       "      <td>171150.00</td>\n",
       "      <td>159600.00</td>\n",
       "      <td>156870.00</td>\n",
       "      <td>1312.50</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13479.00</td>\n",
       "      <td>14526.00</td>\n",
       "      <td>14670.00</td>\n",
       "      <td>13680.00</td>\n",
       "      <td>13446.00</td>\n",
       "      <td>112.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8074.8196</td>\n",
       "      <td>8702.0424</td>\n",
       "      <td>8788.3080</td>\n",
       "      <td>8195.2320</td>\n",
       "      <td>8055.0504</td>\n",
       "      <td>67.395</td>\n",
       "      <td>9377.9856</td>\n",
       "      <td>9470.9520</td>\n",
       "      <td>8831.8080</td>\n",
       "      <td>8680.7376</td>\n",
       "      <td>72.63</td>\n",
       "      <td>9564.8400</td>\n",
       "      <td>8919.3600</td>\n",
       "      <td>8766.7920</td>\n",
       "      <td>73.35</td>\n",
       "      <td>8317.4400</td>\n",
       "      <td>8175.1680</td>\n",
       "      <td>68.40</td>\n",
       "      <td>8035.3296</td>\n",
       "      <td>67.2300</td>\n",
       "      <td>0.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>113348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>3158.0</td>\n",
       "      <td>3934.0</td>\n",
       "      <td>3802.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>94.46</td>\n",
       "      <td>91.77</td>\n",
       "      <td>93.08</td>\n",
       "      <td>69.88</td>\n",
       "      <td>72.03</td>\n",
       "      <td>74.00</td>\n",
       "      <td>1.440000e+10</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>1.360176e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600000000.0</td>\n",
       "      <td>378960000.0</td>\n",
       "      <td>472080000.0</td>\n",
       "      <td>456240000.0</td>\n",
       "      <td>240000000.0</td>\n",
       "      <td>11335200.0</td>\n",
       "      <td>11012400.0</td>\n",
       "      <td>11169600.0</td>\n",
       "      <td>8385600.0</td>\n",
       "      <td>8643600.0</td>\n",
       "      <td>8880000.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>2833700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>78950.0</td>\n",
       "      <td>98350.0</td>\n",
       "      <td>95050.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2361.50</td>\n",
       "      <td>2294.25</td>\n",
       "      <td>2327.00</td>\n",
       "      <td>1747.0</td>\n",
       "      <td>1800.75</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>1.284777e+10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>566740000.0</td>\n",
       "      <td>357952984.0</td>\n",
       "      <td>445911032.0</td>\n",
       "      <td>430949096.0</td>\n",
       "      <td>226696000.0</td>\n",
       "      <td>10706852.08</td>\n",
       "      <td>10401945.96</td>\n",
       "      <td>10550431.84</td>\n",
       "      <td>7920758.24</td>\n",
       "      <td>8164456.44</td>\n",
       "      <td>8387752.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25000000.0</td>\n",
       "      <td>15790000.0</td>\n",
       "      <td>19670000.0</td>\n",
       "      <td>19010000.0</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>472300.00</td>\n",
       "      <td>458850.00</td>\n",
       "      <td>465400.00</td>\n",
       "      <td>349400.0</td>\n",
       "      <td>360150.0</td>\n",
       "      <td>370000.0</td>\n",
       "      <td>9972964.0</td>\n",
       "      <td>12423572.0</td>\n",
       "      <td>12006716.0</td>\n",
       "      <td>6316000.0</td>\n",
       "      <td>298304.68</td>\n",
       "      <td>289809.66</td>\n",
       "      <td>293946.64</td>\n",
       "      <td>220681.04</td>\n",
       "      <td>227470.74</td>\n",
       "      <td>233692.0</td>\n",
       "      <td>15476356.0</td>\n",
       "      <td>14957068.0</td>\n",
       "      <td>7868000.0</td>\n",
       "      <td>371605.64</td>\n",
       "      <td>361023.18</td>\n",
       "      <td>366176.72</td>\n",
       "      <td>274907.92</td>\n",
       "      <td>283366.02</td>\n",
       "      <td>291116.00</td>\n",
       "      <td>14455204.0</td>\n",
       "      <td>7604000.0</td>\n",
       "      <td>359136.92</td>\n",
       "      <td>348909.54</td>\n",
       "      <td>353890.16</td>\n",
       "      <td>265683.76</td>\n",
       "      <td>273858.06</td>\n",
       "      <td>281348.00</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>188920.0</td>\n",
       "      <td>183540.0</td>\n",
       "      <td>186160.0</td>\n",
       "      <td>139760.0</td>\n",
       "      <td>144060.0</td>\n",
       "      <td>148000.0</td>\n",
       "      <td>8922.6916</td>\n",
       "      <td>8668.5942</td>\n",
       "      <td>8792.3368</td>\n",
       "      <td>6600.8648</td>\n",
       "      <td>6803.9538</td>\n",
       "      <td>6990.040</td>\n",
       "      <td>8421.7329</td>\n",
       "      <td>8541.9516</td>\n",
       "      <td>6412.8876</td>\n",
       "      <td>6610.1931</td>\n",
       "      <td>6790.98</td>\n",
       "      <td>8663.8864</td>\n",
       "      <td>6504.4304</td>\n",
       "      <td>6704.5524</td>\n",
       "      <td>6887.92</td>\n",
       "      <td>4883.2144</td>\n",
       "      <td>5033.4564</td>\n",
       "      <td>5171.12</td>\n",
       "      <td>5188.3209</td>\n",
       "      <td>5330.2200</td>\n",
       "      <td>5476.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>260000.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.760000e+10</td>\n",
       "      <td>10400000.0</td>\n",
       "      <td>6.500000e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>249600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.250000e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2400.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9216</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL   AGE  BILL_AMT1  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  \\\n",
       "ID                                                                          \n",
       "1        20000.0  24.0     3913.0       0.0     689.0       0.0       0.0   \n",
       "10       20000.0  35.0        0.0       0.0       0.0       0.0   13007.0   \n",
       "100      20000.0  38.0    17973.0    1699.0    1460.0     626.0    1750.0   \n",
       "1000    120000.0  25.0   113348.0       0.0    5000.0    3158.0    3934.0   \n",
       "10001   260000.0  40.0     2500.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       PAY_AMT5  PAY_AMT6   per1   per2   per3   per4   per5   per6  \\\n",
       "ID                                                                    \n",
       "1           0.0       0.0  19.56  15.51   3.44   0.00   0.00   0.00   \n",
       "10       1122.0       0.0   0.00   0.00   0.00   0.00  65.04  69.56   \n",
       "100       150.0       0.0  89.86  96.84  97.80  91.20  89.64   0.75   \n",
       "1000     3802.0    2000.0  94.46  91.77  93.08  69.88  72.03  74.00   \n",
       "10001       0.0       0.0   0.96   0.00   0.00   0.00   0.00   0.00   \n",
       "\n",
       "        LIMIT_BAL^2  LIMIT_BAL AGE  LIMIT_BAL BILL_AMT1  LIMIT_BAL PAY_AMT1  \\\n",
       "ID                                                                            \n",
       "1      4.000000e+08       480000.0         7.826000e+07                 0.0   \n",
       "10     4.000000e+08       700000.0         0.000000e+00                 0.0   \n",
       "100    4.000000e+08       760000.0         3.594600e+08          33980000.0   \n",
       "1000   1.440000e+10      3000000.0         1.360176e+10                 0.0   \n",
       "10001  6.760000e+10     10400000.0         6.500000e+08                 0.0   \n",
       "\n",
       "       LIMIT_BAL PAY_AMT2  LIMIT_BAL PAY_AMT3  LIMIT_BAL PAY_AMT4  \\\n",
       "ID                                                                  \n",
       "1              13780000.0                 0.0                 0.0   \n",
       "10                    0.0                 0.0         260140000.0   \n",
       "100            29200000.0          12520000.0          35000000.0   \n",
       "1000          600000000.0         378960000.0         472080000.0   \n",
       "10001                 0.0                 0.0                 0.0   \n",
       "\n",
       "       LIMIT_BAL PAY_AMT5  LIMIT_BAL PAY_AMT6  LIMIT_BAL per1  LIMIT_BAL per2  \\\n",
       "ID                                                                              \n",
       "1                     0.0                 0.0        391200.0        310200.0   \n",
       "10             22440000.0                 0.0             0.0             0.0   \n",
       "100             3000000.0                 0.0       1797200.0       1936800.0   \n",
       "1000          456240000.0         240000000.0      11335200.0      11012400.0   \n",
       "10001                 0.0                 0.0        249600.0             0.0   \n",
       "\n",
       "       LIMIT_BAL per3  LIMIT_BAL per4  LIMIT_BAL per5  LIMIT_BAL per6   AGE^2  \\\n",
       "ID                                                                              \n",
       "1             68800.0             0.0             0.0             0.0   576.0   \n",
       "10                0.0             0.0       1300800.0       1391200.0  1225.0   \n",
       "100         1956000.0       1824000.0       1792800.0         15000.0  1444.0   \n",
       "1000       11169600.0       8385600.0       8643600.0       8880000.0   625.0   \n",
       "10001             0.0             0.0             0.0             0.0  1600.0   \n",
       "\n",
       "       AGE BILL_AMT1  AGE PAY_AMT1  AGE PAY_AMT2  AGE PAY_AMT3  AGE PAY_AMT4  \\\n",
       "ID                                                                             \n",
       "1            93912.0           0.0       16536.0           0.0           0.0   \n",
       "10               0.0           0.0           0.0           0.0      455245.0   \n",
       "100         682974.0       64562.0       55480.0       23788.0       66500.0   \n",
       "1000       2833700.0           0.0      125000.0       78950.0       98350.0   \n",
       "10001       100000.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "       AGE PAY_AMT5  AGE PAY_AMT6  AGE per1  AGE per2  AGE per3  AGE per4  \\\n",
       "ID                                                                          \n",
       "1               0.0           0.0    469.44    372.24     82.56       0.0   \n",
       "10          39270.0           0.0      0.00      0.00      0.00       0.0   \n",
       "100          5700.0           0.0   3414.68   3679.92   3716.40    3465.6   \n",
       "1000        95050.0       50000.0   2361.50   2294.25   2327.00    1747.0   \n",
       "10001           0.0           0.0     38.40      0.00      0.00       0.0   \n",
       "\n",
       "       AGE per5  AGE per6   BILL_AMT1^2  BILL_AMT1 PAY_AMT1  \\\n",
       "ID                                                            \n",
       "1          0.00       0.0  1.531157e+07                 0.0   \n",
       "10      2276.40    2434.6  0.000000e+00                 0.0   \n",
       "100     3406.32      28.5  3.230287e+08          30536127.0   \n",
       "1000    1800.75    1850.0  1.284777e+10                 0.0   \n",
       "10001      0.00       0.0  6.250000e+06                 0.0   \n",
       "\n",
       "       BILL_AMT1 PAY_AMT2  BILL_AMT1 PAY_AMT3  BILL_AMT1 PAY_AMT4  \\\n",
       "ID                                                                  \n",
       "1               2696057.0                 0.0                 0.0   \n",
       "10                    0.0                 0.0                 0.0   \n",
       "100            26240580.0          11251098.0          31452750.0   \n",
       "1000          566740000.0         357952984.0         445911032.0   \n",
       "10001                 0.0                 0.0                 0.0   \n",
       "\n",
       "       BILL_AMT1 PAY_AMT5  BILL_AMT1 PAY_AMT6  BILL_AMT1 per1  BILL_AMT1 per2  \\\n",
       "ID                                                                              \n",
       "1                     0.0                 0.0        76538.28        60690.63   \n",
       "10                    0.0                 0.0            0.00            0.00   \n",
       "100             2695950.0                 0.0      1615053.78      1740505.32   \n",
       "1000          430949096.0         226696000.0     10706852.08     10401945.96   \n",
       "10001                 0.0                 0.0         2400.00            0.00   \n",
       "\n",
       "       BILL_AMT1 per3  BILL_AMT1 per4  BILL_AMT1 per5  BILL_AMT1 per6  \\\n",
       "ID                                                                      \n",
       "1            13460.72            0.00            0.00            0.00   \n",
       "10               0.00            0.00            0.00            0.00   \n",
       "100        1757759.40      1639137.60      1611099.72        13479.75   \n",
       "1000      10550431.84      7920758.24      8164456.44      8387752.00   \n",
       "10001            0.00            0.00            0.00            0.00   \n",
       "\n",
       "       PAY_AMT1^2  PAY_AMT1 PAY_AMT2  PAY_AMT1 PAY_AMT3  PAY_AMT1 PAY_AMT4  \\\n",
       "ID                                                                           \n",
       "1             0.0                0.0                0.0                0.0   \n",
       "10            0.0                0.0                0.0                0.0   \n",
       "100     2886601.0          2480540.0          1063574.0          2973250.0   \n",
       "1000          0.0                0.0                0.0                0.0   \n",
       "10001         0.0                0.0                0.0                0.0   \n",
       "\n",
       "       PAY_AMT1 PAY_AMT5  PAY_AMT1 PAY_AMT6  PAY_AMT1 per1  PAY_AMT1 per2  \\\n",
       "ID                                                                          \n",
       "1                    0.0                0.0           0.00           0.00   \n",
       "10                   0.0                0.0           0.00           0.00   \n",
       "100             254850.0                0.0      152672.14      164531.16   \n",
       "1000                 0.0                0.0           0.00           0.00   \n",
       "10001                0.0                0.0           0.00           0.00   \n",
       "\n",
       "       PAY_AMT1 per3  PAY_AMT1 per4  PAY_AMT1 per5  PAY_AMT1 per6  PAY_AMT2^2  \\\n",
       "ID                                                                              \n",
       "1                0.0            0.0           0.00           0.00    474721.0   \n",
       "10               0.0            0.0           0.00           0.00         0.0   \n",
       "100         166162.2       154948.8      152298.36        1274.25   2131600.0   \n",
       "1000             0.0            0.0           0.00           0.00  25000000.0   \n",
       "10001            0.0            0.0           0.00           0.00         0.0   \n",
       "\n",
       "       PAY_AMT2 PAY_AMT3  PAY_AMT2 PAY_AMT4  PAY_AMT2 PAY_AMT5  \\\n",
       "ID                                                               \n",
       "1                    0.0                0.0                0.0   \n",
       "10                   0.0                0.0                0.0   \n",
       "100             913960.0          2555000.0           219000.0   \n",
       "1000          15790000.0         19670000.0         19010000.0   \n",
       "10001                0.0                0.0                0.0   \n",
       "\n",
       "       PAY_AMT2 PAY_AMT6  PAY_AMT2 per1  PAY_AMT2 per2  PAY_AMT2 per3  \\\n",
       "ID                                                                      \n",
       "1                    0.0       13476.84       10686.39        2370.16   \n",
       "10                   0.0           0.00           0.00           0.00   \n",
       "100                  0.0      131195.60      141386.40      142788.00   \n",
       "1000          10000000.0      472300.00      458850.00      465400.00   \n",
       "10001                0.0           0.00           0.00           0.00   \n",
       "\n",
       "       PAY_AMT2 per4  PAY_AMT2 per5  PAY_AMT2 per6  PAY_AMT3^2  \\\n",
       "ID                                                               \n",
       "1                0.0            0.0            0.0         0.0   \n",
       "10               0.0            0.0            0.0         0.0   \n",
       "100         133152.0       130874.4         1095.0    391876.0   \n",
       "1000        349400.0       360150.0       370000.0   9972964.0   \n",
       "10001            0.0            0.0            0.0         0.0   \n",
       "\n",
       "       PAY_AMT3 PAY_AMT4  PAY_AMT3 PAY_AMT5  PAY_AMT3 PAY_AMT6  PAY_AMT3 per1  \\\n",
       "ID                                                                              \n",
       "1                    0.0                0.0                0.0           0.00   \n",
       "10                   0.0                0.0                0.0           0.00   \n",
       "100            1095500.0            93900.0                0.0       56252.36   \n",
       "1000          12423572.0         12006716.0          6316000.0      298304.68   \n",
       "10001                0.0                0.0                0.0           0.00   \n",
       "\n",
       "       PAY_AMT3 per2  PAY_AMT3 per3  PAY_AMT3 per4  PAY_AMT3 per5  \\\n",
       "ID                                                                  \n",
       "1               0.00           0.00           0.00           0.00   \n",
       "10              0.00           0.00           0.00           0.00   \n",
       "100         60621.84       61222.80       57091.20       56114.64   \n",
       "1000       289809.66      293946.64      220681.04      227470.74   \n",
       "10001           0.00           0.00           0.00           0.00   \n",
       "\n",
       "       PAY_AMT3 per6   PAY_AMT4^2  PAY_AMT4 PAY_AMT5  PAY_AMT4 PAY_AMT6  \\\n",
       "ID                                                                        \n",
       "1                0.0          0.0                0.0                0.0   \n",
       "10               0.0  169182049.0         14593854.0                0.0   \n",
       "100            469.5    3062500.0           262500.0                0.0   \n",
       "1000        233692.0   15476356.0         14957068.0          7868000.0   \n",
       "10001            0.0          0.0                0.0                0.0   \n",
       "\n",
       "       PAY_AMT4 per1  PAY_AMT4 per2  PAY_AMT4 per3  PAY_AMT4 per4  \\\n",
       "ID                                                                  \n",
       "1               0.00           0.00           0.00           0.00   \n",
       "10              0.00           0.00           0.00           0.00   \n",
       "100        157255.00      169470.00      171150.00      159600.00   \n",
       "1000       371605.64      361023.18      366176.72      274907.92   \n",
       "10001           0.00           0.00           0.00           0.00   \n",
       "\n",
       "       PAY_AMT4 per5  PAY_AMT4 per6  PAY_AMT5^2  PAY_AMT5 PAY_AMT6  \\\n",
       "ID                                                                   \n",
       "1               0.00           0.00         0.0                0.0   \n",
       "10         845975.28      904766.92   1258884.0                0.0   \n",
       "100        156870.00        1312.50     22500.0                0.0   \n",
       "1000       283366.02      291116.00  14455204.0          7604000.0   \n",
       "10001           0.00           0.00         0.0                0.0   \n",
       "\n",
       "       PAY_AMT5 per1  PAY_AMT5 per2  PAY_AMT5 per3  PAY_AMT5 per4  \\\n",
       "ID                                                                  \n",
       "1               0.00           0.00           0.00           0.00   \n",
       "10              0.00           0.00           0.00           0.00   \n",
       "100         13479.00       14526.00       14670.00       13680.00   \n",
       "1000       359136.92      348909.54      353890.16      265683.76   \n",
       "10001           0.00           0.00           0.00           0.00   \n",
       "\n",
       "       PAY_AMT5 per5  PAY_AMT5 per6  PAY_AMT6^2  PAY_AMT6 per1  PAY_AMT6 per2  \\\n",
       "ID                                                                              \n",
       "1               0.00           0.00         0.0            0.0            0.0   \n",
       "10          72974.88       78046.32         0.0            0.0            0.0   \n",
       "100         13446.00         112.50         0.0            0.0            0.0   \n",
       "1000       273858.06      281348.00   4000000.0       188920.0       183540.0   \n",
       "10001           0.00           0.00         0.0            0.0            0.0   \n",
       "\n",
       "       PAY_AMT6 per3  PAY_AMT6 per4  PAY_AMT6 per5  PAY_AMT6 per6     per1^2  \\\n",
       "ID                                                                             \n",
       "1                0.0            0.0            0.0            0.0   382.5936   \n",
       "10               0.0            0.0            0.0            0.0     0.0000   \n",
       "100              0.0            0.0            0.0            0.0  8074.8196   \n",
       "1000        186160.0       139760.0       144060.0       148000.0  8922.6916   \n",
       "10001            0.0            0.0            0.0            0.0     0.9216   \n",
       "\n",
       "       per1 per2  per1 per3  per1 per4  per1 per5  per1 per6     per2^2  \\\n",
       "ID                                                                        \n",
       "1       303.3756    67.2864     0.0000     0.0000      0.000   240.5601   \n",
       "10        0.0000     0.0000     0.0000     0.0000      0.000     0.0000   \n",
       "100    8702.0424  8788.3080  8195.2320  8055.0504     67.395  9377.9856   \n",
       "1000   8668.5942  8792.3368  6600.8648  6803.9538   6990.040  8421.7329   \n",
       "10001     0.0000     0.0000     0.0000     0.0000      0.000     0.0000   \n",
       "\n",
       "       per2 per3  per2 per4  per2 per5  per2 per6     per3^2  per3 per4  \\\n",
       "ID                                                                        \n",
       "1        53.3544     0.0000     0.0000       0.00    11.8336     0.0000   \n",
       "10        0.0000     0.0000     0.0000       0.00     0.0000     0.0000   \n",
       "100    9470.9520  8831.8080  8680.7376      72.63  9564.8400  8919.3600   \n",
       "1000   8541.9516  6412.8876  6610.1931    6790.98  8663.8864  6504.4304   \n",
       "10001     0.0000     0.0000     0.0000       0.00     0.0000     0.0000   \n",
       "\n",
       "       per3 per5  per3 per6     per4^2  per4 per5  per4 per6     per5^2  \\\n",
       "ID                                                                        \n",
       "1         0.0000       0.00     0.0000     0.0000       0.00     0.0000   \n",
       "10        0.0000       0.00     0.0000     0.0000       0.00  4230.2016   \n",
       "100    8766.7920      73.35  8317.4400  8175.1680      68.40  8035.3296   \n",
       "1000   6704.5524    6887.92  4883.2144  5033.4564    5171.12  5188.3209   \n",
       "10001     0.0000       0.00     0.0000     0.0000       0.00     0.0000   \n",
       "\n",
       "       per5 per6     per6^2  \n",
       "ID                           \n",
       "1         0.0000     0.0000  \n",
       "10     4524.1824  4838.5936  \n",
       "100      67.2300     0.5625  \n",
       "1000   5330.2200  5476.0000  \n",
       "10001     0.0000     0.0000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_poly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22499, 38)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,df_poly], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22499, 173)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing duplicate columns after joining \n",
    "df = df.loc[:,~df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['default']\n",
    "df =  pd.get_dummies(df, columns=['SEX'], drop_first = True )\n",
    "df =  pd.get_dummies(df, columns=['EDUCATION'], drop_first = True )\n",
    "df =  pd.get_dummies(df, columns=['MARRIAGE'], drop_first = True )\n",
    "df =  pd.get_dummies(df, columns=['PAY_1'], drop_first = True )\n",
    "df =  pd.get_dummies(df, columns=['PAY_2'], drop_first = True )\n",
    "df =  pd.get_dummies(df, columns=['PAY_3'], drop_first = True )\n",
    "df =  pd.get_dummies(df, columns=['PAY_4'], drop_first = True )\n",
    "df =  pd.get_dummies(df, columns=['PAY_5'], drop_first = True )\n",
    "df =  pd.get_dummies(df, columns=['PAY_6'], drop_first = True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22499, 207)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>AGE</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default</th>\n",
       "      <th>avg_bill</th>\n",
       "      <th>avg_pay</th>\n",
       "      <th>out1</th>\n",
       "      <th>out2</th>\n",
       "      <th>out3</th>\n",
       "      <th>out4</th>\n",
       "      <th>out5</th>\n",
       "      <th>out6</th>\n",
       "      <th>per1</th>\n",
       "      <th>per2</th>\n",
       "      <th>per3</th>\n",
       "      <th>per4</th>\n",
       "      <th>per5</th>\n",
       "      <th>per6</th>\n",
       "      <th>LIMIT_BAL^2</th>\n",
       "      <th>LIMIT_BAL AGE</th>\n",
       "      <th>LIMIT_BAL BILL_AMT1</th>\n",
       "      <th>LIMIT_BAL PAY_AMT1</th>\n",
       "      <th>LIMIT_BAL PAY_AMT2</th>\n",
       "      <th>LIMIT_BAL PAY_AMT3</th>\n",
       "      <th>LIMIT_BAL PAY_AMT4</th>\n",
       "      <th>LIMIT_BAL PAY_AMT5</th>\n",
       "      <th>LIMIT_BAL PAY_AMT6</th>\n",
       "      <th>LIMIT_BAL per1</th>\n",
       "      <th>LIMIT_BAL per2</th>\n",
       "      <th>LIMIT_BAL per3</th>\n",
       "      <th>LIMIT_BAL per4</th>\n",
       "      <th>LIMIT_BAL per5</th>\n",
       "      <th>LIMIT_BAL per6</th>\n",
       "      <th>AGE^2</th>\n",
       "      <th>AGE BILL_AMT1</th>\n",
       "      <th>AGE PAY_AMT1</th>\n",
       "      <th>AGE PAY_AMT2</th>\n",
       "      <th>AGE PAY_AMT3</th>\n",
       "      <th>AGE PAY_AMT4</th>\n",
       "      <th>AGE PAY_AMT5</th>\n",
       "      <th>AGE PAY_AMT6</th>\n",
       "      <th>AGE per1</th>\n",
       "      <th>AGE per2</th>\n",
       "      <th>AGE per3</th>\n",
       "      <th>AGE per4</th>\n",
       "      <th>AGE per5</th>\n",
       "      <th>AGE per6</th>\n",
       "      <th>BILL_AMT1^2</th>\n",
       "      <th>BILL_AMT1 PAY_AMT1</th>\n",
       "      <th>BILL_AMT1 PAY_AMT2</th>\n",
       "      <th>BILL_AMT1 PAY_AMT3</th>\n",
       "      <th>BILL_AMT1 PAY_AMT4</th>\n",
       "      <th>BILL_AMT1 PAY_AMT5</th>\n",
       "      <th>BILL_AMT1 PAY_AMT6</th>\n",
       "      <th>BILL_AMT1 per1</th>\n",
       "      <th>BILL_AMT1 per2</th>\n",
       "      <th>BILL_AMT1 per3</th>\n",
       "      <th>BILL_AMT1 per4</th>\n",
       "      <th>BILL_AMT1 per5</th>\n",
       "      <th>BILL_AMT1 per6</th>\n",
       "      <th>PAY_AMT1^2</th>\n",
       "      <th>PAY_AMT1 PAY_AMT2</th>\n",
       "      <th>PAY_AMT1 PAY_AMT3</th>\n",
       "      <th>PAY_AMT1 PAY_AMT4</th>\n",
       "      <th>PAY_AMT1 PAY_AMT5</th>\n",
       "      <th>PAY_AMT1 PAY_AMT6</th>\n",
       "      <th>PAY_AMT1 per1</th>\n",
       "      <th>PAY_AMT1 per2</th>\n",
       "      <th>PAY_AMT1 per3</th>\n",
       "      <th>PAY_AMT1 per4</th>\n",
       "      <th>PAY_AMT1 per5</th>\n",
       "      <th>PAY_AMT1 per6</th>\n",
       "      <th>PAY_AMT2^2</th>\n",
       "      <th>PAY_AMT2 PAY_AMT3</th>\n",
       "      <th>PAY_AMT2 PAY_AMT4</th>\n",
       "      <th>PAY_AMT2 PAY_AMT5</th>\n",
       "      <th>PAY_AMT2 PAY_AMT6</th>\n",
       "      <th>PAY_AMT2 per1</th>\n",
       "      <th>PAY_AMT2 per2</th>\n",
       "      <th>PAY_AMT2 per3</th>\n",
       "      <th>PAY_AMT2 per4</th>\n",
       "      <th>PAY_AMT2 per5</th>\n",
       "      <th>PAY_AMT2 per6</th>\n",
       "      <th>PAY_AMT3^2</th>\n",
       "      <th>PAY_AMT3 PAY_AMT4</th>\n",
       "      <th>PAY_AMT3 PAY_AMT5</th>\n",
       "      <th>PAY_AMT3 PAY_AMT6</th>\n",
       "      <th>PAY_AMT3 per1</th>\n",
       "      <th>PAY_AMT3 per2</th>\n",
       "      <th>PAY_AMT3 per3</th>\n",
       "      <th>PAY_AMT3 per4</th>\n",
       "      <th>PAY_AMT3 per5</th>\n",
       "      <th>PAY_AMT3 per6</th>\n",
       "      <th>PAY_AMT4^2</th>\n",
       "      <th>PAY_AMT4 PAY_AMT5</th>\n",
       "      <th>PAY_AMT4 PAY_AMT6</th>\n",
       "      <th>PAY_AMT4 per1</th>\n",
       "      <th>PAY_AMT4 per2</th>\n",
       "      <th>PAY_AMT4 per3</th>\n",
       "      <th>PAY_AMT4 per4</th>\n",
       "      <th>PAY_AMT4 per5</th>\n",
       "      <th>PAY_AMT4 per6</th>\n",
       "      <th>PAY_AMT5^2</th>\n",
       "      <th>PAY_AMT5 PAY_AMT6</th>\n",
       "      <th>PAY_AMT5 per1</th>\n",
       "      <th>PAY_AMT5 per2</th>\n",
       "      <th>PAY_AMT5 per3</th>\n",
       "      <th>PAY_AMT5 per4</th>\n",
       "      <th>PAY_AMT5 per5</th>\n",
       "      <th>PAY_AMT5 per6</th>\n",
       "      <th>PAY_AMT6^2</th>\n",
       "      <th>PAY_AMT6 per1</th>\n",
       "      <th>PAY_AMT6 per2</th>\n",
       "      <th>PAY_AMT6 per3</th>\n",
       "      <th>PAY_AMT6 per4</th>\n",
       "      <th>PAY_AMT6 per5</th>\n",
       "      <th>PAY_AMT6 per6</th>\n",
       "      <th>per1^2</th>\n",
       "      <th>per1 per2</th>\n",
       "      <th>per1 per3</th>\n",
       "      <th>per1 per4</th>\n",
       "      <th>per1 per5</th>\n",
       "      <th>per1 per6</th>\n",
       "      <th>per2^2</th>\n",
       "      <th>per2 per3</th>\n",
       "      <th>per2 per4</th>\n",
       "      <th>per2 per5</th>\n",
       "      <th>per2 per6</th>\n",
       "      <th>per3^2</th>\n",
       "      <th>per3 per4</th>\n",
       "      <th>per3 per5</th>\n",
       "      <th>per3 per6</th>\n",
       "      <th>per4^2</th>\n",
       "      <th>per4 per5</th>\n",
       "      <th>per4 per6</th>\n",
       "      <th>per5^2</th>\n",
       "      <th>per5 per6</th>\n",
       "      <th>per6^2</th>\n",
       "      <th>SEX_2</th>\n",
       "      <th>EDUCATION_2</th>\n",
       "      <th>EDUCATION_3</th>\n",
       "      <th>EDUCATION_4</th>\n",
       "      <th>MARRIAGE_2</th>\n",
       "      <th>MARRIAGE_3</th>\n",
       "      <th>PAY_1_0</th>\n",
       "      <th>PAY_1_1</th>\n",
       "      <th>PAY_1_2</th>\n",
       "      <th>PAY_1_3</th>\n",
       "      <th>PAY_1_4</th>\n",
       "      <th>PAY_1_5</th>\n",
       "      <th>PAY_1_6</th>\n",
       "      <th>PAY_1_7</th>\n",
       "      <th>PAY_1_8</th>\n",
       "      <th>PAY_2_0</th>\n",
       "      <th>PAY_2_1</th>\n",
       "      <th>PAY_2_2</th>\n",
       "      <th>PAY_2_3</th>\n",
       "      <th>PAY_2_4</th>\n",
       "      <th>PAY_2_5</th>\n",
       "      <th>PAY_2_6</th>\n",
       "      <th>PAY_2_7</th>\n",
       "      <th>PAY_2_8</th>\n",
       "      <th>PAY_3_0</th>\n",
       "      <th>PAY_3_1</th>\n",
       "      <th>PAY_3_2</th>\n",
       "      <th>PAY_3_3</th>\n",
       "      <th>PAY_3_4</th>\n",
       "      <th>PAY_3_5</th>\n",
       "      <th>PAY_3_6</th>\n",
       "      <th>PAY_3_7</th>\n",
       "      <th>PAY_3_8</th>\n",
       "      <th>PAY_4_0</th>\n",
       "      <th>PAY_4_1</th>\n",
       "      <th>PAY_4_2</th>\n",
       "      <th>PAY_4_3</th>\n",
       "      <th>PAY_4_4</th>\n",
       "      <th>PAY_4_5</th>\n",
       "      <th>PAY_4_6</th>\n",
       "      <th>PAY_4_7</th>\n",
       "      <th>PAY_4_8</th>\n",
       "      <th>PAY_5_0</th>\n",
       "      <th>PAY_5_2</th>\n",
       "      <th>PAY_5_3</th>\n",
       "      <th>PAY_5_4</th>\n",
       "      <th>PAY_5_5</th>\n",
       "      <th>PAY_5_6</th>\n",
       "      <th>PAY_5_7</th>\n",
       "      <th>PAY_5_8</th>\n",
       "      <th>PAY_6_0</th>\n",
       "      <th>PAY_6_2</th>\n",
       "      <th>PAY_6_3</th>\n",
       "      <th>PAY_6_4</th>\n",
       "      <th>PAY_6_5</th>\n",
       "      <th>PAY_6_6</th>\n",
       "      <th>PAY_6_7</th>\n",
       "      <th>PAY_6_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.146964</td>\n",
       "      <td>0.295659</td>\n",
       "      <td>0.288841</td>\n",
       "      <td>0.288696</td>\n",
       "      <td>0.299262</td>\n",
       "      <td>0.299236</td>\n",
       "      <td>0.294636</td>\n",
       "      <td>0.196075</td>\n",
       "      <td>0.165682</td>\n",
       "      <td>0.211372</td>\n",
       "      <td>0.199648</td>\n",
       "      <td>0.216146</td>\n",
       "      <td>0.224594</td>\n",
       "      <td>0.155958</td>\n",
       "      <td>0.309080</td>\n",
       "      <td>0.343312</td>\n",
       "      <td>0.253961</td>\n",
       "      <td>0.227156</td>\n",
       "      <td>0.234207</td>\n",
       "      <td>0.251301</td>\n",
       "      <td>0.244805</td>\n",
       "      <td>0.224505</td>\n",
       "      <td>0.363611</td>\n",
       "      <td>0.367210</td>\n",
       "      <td>0.357129</td>\n",
       "      <td>0.351012</td>\n",
       "      <td>0.337173</td>\n",
       "      <td>0.318580</td>\n",
       "      <td>0.944200</td>\n",
       "      <td>0.942585</td>\n",
       "      <td>0.457971</td>\n",
       "      <td>0.294216</td>\n",
       "      <td>0.211126</td>\n",
       "      <td>0.234115</td>\n",
       "      <td>0.271608</td>\n",
       "      <td>0.297079</td>\n",
       "      <td>0.288880</td>\n",
       "      <td>0.295659</td>\n",
       "      <td>0.288841</td>\n",
       "      <td>0.288695</td>\n",
       "      <td>0.299262</td>\n",
       "      <td>0.299236</td>\n",
       "      <td>0.294637</td>\n",
       "      <td>0.115574</td>\n",
       "      <td>0.298576</td>\n",
       "      <td>0.199462</td>\n",
       "      <td>0.173972</td>\n",
       "      <td>0.210451</td>\n",
       "      <td>0.210728</td>\n",
       "      <td>0.223393</td>\n",
       "      <td>0.229342</td>\n",
       "      <td>0.307870</td>\n",
       "      <td>0.312513</td>\n",
       "      <td>0.305550</td>\n",
       "      <td>0.299329</td>\n",
       "      <td>0.287790</td>\n",
       "      <td>0.272520</td>\n",
       "      <td>0.334041</td>\n",
       "      <td>0.190743</td>\n",
       "      <td>0.185277</td>\n",
       "      <td>0.116389</td>\n",
       "      <td>0.151088</td>\n",
       "      <td>0.167601</td>\n",
       "      <td>0.163045</td>\n",
       "      <td>0.171639</td>\n",
       "      <td>0.166834</td>\n",
       "      <td>0.163798</td>\n",
       "      <td>0.169347</td>\n",
       "      <td>0.171775</td>\n",
       "      <td>0.170501</td>\n",
       "      <td>0.055390</td>\n",
       "      <td>0.028405</td>\n",
       "      <td>0.032119</td>\n",
       "      <td>0.031477</td>\n",
       "      <td>0.109325</td>\n",
       "      <td>0.080031</td>\n",
       "      <td>0.090972</td>\n",
       "      <td>0.078030</td>\n",
       "      <td>0.073503</td>\n",
       "      <td>0.078012</td>\n",
       "      <td>0.075631</td>\n",
       "      <td>0.075221</td>\n",
       "      <td>0.039177</td>\n",
       "      <td>0.031239</td>\n",
       "      <td>0.027028</td>\n",
       "      <td>0.034074</td>\n",
       "      <td>0.079128</td>\n",
       "      <td>0.075886</td>\n",
       "      <td>0.075680</td>\n",
       "      <td>0.020009</td>\n",
       "      <td>0.094053</td>\n",
       "      <td>0.085740</td>\n",
       "      <td>0.052753</td>\n",
       "      <td>0.079100</td>\n",
       "      <td>0.038340</td>\n",
       "      <td>0.110562</td>\n",
       "      <td>0.097425</td>\n",
       "      <td>0.096016</td>\n",
       "      <td>0.094908</td>\n",
       "      <td>0.112270</td>\n",
       "      <td>0.106460</td>\n",
       "      <td>0.098617</td>\n",
       "      <td>0.097327</td>\n",
       "      <td>0.082141</td>\n",
       "      <td>0.119093</td>\n",
       "      <td>0.106022</td>\n",
       "      <td>0.076233</td>\n",
       "      <td>0.074689</td>\n",
       "      <td>0.080390</td>\n",
       "      <td>0.094313</td>\n",
       "      <td>0.089594</td>\n",
       "      <td>0.088009</td>\n",
       "      <td>0.105786</td>\n",
       "      <td>0.130070</td>\n",
       "      <td>0.082259</td>\n",
       "      <td>0.078864</td>\n",
       "      <td>0.051596</td>\n",
       "      <td>0.097408</td>\n",
       "      <td>0.105280</td>\n",
       "      <td>0.096949</td>\n",
       "      <td>0.108208</td>\n",
       "      <td>0.095303</td>\n",
       "      <td>0.092620</td>\n",
       "      <td>0.099153</td>\n",
       "      <td>0.103182</td>\n",
       "      <td>0.106545</td>\n",
       "      <td>0.097486</td>\n",
       "      <td>0.238557</td>\n",
       "      <td>0.239503</td>\n",
       "      <td>0.259073</td>\n",
       "      <td>0.256752</td>\n",
       "      <td>0.248933</td>\n",
       "      <td>0.261696</td>\n",
       "      <td>0.243438</td>\n",
       "      <td>0.265211</td>\n",
       "      <td>0.261068</td>\n",
       "      <td>0.253307</td>\n",
       "      <td>0.267524</td>\n",
       "      <td>0.152239</td>\n",
       "      <td>0.270064</td>\n",
       "      <td>0.261840</td>\n",
       "      <td>0.266119</td>\n",
       "      <td>0.265682</td>\n",
       "      <td>0.258754</td>\n",
       "      <td>0.275083</td>\n",
       "      <td>0.255874</td>\n",
       "      <td>0.274933</td>\n",
       "      <td>0.277401</td>\n",
       "      <td>0.021080</td>\n",
       "      <td>0.148857</td>\n",
       "      <td>0.141774</td>\n",
       "      <td>0.010605</td>\n",
       "      <td>0.089221</td>\n",
       "      <td>0.049389</td>\n",
       "      <td>0.097790</td>\n",
       "      <td>0.052475</td>\n",
       "      <td>0.134128</td>\n",
       "      <td>0.067959</td>\n",
       "      <td>0.032744</td>\n",
       "      <td>0.020340</td>\n",
       "      <td>0.010672</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>0.008696</td>\n",
       "      <td>0.115974</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.179362</td>\n",
       "      <td>0.066706</td>\n",
       "      <td>0.041322</td>\n",
       "      <td>0.019725</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>0.010180</td>\n",
       "      <td>0.006523</td>\n",
       "      <td>0.116551</td>\n",
       "      <td>0.014678</td>\n",
       "      <td>0.174591</td>\n",
       "      <td>0.065854</td>\n",
       "      <td>0.036510</td>\n",
       "      <td>0.009359</td>\n",
       "      <td>0.014540</td>\n",
       "      <td>0.023601</td>\n",
       "      <td>0.008499</td>\n",
       "      <td>0.110370</td>\n",
       "      <td>0.015098</td>\n",
       "      <td>0.163705</td>\n",
       "      <td>0.057660</td>\n",
       "      <td>0.032126</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>0.013668</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.009225</td>\n",
       "      <td>0.101661</td>\n",
       "      <td>0.154219</td>\n",
       "      <td>0.057306</td>\n",
       "      <td>0.035444</td>\n",
       "      <td>0.016856</td>\n",
       "      <td>0.003295</td>\n",
       "      <td>0.037118</td>\n",
       "      <td>0.007036</td>\n",
       "      <td>0.095496</td>\n",
       "      <td>0.151656</td>\n",
       "      <td>0.054569</td>\n",
       "      <td>0.035408</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>0.013571</td>\n",
       "      <td>0.032157</td>\n",
       "      <td>0.007410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.058995</td>\n",
       "      <td>0.056343</td>\n",
       "      <td>0.055082</td>\n",
       "      <td>0.052860</td>\n",
       "      <td>0.051109</td>\n",
       "      <td>0.048705</td>\n",
       "      <td>0.026827</td>\n",
       "      <td>0.019959</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.018125</td>\n",
       "      <td>0.023779</td>\n",
       "      <td>0.019674</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.056863</td>\n",
       "      <td>0.039428</td>\n",
       "      <td>0.053443</td>\n",
       "      <td>0.048411</td>\n",
       "      <td>0.047321</td>\n",
       "      <td>0.048618</td>\n",
       "      <td>0.045165</td>\n",
       "      <td>0.042270</td>\n",
       "      <td>0.026934</td>\n",
       "      <td>0.030858</td>\n",
       "      <td>0.036442</td>\n",
       "      <td>0.051097</td>\n",
       "      <td>0.052280</td>\n",
       "      <td>0.051160</td>\n",
       "      <td>0.138273</td>\n",
       "      <td>0.385628</td>\n",
       "      <td>0.074775</td>\n",
       "      <td>0.043212</td>\n",
       "      <td>0.027186</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.031857</td>\n",
       "      <td>0.040136</td>\n",
       "      <td>0.032290</td>\n",
       "      <td>0.058996</td>\n",
       "      <td>0.056343</td>\n",
       "      <td>0.055083</td>\n",
       "      <td>0.052860</td>\n",
       "      <td>0.051109</td>\n",
       "      <td>0.048706</td>\n",
       "      <td>0.989490</td>\n",
       "      <td>0.208651</td>\n",
       "      <td>0.097894</td>\n",
       "      <td>0.072019</td>\n",
       "      <td>0.087655</td>\n",
       "      <td>0.082535</td>\n",
       "      <td>0.091657</td>\n",
       "      <td>0.080935</td>\n",
       "      <td>0.248281</td>\n",
       "      <td>0.241658</td>\n",
       "      <td>0.230923</td>\n",
       "      <td>0.215988</td>\n",
       "      <td>0.208595</td>\n",
       "      <td>0.202488</td>\n",
       "      <td>0.069892</td>\n",
       "      <td>0.034149</td>\n",
       "      <td>0.034974</td>\n",
       "      <td>0.023819</td>\n",
       "      <td>0.015084</td>\n",
       "      <td>0.021763</td>\n",
       "      <td>0.023917</td>\n",
       "      <td>0.058934</td>\n",
       "      <td>0.055922</td>\n",
       "      <td>0.056278</td>\n",
       "      <td>0.051882</td>\n",
       "      <td>0.051421</td>\n",
       "      <td>0.048372</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.004637</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>0.007064</td>\n",
       "      <td>0.013443</td>\n",
       "      <td>0.014726</td>\n",
       "      <td>0.024772</td>\n",
       "      <td>0.016233</td>\n",
       "      <td>0.013461</td>\n",
       "      <td>0.016452</td>\n",
       "      <td>0.016991</td>\n",
       "      <td>0.015043</td>\n",
       "      <td>0.002127</td>\n",
       "      <td>0.006309</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.013576</td>\n",
       "      <td>0.023894</td>\n",
       "      <td>0.017622</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>0.012828</td>\n",
       "      <td>0.015031</td>\n",
       "      <td>0.008198</td>\n",
       "      <td>0.017160</td>\n",
       "      <td>0.008845</td>\n",
       "      <td>0.014913</td>\n",
       "      <td>0.017477</td>\n",
       "      <td>0.022746</td>\n",
       "      <td>0.021761</td>\n",
       "      <td>0.023132</td>\n",
       "      <td>0.018485</td>\n",
       "      <td>0.016608</td>\n",
       "      <td>0.014653</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.015452</td>\n",
       "      <td>0.015007</td>\n",
       "      <td>0.003682</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.005695</td>\n",
       "      <td>0.010536</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.002330</td>\n",
       "      <td>0.010572</td>\n",
       "      <td>0.019012</td>\n",
       "      <td>0.011232</td>\n",
       "      <td>0.010243</td>\n",
       "      <td>0.005696</td>\n",
       "      <td>0.011987</td>\n",
       "      <td>0.020058</td>\n",
       "      <td>0.008030</td>\n",
       "      <td>0.009263</td>\n",
       "      <td>0.014636</td>\n",
       "      <td>0.017688</td>\n",
       "      <td>0.017981</td>\n",
       "      <td>0.017935</td>\n",
       "      <td>0.017944</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>0.011161</td>\n",
       "      <td>0.023017</td>\n",
       "      <td>0.024083</td>\n",
       "      <td>0.026448</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.014809</td>\n",
       "      <td>0.024923</td>\n",
       "      <td>0.026002</td>\n",
       "      <td>0.029741</td>\n",
       "      <td>0.010470</td>\n",
       "      <td>0.030932</td>\n",
       "      <td>0.031216</td>\n",
       "      <td>0.032309</td>\n",
       "      <td>0.037320</td>\n",
       "      <td>0.037497</td>\n",
       "      <td>0.041212</td>\n",
       "      <td>0.040072</td>\n",
       "      <td>0.044338</td>\n",
       "      <td>0.048511</td>\n",
       "      <td>0.093937</td>\n",
       "      <td>0.080027</td>\n",
       "      <td>0.226650</td>\n",
       "      <td>0.017191</td>\n",
       "      <td>0.468115</td>\n",
       "      <td>0.079989</td>\n",
       "      <td>0.056465</td>\n",
       "      <td>0.004277</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.007933</td>\n",
       "      <td>0.005986</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.062726</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>0.017519</td>\n",
       "      <td>0.008177</td>\n",
       "      <td>0.008529</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.006107</td>\n",
       "      <td>0.008262</td>\n",
       "      <td>0.052186</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.020546</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>0.004646</td>\n",
       "      <td>0.062570</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>0.007832</td>\n",
       "      <td>0.006975</td>\n",
       "      <td>0.005775</td>\n",
       "      <td>0.001973</td>\n",
       "      <td>0.014603</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.054778</td>\n",
       "      <td>0.020294</td>\n",
       "      <td>0.006504</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>0.008894</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.008338</td>\n",
       "      <td>0.050122</td>\n",
       "      <td>0.016765</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.004490</td>\n",
       "      <td>0.010661</td>\n",
       "      <td>0.003115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.954453</td>\n",
       "      <td>0.892254</td>\n",
       "      <td>0.864993</td>\n",
       "      <td>0.835076</td>\n",
       "      <td>0.805479</td>\n",
       "      <td>0.148222</td>\n",
       "      <td>0.095717</td>\n",
       "      <td>0.166570</td>\n",
       "      <td>0.161754</td>\n",
       "      <td>0.174668</td>\n",
       "      <td>0.172586</td>\n",
       "      <td>0.016858</td>\n",
       "      <td>0.942806</td>\n",
       "      <td>0.256331</td>\n",
       "      <td>0.974899</td>\n",
       "      <td>0.900525</td>\n",
       "      <td>0.850430</td>\n",
       "      <td>0.828845</td>\n",
       "      <td>0.792527</td>\n",
       "      <td>0.744198</td>\n",
       "      <td>0.563137</td>\n",
       "      <td>0.514426</td>\n",
       "      <td>0.465563</td>\n",
       "      <td>0.434497</td>\n",
       "      <td>0.406770</td>\n",
       "      <td>0.394430</td>\n",
       "      <td>0.275482</td>\n",
       "      <td>0.283329</td>\n",
       "      <td>0.892175</td>\n",
       "      <td>0.175578</td>\n",
       "      <td>0.096436</td>\n",
       "      <td>0.172558</td>\n",
       "      <td>0.166005</td>\n",
       "      <td>0.182404</td>\n",
       "      <td>0.179571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.954452</td>\n",
       "      <td>0.892253</td>\n",
       "      <td>0.864993</td>\n",
       "      <td>0.835077</td>\n",
       "      <td>0.805479</td>\n",
       "      <td>0.050446</td>\n",
       "      <td>0.961785</td>\n",
       "      <td>0.149431</td>\n",
       "      <td>0.102301</td>\n",
       "      <td>0.167965</td>\n",
       "      <td>0.163725</td>\n",
       "      <td>0.173984</td>\n",
       "      <td>0.176371</td>\n",
       "      <td>0.558918</td>\n",
       "      <td>0.513735</td>\n",
       "      <td>0.473381</td>\n",
       "      <td>0.449089</td>\n",
       "      <td>0.423683</td>\n",
       "      <td>0.411444</td>\n",
       "      <td>0.880237</td>\n",
       "      <td>0.411059</td>\n",
       "      <td>0.375155</td>\n",
       "      <td>0.238614</td>\n",
       "      <td>0.330237</td>\n",
       "      <td>0.361902</td>\n",
       "      <td>0.354387</td>\n",
       "      <td>0.930550</td>\n",
       "      <td>0.912840</td>\n",
       "      <td>0.893141</td>\n",
       "      <td>0.873738</td>\n",
       "      <td>0.858373</td>\n",
       "      <td>0.846376</td>\n",
       "      <td>0.026023</td>\n",
       "      <td>0.013650</td>\n",
       "      <td>0.025290</td>\n",
       "      <td>0.026592</td>\n",
       "      <td>0.073329</td>\n",
       "      <td>0.055582</td>\n",
       "      <td>0.411566</td>\n",
       "      <td>0.220920</td>\n",
       "      <td>0.224801</td>\n",
       "      <td>0.240872</td>\n",
       "      <td>0.229029</td>\n",
       "      <td>0.224735</td>\n",
       "      <td>0.006223</td>\n",
       "      <td>0.018719</td>\n",
       "      <td>0.016851</td>\n",
       "      <td>0.007917</td>\n",
       "      <td>0.028163</td>\n",
       "      <td>0.331482</td>\n",
       "      <td>0.255554</td>\n",
       "      <td>0.028257</td>\n",
       "      <td>0.186342</td>\n",
       "      <td>0.177915</td>\n",
       "      <td>0.108446</td>\n",
       "      <td>0.088587</td>\n",
       "      <td>0.034045</td>\n",
       "      <td>0.080910</td>\n",
       "      <td>0.077891</td>\n",
       "      <td>0.339820</td>\n",
       "      <td>0.320124</td>\n",
       "      <td>0.345826</td>\n",
       "      <td>0.222035</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.223244</td>\n",
       "      <td>0.061487</td>\n",
       "      <td>0.084578</td>\n",
       "      <td>0.080427</td>\n",
       "      <td>0.329690</td>\n",
       "      <td>0.322576</td>\n",
       "      <td>0.317617</td>\n",
       "      <td>0.321166</td>\n",
       "      <td>0.205528</td>\n",
       "      <td>0.214957</td>\n",
       "      <td>0.084540</td>\n",
       "      <td>0.092018</td>\n",
       "      <td>0.343533</td>\n",
       "      <td>0.336848</td>\n",
       "      <td>0.179771</td>\n",
       "      <td>0.344175</td>\n",
       "      <td>0.355705</td>\n",
       "      <td>0.217894</td>\n",
       "      <td>0.078649</td>\n",
       "      <td>0.352254</td>\n",
       "      <td>0.328955</td>\n",
       "      <td>0.303964</td>\n",
       "      <td>0.296327</td>\n",
       "      <td>0.309282</td>\n",
       "      <td>0.299653</td>\n",
       "      <td>0.382612</td>\n",
       "      <td>0.367453</td>\n",
       "      <td>0.381581</td>\n",
       "      <td>0.368841</td>\n",
       "      <td>0.358335</td>\n",
       "      <td>0.392431</td>\n",
       "      <td>0.342046</td>\n",
       "      <td>0.362978</td>\n",
       "      <td>0.347783</td>\n",
       "      <td>0.338653</td>\n",
       "      <td>0.371877</td>\n",
       "      <td>0.188642</td>\n",
       "      <td>0.333987</td>\n",
       "      <td>0.323810</td>\n",
       "      <td>0.339460</td>\n",
       "      <td>0.305627</td>\n",
       "      <td>0.300582</td>\n",
       "      <td>0.331565</td>\n",
       "      <td>0.271970</td>\n",
       "      <td>0.309126</td>\n",
       "      <td>0.296519</td>\n",
       "      <td>0.037009</td>\n",
       "      <td>0.029336</td>\n",
       "      <td>0.023885</td>\n",
       "      <td>0.032840</td>\n",
       "      <td>0.025045</td>\n",
       "      <td>0.013498</td>\n",
       "      <td>0.360850</td>\n",
       "      <td>0.125751</td>\n",
       "      <td>0.061324</td>\n",
       "      <td>0.021045</td>\n",
       "      <td>0.009327</td>\n",
       "      <td>0.016173</td>\n",
       "      <td>0.011825</td>\n",
       "      <td>0.019063</td>\n",
       "      <td>0.029410</td>\n",
       "      <td>0.382785</td>\n",
       "      <td>0.009168</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.007138</td>\n",
       "      <td>0.006578</td>\n",
       "      <td>0.010599</td>\n",
       "      <td>0.020365</td>\n",
       "      <td>0.028015</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.389920</td>\n",
       "      <td>0.011149</td>\n",
       "      <td>0.027221</td>\n",
       "      <td>0.011784</td>\n",
       "      <td>0.007988</td>\n",
       "      <td>0.011846</td>\n",
       "      <td>0.022971</td>\n",
       "      <td>0.018897</td>\n",
       "      <td>0.004706</td>\n",
       "      <td>0.365285</td>\n",
       "      <td>0.018819</td>\n",
       "      <td>0.016970</td>\n",
       "      <td>0.004030</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>0.013285</td>\n",
       "      <td>0.004501</td>\n",
       "      <td>0.026160</td>\n",
       "      <td>0.003294</td>\n",
       "      <td>0.343021</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>0.016814</td>\n",
       "      <td>0.006194</td>\n",
       "      <td>0.009829</td>\n",
       "      <td>0.007460</td>\n",
       "      <td>0.028479</td>\n",
       "      <td>0.004392</td>\n",
       "      <td>0.346920</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.014748</td>\n",
       "      <td>0.014988</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.002434</td>\n",
       "      <td>0.027288</td>\n",
       "      <td>0.001764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.924654</td>\n",
       "      <td>0.893372</td>\n",
       "      <td>0.860374</td>\n",
       "      <td>0.830698</td>\n",
       "      <td>0.278827</td>\n",
       "      <td>0.099033</td>\n",
       "      <td>0.159873</td>\n",
       "      <td>0.150938</td>\n",
       "      <td>0.162069</td>\n",
       "      <td>0.170157</td>\n",
       "      <td>0.011762</td>\n",
       "      <td>0.961202</td>\n",
       "      <td>0.283571</td>\n",
       "      <td>0.899572</td>\n",
       "      <td>0.943914</td>\n",
       "      <td>0.884626</td>\n",
       "      <td>0.860016</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.769813</td>\n",
       "      <td>0.530678</td>\n",
       "      <td>0.560388</td>\n",
       "      <td>0.499078</td>\n",
       "      <td>0.465249</td>\n",
       "      <td>0.434277</td>\n",
       "      <td>0.421363</td>\n",
       "      <td>0.268179</td>\n",
       "      <td>0.276458</td>\n",
       "      <td>0.852679</td>\n",
       "      <td>0.284739</td>\n",
       "      <td>0.105608</td>\n",
       "      <td>0.169906</td>\n",
       "      <td>0.155139</td>\n",
       "      <td>0.167664</td>\n",
       "      <td>0.175930</td>\n",
       "      <td>0.954453</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.924654</td>\n",
       "      <td>0.893372</td>\n",
       "      <td>0.860374</td>\n",
       "      <td>0.830698</td>\n",
       "      <td>0.047926</td>\n",
       "      <td>0.917411</td>\n",
       "      <td>0.272370</td>\n",
       "      <td>0.103477</td>\n",
       "      <td>0.160636</td>\n",
       "      <td>0.153791</td>\n",
       "      <td>0.161836</td>\n",
       "      <td>0.174519</td>\n",
       "      <td>0.526488</td>\n",
       "      <td>0.556147</td>\n",
       "      <td>0.503981</td>\n",
       "      <td>0.477553</td>\n",
       "      <td>0.449317</td>\n",
       "      <td>0.436643</td>\n",
       "      <td>0.841187</td>\n",
       "      <td>0.417411</td>\n",
       "      <td>0.346921</td>\n",
       "      <td>0.227662</td>\n",
       "      <td>0.307165</td>\n",
       "      <td>0.329245</td>\n",
       "      <td>0.331639</td>\n",
       "      <td>0.885826</td>\n",
       "      <td>0.923404</td>\n",
       "      <td>0.899075</td>\n",
       "      <td>0.880560</td>\n",
       "      <td>0.864230</td>\n",
       "      <td>0.853090</td>\n",
       "      <td>0.097818</td>\n",
       "      <td>0.040565</td>\n",
       "      <td>0.038027</td>\n",
       "      <td>0.035341</td>\n",
       "      <td>0.114293</td>\n",
       "      <td>0.096998</td>\n",
       "      <td>0.422237</td>\n",
       "      <td>0.352566</td>\n",
       "      <td>0.342966</td>\n",
       "      <td>0.337979</td>\n",
       "      <td>0.319993</td>\n",
       "      <td>0.315806</td>\n",
       "      <td>0.017507</td>\n",
       "      <td>0.027013</td>\n",
       "      <td>0.018732</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.028326</td>\n",
       "      <td>0.297159</td>\n",
       "      <td>0.301842</td>\n",
       "      <td>0.026459</td>\n",
       "      <td>0.188127</td>\n",
       "      <td>0.179560</td>\n",
       "      <td>0.108340</td>\n",
       "      <td>0.088181</td>\n",
       "      <td>0.034580</td>\n",
       "      <td>0.072033</td>\n",
       "      <td>0.075796</td>\n",
       "      <td>0.313643</td>\n",
       "      <td>0.341272</td>\n",
       "      <td>0.360717</td>\n",
       "      <td>0.218232</td>\n",
       "      <td>0.225236</td>\n",
       "      <td>0.225425</td>\n",
       "      <td>0.054785</td>\n",
       "      <td>0.065533</td>\n",
       "      <td>0.068412</td>\n",
       "      <td>0.305280</td>\n",
       "      <td>0.333755</td>\n",
       "      <td>0.324026</td>\n",
       "      <td>0.326616</td>\n",
       "      <td>0.200865</td>\n",
       "      <td>0.212468</td>\n",
       "      <td>0.062537</td>\n",
       "      <td>0.086733</td>\n",
       "      <td>0.314650</td>\n",
       "      <td>0.357311</td>\n",
       "      <td>0.182485</td>\n",
       "      <td>0.354006</td>\n",
       "      <td>0.363207</td>\n",
       "      <td>0.208562</td>\n",
       "      <td>0.080367</td>\n",
       "      <td>0.330099</td>\n",
       "      <td>0.350444</td>\n",
       "      <td>0.316384</td>\n",
       "      <td>0.307910</td>\n",
       "      <td>0.319654</td>\n",
       "      <td>0.312045</td>\n",
       "      <td>0.357342</td>\n",
       "      <td>0.377242</td>\n",
       "      <td>0.388055</td>\n",
       "      <td>0.376183</td>\n",
       "      <td>0.364571</td>\n",
       "      <td>0.399283</td>\n",
       "      <td>0.376666</td>\n",
       "      <td>0.395585</td>\n",
       "      <td>0.379114</td>\n",
       "      <td>0.368636</td>\n",
       "      <td>0.404541</td>\n",
       "      <td>0.199905</td>\n",
       "      <td>0.360778</td>\n",
       "      <td>0.349618</td>\n",
       "      <td>0.365216</td>\n",
       "      <td>0.329638</td>\n",
       "      <td>0.324231</td>\n",
       "      <td>0.358141</td>\n",
       "      <td>0.293239</td>\n",
       "      <td>0.333687</td>\n",
       "      <td>0.319579</td>\n",
       "      <td>0.032141</td>\n",
       "      <td>0.028974</td>\n",
       "      <td>0.026259</td>\n",
       "      <td>0.027709</td>\n",
       "      <td>0.021019</td>\n",
       "      <td>0.013752</td>\n",
       "      <td>0.344220</td>\n",
       "      <td>0.120726</td>\n",
       "      <td>0.069148</td>\n",
       "      <td>0.020209</td>\n",
       "      <td>0.010214</td>\n",
       "      <td>0.016767</td>\n",
       "      <td>0.011599</td>\n",
       "      <td>0.019221</td>\n",
       "      <td>0.030466</td>\n",
       "      <td>0.372728</td>\n",
       "      <td>0.007717</td>\n",
       "      <td>0.004344</td>\n",
       "      <td>0.005206</td>\n",
       "      <td>0.007627</td>\n",
       "      <td>0.010743</td>\n",
       "      <td>0.020880</td>\n",
       "      <td>0.029059</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>0.397618</td>\n",
       "      <td>0.011852</td>\n",
       "      <td>0.008144</td>\n",
       "      <td>0.007124</td>\n",
       "      <td>0.010496</td>\n",
       "      <td>0.013375</td>\n",
       "      <td>0.024064</td>\n",
       "      <td>0.018312</td>\n",
       "      <td>0.003850</td>\n",
       "      <td>0.375786</td>\n",
       "      <td>0.019396</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.014346</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>0.025493</td>\n",
       "      <td>0.003207</td>\n",
       "      <td>0.354078</td>\n",
       "      <td>0.012240</td>\n",
       "      <td>0.013955</td>\n",
       "      <td>0.008553</td>\n",
       "      <td>0.008852</td>\n",
       "      <td>0.008487</td>\n",
       "      <td>0.027777</td>\n",
       "      <td>0.004354</td>\n",
       "      <td>0.358456</td>\n",
       "      <td>0.009738</td>\n",
       "      <td>0.012181</td>\n",
       "      <td>0.013710</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.027058</td>\n",
       "      <td>0.000387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.921288</td>\n",
       "      <td>0.881543</td>\n",
       "      <td>0.850451</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.318260</td>\n",
       "      <td>0.136266</td>\n",
       "      <td>0.145508</td>\n",
       "      <td>0.181863</td>\n",
       "      <td>0.180267</td>\n",
       "      <td>0.012578</td>\n",
       "      <td>0.959864</td>\n",
       "      <td>0.356188</td>\n",
       "      <td>0.846941</td>\n",
       "      <td>0.797573</td>\n",
       "      <td>0.966238</td>\n",
       "      <td>0.889393</td>\n",
       "      <td>0.837271</td>\n",
       "      <td>0.786326</td>\n",
       "      <td>0.485722</td>\n",
       "      <td>0.504247</td>\n",
       "      <td>0.562120</td>\n",
       "      <td>0.493596</td>\n",
       "      <td>0.458161</td>\n",
       "      <td>0.445490</td>\n",
       "      <td>0.267979</td>\n",
       "      <td>0.276361</td>\n",
       "      <td>0.795792</td>\n",
       "      <td>0.243118</td>\n",
       "      <td>0.305165</td>\n",
       "      <td>0.141413</td>\n",
       "      <td>0.151982</td>\n",
       "      <td>0.193037</td>\n",
       "      <td>0.190496</td>\n",
       "      <td>0.892253</td>\n",
       "      <td>0.924654</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.921288</td>\n",
       "      <td>0.881543</td>\n",
       "      <td>0.850451</td>\n",
       "      <td>0.046919</td>\n",
       "      <td>0.859993</td>\n",
       "      <td>0.228162</td>\n",
       "      <td>0.313600</td>\n",
       "      <td>0.135195</td>\n",
       "      <td>0.147926</td>\n",
       "      <td>0.179010</td>\n",
       "      <td>0.185251</td>\n",
       "      <td>0.483705</td>\n",
       "      <td>0.502195</td>\n",
       "      <td>0.562853</td>\n",
       "      <td>0.503573</td>\n",
       "      <td>0.471438</td>\n",
       "      <td>0.459086</td>\n",
       "      <td>0.778165</td>\n",
       "      <td>0.378001</td>\n",
       "      <td>0.403746</td>\n",
       "      <td>0.176575</td>\n",
       "      <td>0.281871</td>\n",
       "      <td>0.299823</td>\n",
       "      <td>0.313707</td>\n",
       "      <td>0.819472</td>\n",
       "      <td>0.850675</td>\n",
       "      <td>0.901831</td>\n",
       "      <td>0.871232</td>\n",
       "      <td>0.853267</td>\n",
       "      <td>0.839787</td>\n",
       "      <td>0.072596</td>\n",
       "      <td>0.038365</td>\n",
       "      <td>0.019399</td>\n",
       "      <td>0.021667</td>\n",
       "      <td>0.100753</td>\n",
       "      <td>0.077594</td>\n",
       "      <td>0.382606</td>\n",
       "      <td>0.306763</td>\n",
       "      <td>0.355599</td>\n",
       "      <td>0.334365</td>\n",
       "      <td>0.313448</td>\n",
       "      <td>0.306184</td>\n",
       "      <td>0.186355</td>\n",
       "      <td>0.051735</td>\n",
       "      <td>0.048540</td>\n",
       "      <td>0.184473</td>\n",
       "      <td>0.109008</td>\n",
       "      <td>0.381241</td>\n",
       "      <td>0.311840</td>\n",
       "      <td>0.196637</td>\n",
       "      <td>0.354946</td>\n",
       "      <td>0.321838</td>\n",
       "      <td>0.297814</td>\n",
       "      <td>0.046870</td>\n",
       "      <td>0.022077</td>\n",
       "      <td>0.104220</td>\n",
       "      <td>0.069284</td>\n",
       "      <td>0.257956</td>\n",
       "      <td>0.275341</td>\n",
       "      <td>0.421423</td>\n",
       "      <td>0.186303</td>\n",
       "      <td>0.187362</td>\n",
       "      <td>0.189944</td>\n",
       "      <td>0.041409</td>\n",
       "      <td>0.119573</td>\n",
       "      <td>0.071053</td>\n",
       "      <td>0.279361</td>\n",
       "      <td>0.301394</td>\n",
       "      <td>0.379722</td>\n",
       "      <td>0.331571</td>\n",
       "      <td>0.192071</td>\n",
       "      <td>0.207662</td>\n",
       "      <td>0.101640</td>\n",
       "      <td>0.104782</td>\n",
       "      <td>0.289432</td>\n",
       "      <td>0.314479</td>\n",
       "      <td>0.328803</td>\n",
       "      <td>0.366762</td>\n",
       "      <td>0.377078</td>\n",
       "      <td>0.238230</td>\n",
       "      <td>0.098689</td>\n",
       "      <td>0.311366</td>\n",
       "      <td>0.322882</td>\n",
       "      <td>0.362188</td>\n",
       "      <td>0.332871</td>\n",
       "      <td>0.337762</td>\n",
       "      <td>0.323388</td>\n",
       "      <td>0.320172</td>\n",
       "      <td>0.335556</td>\n",
       "      <td>0.400121</td>\n",
       "      <td>0.377485</td>\n",
       "      <td>0.364875</td>\n",
       "      <td>0.399877</td>\n",
       "      <td>0.331028</td>\n",
       "      <td>0.395624</td>\n",
       "      <td>0.375974</td>\n",
       "      <td>0.364957</td>\n",
       "      <td>0.399598</td>\n",
       "      <td>0.300607</td>\n",
       "      <td>0.392799</td>\n",
       "      <td>0.379460</td>\n",
       "      <td>0.424518</td>\n",
       "      <td>0.352713</td>\n",
       "      <td>0.345987</td>\n",
       "      <td>0.381145</td>\n",
       "      <td>0.312240</td>\n",
       "      <td>0.354263</td>\n",
       "      <td>0.343472</td>\n",
       "      <td>0.025418</td>\n",
       "      <td>0.021934</td>\n",
       "      <td>0.025360</td>\n",
       "      <td>0.027688</td>\n",
       "      <td>0.023328</td>\n",
       "      <td>0.017628</td>\n",
       "      <td>0.317641</td>\n",
       "      <td>0.110904</td>\n",
       "      <td>0.069525</td>\n",
       "      <td>0.019948</td>\n",
       "      <td>0.008492</td>\n",
       "      <td>0.014684</td>\n",
       "      <td>0.011355</td>\n",
       "      <td>0.019287</td>\n",
       "      <td>0.031007</td>\n",
       "      <td>0.340015</td>\n",
       "      <td>0.009362</td>\n",
       "      <td>0.011263</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>0.007031</td>\n",
       "      <td>0.011146</td>\n",
       "      <td>0.021074</td>\n",
       "      <td>0.029608</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>0.370241</td>\n",
       "      <td>0.013633</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>0.006597</td>\n",
       "      <td>0.011789</td>\n",
       "      <td>0.013754</td>\n",
       "      <td>0.024633</td>\n",
       "      <td>0.017834</td>\n",
       "      <td>0.003686</td>\n",
       "      <td>0.379256</td>\n",
       "      <td>0.019565</td>\n",
       "      <td>0.011682</td>\n",
       "      <td>0.004370</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.015281</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.023614</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.359443</td>\n",
       "      <td>0.024206</td>\n",
       "      <td>0.010792</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>0.006956</td>\n",
       "      <td>0.013458</td>\n",
       "      <td>0.026952</td>\n",
       "      <td>0.004257</td>\n",
       "      <td>0.359092</td>\n",
       "      <td>0.021019</td>\n",
       "      <td>0.009520</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.006865</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.026467</td>\n",
       "      <td>0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_6_4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>0.000388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_6_5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_6_6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.000235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_6_7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAY_6_8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows  207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           LIMIT_BAL       AGE  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  \\\n",
       "LIMIT_BAL        NaN  0.146964   0.295659   0.288841   0.288696   0.299262   \n",
       "AGE              NaN       NaN   0.058995   0.056343   0.055082   0.052860   \n",
       "BILL_AMT1        NaN       NaN        NaN   0.954453   0.892254   0.864993   \n",
       "BILL_AMT2        NaN       NaN        NaN        NaN   0.924654   0.893372   \n",
       "BILL_AMT3        NaN       NaN        NaN        NaN        NaN   0.921288   \n",
       "...              ...       ...        ...        ...        ...        ...   \n",
       "PAY_6_4          NaN       NaN        NaN        NaN        NaN        NaN   \n",
       "PAY_6_5          NaN       NaN        NaN        NaN        NaN        NaN   \n",
       "PAY_6_6          NaN       NaN        NaN        NaN        NaN        NaN   \n",
       "PAY_6_7          NaN       NaN        NaN        NaN        NaN        NaN   \n",
       "PAY_6_8          NaN       NaN        NaN        NaN        NaN        NaN   \n",
       "\n",
       "           BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  \\\n",
       "LIMIT_BAL   0.299236   0.294636  0.196075  0.165682  0.211372  0.199648   \n",
       "AGE         0.051109   0.048705  0.026827  0.019959  0.030200  0.018125   \n",
       "BILL_AMT1   0.835076   0.805479  0.148222  0.095717  0.166570  0.161754   \n",
       "BILL_AMT2   0.860374   0.830698  0.278827  0.099033  0.159873  0.150938   \n",
       "BILL_AMT3   0.881543   0.850451  0.234043  0.318260  0.136266  0.145508   \n",
       "...              ...        ...       ...       ...       ...       ...   \n",
       "PAY_6_4          NaN        NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_5          NaN        NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_6          NaN        NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_7          NaN        NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_8          NaN        NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "           PAY_AMT5  PAY_AMT6   default  avg_bill   avg_pay      out1  \\\n",
       "LIMIT_BAL  0.216146  0.224594  0.155958  0.309080  0.343312  0.253961   \n",
       "AGE        0.023779  0.019674  0.014586  0.056863  0.039428  0.053443   \n",
       "BILL_AMT1  0.174668  0.172586  0.016858  0.942806  0.256331  0.974899   \n",
       "BILL_AMT2  0.162069  0.170157  0.011762  0.961202  0.283571  0.899572   \n",
       "BILL_AMT3  0.181863  0.180267  0.012578  0.959864  0.356188  0.846941   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "PAY_6_4         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_5         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_6         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_7         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_8         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "               out2      out3      out4      out5      out6      per1  \\\n",
       "LIMIT_BAL  0.227156  0.234207  0.251301  0.244805  0.224505  0.363611   \n",
       "AGE        0.048411  0.047321  0.048618  0.045165  0.042270  0.026934   \n",
       "BILL_AMT1  0.900525  0.850430  0.828845  0.792527  0.744198  0.563137   \n",
       "BILL_AMT2  0.943914  0.884626  0.860016  0.821101  0.769813  0.530678   \n",
       "BILL_AMT3  0.797573  0.966238  0.889393  0.837271  0.786326  0.485722   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "PAY_6_4         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_5         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_6         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_7         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_8         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "               per2      per3      per4      per5      per6  LIMIT_BAL^2  \\\n",
       "LIMIT_BAL  0.367210  0.357129  0.351012  0.337173  0.318580     0.944200   \n",
       "AGE        0.030858  0.036442  0.051097  0.052280  0.051160     0.138273   \n",
       "BILL_AMT1  0.514426  0.465563  0.434497  0.406770  0.394430     0.275482   \n",
       "BILL_AMT2  0.560388  0.499078  0.465249  0.434277  0.421363     0.268179   \n",
       "BILL_AMT3  0.504247  0.562120  0.493596  0.458161  0.445490     0.267979   \n",
       "...             ...       ...       ...       ...       ...          ...   \n",
       "PAY_6_4         NaN       NaN       NaN       NaN       NaN          NaN   \n",
       "PAY_6_5         NaN       NaN       NaN       NaN       NaN          NaN   \n",
       "PAY_6_6         NaN       NaN       NaN       NaN       NaN          NaN   \n",
       "PAY_6_7         NaN       NaN       NaN       NaN       NaN          NaN   \n",
       "PAY_6_8         NaN       NaN       NaN       NaN       NaN          NaN   \n",
       "\n",
       "           LIMIT_BAL AGE  LIMIT_BAL BILL_AMT1  LIMIT_BAL PAY_AMT1  \\\n",
       "LIMIT_BAL       0.942585             0.457971            0.294216   \n",
       "AGE             0.385628             0.074775            0.043212   \n",
       "BILL_AMT1       0.283329             0.892175            0.175578   \n",
       "BILL_AMT2       0.276458             0.852679            0.284739   \n",
       "BILL_AMT3       0.276361             0.795792            0.243118   \n",
       "...                  ...                  ...                 ...   \n",
       "PAY_6_4              NaN                  NaN                 NaN   \n",
       "PAY_6_5              NaN                  NaN                 NaN   \n",
       "PAY_6_6              NaN                  NaN                 NaN   \n",
       "PAY_6_7              NaN                  NaN                 NaN   \n",
       "PAY_6_8              NaN                  NaN                 NaN   \n",
       "\n",
       "           LIMIT_BAL PAY_AMT2  LIMIT_BAL PAY_AMT3  LIMIT_BAL PAY_AMT4  \\\n",
       "LIMIT_BAL            0.211126            0.234115            0.271608   \n",
       "AGE                  0.027186            0.040229            0.031857   \n",
       "BILL_AMT1            0.096436            0.172558            0.166005   \n",
       "BILL_AMT2            0.105608            0.169906            0.155139   \n",
       "BILL_AMT3            0.305165            0.141413            0.151982   \n",
       "...                       ...                 ...                 ...   \n",
       "PAY_6_4                   NaN                 NaN                 NaN   \n",
       "PAY_6_5                   NaN                 NaN                 NaN   \n",
       "PAY_6_6                   NaN                 NaN                 NaN   \n",
       "PAY_6_7                   NaN                 NaN                 NaN   \n",
       "PAY_6_8                   NaN                 NaN                 NaN   \n",
       "\n",
       "           LIMIT_BAL PAY_AMT5  LIMIT_BAL PAY_AMT6  LIMIT_BAL per1  \\\n",
       "LIMIT_BAL            0.297079            0.288880        0.295659   \n",
       "AGE                  0.040136            0.032290        0.058996   \n",
       "BILL_AMT1            0.182404            0.179571        1.000000   \n",
       "BILL_AMT2            0.167664            0.175930        0.954453   \n",
       "BILL_AMT3            0.193037            0.190496        0.892253   \n",
       "...                       ...                 ...             ...   \n",
       "PAY_6_4                   NaN                 NaN             NaN   \n",
       "PAY_6_5                   NaN                 NaN             NaN   \n",
       "PAY_6_6                   NaN                 NaN             NaN   \n",
       "PAY_6_7                   NaN                 NaN             NaN   \n",
       "PAY_6_8                   NaN                 NaN             NaN   \n",
       "\n",
       "           LIMIT_BAL per2  LIMIT_BAL per3  LIMIT_BAL per4  LIMIT_BAL per5  \\\n",
       "LIMIT_BAL        0.288841        0.288695        0.299262        0.299236   \n",
       "AGE              0.056343        0.055083        0.052860        0.051109   \n",
       "BILL_AMT1        0.954452        0.892253        0.864993        0.835077   \n",
       "BILL_AMT2        1.000000        0.924654        0.893372        0.860374   \n",
       "BILL_AMT3        0.924654        1.000000        0.921288        0.881543   \n",
       "...                   ...             ...             ...             ...   \n",
       "PAY_6_4               NaN             NaN             NaN             NaN   \n",
       "PAY_6_5               NaN             NaN             NaN             NaN   \n",
       "PAY_6_6               NaN             NaN             NaN             NaN   \n",
       "PAY_6_7               NaN             NaN             NaN             NaN   \n",
       "PAY_6_8               NaN             NaN             NaN             NaN   \n",
       "\n",
       "           LIMIT_BAL per6     AGE^2  AGE BILL_AMT1  AGE PAY_AMT1  \\\n",
       "LIMIT_BAL        0.294637  0.115574       0.298576      0.199462   \n",
       "AGE              0.048706  0.989490       0.208651      0.097894   \n",
       "BILL_AMT1        0.805479  0.050446       0.961785      0.149431   \n",
       "BILL_AMT2        0.830698  0.047926       0.917411      0.272370   \n",
       "BILL_AMT3        0.850451  0.046919       0.859993      0.228162   \n",
       "...                   ...       ...            ...           ...   \n",
       "PAY_6_4               NaN       NaN            NaN           NaN   \n",
       "PAY_6_5               NaN       NaN            NaN           NaN   \n",
       "PAY_6_6               NaN       NaN            NaN           NaN   \n",
       "PAY_6_7               NaN       NaN            NaN           NaN   \n",
       "PAY_6_8               NaN       NaN            NaN           NaN   \n",
       "\n",
       "           AGE PAY_AMT2  AGE PAY_AMT3  AGE PAY_AMT4  AGE PAY_AMT5  \\\n",
       "LIMIT_BAL      0.173972      0.210451      0.210728      0.223393   \n",
       "AGE            0.072019      0.087655      0.082535      0.091657   \n",
       "BILL_AMT1      0.102301      0.167965      0.163725      0.173984   \n",
       "BILL_AMT2      0.103477      0.160636      0.153791      0.161836   \n",
       "BILL_AMT3      0.313600      0.135195      0.147926      0.179010   \n",
       "...                 ...           ...           ...           ...   \n",
       "PAY_6_4             NaN           NaN           NaN           NaN   \n",
       "PAY_6_5             NaN           NaN           NaN           NaN   \n",
       "PAY_6_6             NaN           NaN           NaN           NaN   \n",
       "PAY_6_7             NaN           NaN           NaN           NaN   \n",
       "PAY_6_8             NaN           NaN           NaN           NaN   \n",
       "\n",
       "           AGE PAY_AMT6  AGE per1  AGE per2  AGE per3  AGE per4  AGE per5  \\\n",
       "LIMIT_BAL      0.229342  0.307870  0.312513  0.305550  0.299329  0.287790   \n",
       "AGE            0.080935  0.248281  0.241658  0.230923  0.215988  0.208595   \n",
       "BILL_AMT1      0.176371  0.558918  0.513735  0.473381  0.449089  0.423683   \n",
       "BILL_AMT2      0.174519  0.526488  0.556147  0.503981  0.477553  0.449317   \n",
       "BILL_AMT3      0.185251  0.483705  0.502195  0.562853  0.503573  0.471438   \n",
       "...                 ...       ...       ...       ...       ...       ...   \n",
       "PAY_6_4             NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_5             NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_6             NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_7             NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_8             NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "           AGE per6  BILL_AMT1^2  BILL_AMT1 PAY_AMT1  BILL_AMT1 PAY_AMT2  \\\n",
       "LIMIT_BAL  0.272520     0.334041            0.190743            0.185277   \n",
       "AGE        0.202488     0.069892            0.034149            0.034974   \n",
       "BILL_AMT1  0.411444     0.880237            0.411059            0.375155   \n",
       "BILL_AMT2  0.436643     0.841187            0.417411            0.346921   \n",
       "BILL_AMT3  0.459086     0.778165            0.378001            0.403746   \n",
       "...             ...          ...                 ...                 ...   \n",
       "PAY_6_4         NaN          NaN                 NaN                 NaN   \n",
       "PAY_6_5         NaN          NaN                 NaN                 NaN   \n",
       "PAY_6_6         NaN          NaN                 NaN                 NaN   \n",
       "PAY_6_7         NaN          NaN                 NaN                 NaN   \n",
       "PAY_6_8         NaN          NaN                 NaN                 NaN   \n",
       "\n",
       "           BILL_AMT1 PAY_AMT3  BILL_AMT1 PAY_AMT4  BILL_AMT1 PAY_AMT5  \\\n",
       "LIMIT_BAL            0.116389            0.151088            0.167601   \n",
       "AGE                  0.023819            0.015084            0.021763   \n",
       "BILL_AMT1            0.238614            0.330237            0.361902   \n",
       "BILL_AMT2            0.227662            0.307165            0.329245   \n",
       "BILL_AMT3            0.176575            0.281871            0.299823   \n",
       "...                       ...                 ...                 ...   \n",
       "PAY_6_4                   NaN                 NaN                 NaN   \n",
       "PAY_6_5                   NaN                 NaN                 NaN   \n",
       "PAY_6_6                   NaN                 NaN                 NaN   \n",
       "PAY_6_7                   NaN                 NaN                 NaN   \n",
       "PAY_6_8                   NaN                 NaN                 NaN   \n",
       "\n",
       "           BILL_AMT1 PAY_AMT6  BILL_AMT1 per1  BILL_AMT1 per2  BILL_AMT1 per3  \\\n",
       "LIMIT_BAL            0.163045        0.171639        0.166834        0.163798   \n",
       "AGE                  0.023917        0.058934        0.055922        0.056278   \n",
       "BILL_AMT1            0.354387        0.930550        0.912840        0.893141   \n",
       "BILL_AMT2            0.331639        0.885826        0.923404        0.899075   \n",
       "BILL_AMT3            0.313707        0.819472        0.850675        0.901831   \n",
       "...                       ...             ...             ...             ...   \n",
       "PAY_6_4                   NaN             NaN             NaN             NaN   \n",
       "PAY_6_5                   NaN             NaN             NaN             NaN   \n",
       "PAY_6_6                   NaN             NaN             NaN             NaN   \n",
       "PAY_6_7                   NaN             NaN             NaN             NaN   \n",
       "PAY_6_8                   NaN             NaN             NaN             NaN   \n",
       "\n",
       "           BILL_AMT1 per4  BILL_AMT1 per5  BILL_AMT1 per6  PAY_AMT1^2  \\\n",
       "LIMIT_BAL        0.169347        0.171775        0.170501    0.055390   \n",
       "AGE              0.051882        0.051421        0.048372    0.010941   \n",
       "BILL_AMT1        0.873738        0.858373        0.846376    0.026023   \n",
       "BILL_AMT2        0.880560        0.864230        0.853090    0.097818   \n",
       "BILL_AMT3        0.871232        0.853267        0.839787    0.072596   \n",
       "...                   ...             ...             ...         ...   \n",
       "PAY_6_4               NaN             NaN             NaN         NaN   \n",
       "PAY_6_5               NaN             NaN             NaN         NaN   \n",
       "PAY_6_6               NaN             NaN             NaN         NaN   \n",
       "PAY_6_7               NaN             NaN             NaN         NaN   \n",
       "PAY_6_8               NaN             NaN             NaN         NaN   \n",
       "\n",
       "           PAY_AMT1 PAY_AMT2  PAY_AMT1 PAY_AMT3  PAY_AMT1 PAY_AMT4  \\\n",
       "LIMIT_BAL           0.028405           0.032119           0.031477   \n",
       "AGE                 0.004637           0.007277           0.007064   \n",
       "BILL_AMT1           0.013650           0.025290           0.026592   \n",
       "BILL_AMT2           0.040565           0.038027           0.035341   \n",
       "BILL_AMT3           0.038365           0.019399           0.021667   \n",
       "...                      ...                ...                ...   \n",
       "PAY_6_4                  NaN                NaN                NaN   \n",
       "PAY_6_5                  NaN                NaN                NaN   \n",
       "PAY_6_6                  NaN                NaN                NaN   \n",
       "PAY_6_7                  NaN                NaN                NaN   \n",
       "PAY_6_8                  NaN                NaN                NaN   \n",
       "\n",
       "           PAY_AMT1 PAY_AMT5  PAY_AMT1 PAY_AMT6  PAY_AMT1 per1  PAY_AMT1 per2  \\\n",
       "LIMIT_BAL           0.109325           0.080031       0.090972       0.078030   \n",
       "AGE                 0.013443           0.014726       0.024772       0.016233   \n",
       "BILL_AMT1           0.073329           0.055582       0.411566       0.220920   \n",
       "BILL_AMT2           0.114293           0.096998       0.422237       0.352566   \n",
       "BILL_AMT3           0.100753           0.077594       0.382606       0.306763   \n",
       "...                      ...                ...            ...            ...   \n",
       "PAY_6_4                  NaN                NaN            NaN            NaN   \n",
       "PAY_6_5                  NaN                NaN            NaN            NaN   \n",
       "PAY_6_6                  NaN                NaN            NaN            NaN   \n",
       "PAY_6_7                  NaN                NaN            NaN            NaN   \n",
       "PAY_6_8                  NaN                NaN            NaN            NaN   \n",
       "\n",
       "           PAY_AMT1 per3  PAY_AMT1 per4  PAY_AMT1 per5  PAY_AMT1 per6  \\\n",
       "LIMIT_BAL       0.073503       0.078012       0.075631       0.075221   \n",
       "AGE             0.013461       0.016452       0.016991       0.015043   \n",
       "BILL_AMT1       0.224801       0.240872       0.229029       0.224735   \n",
       "BILL_AMT2       0.342966       0.337979       0.319993       0.315806   \n",
       "BILL_AMT3       0.355599       0.334365       0.313448       0.306184   \n",
       "...                  ...            ...            ...            ...   \n",
       "PAY_6_4              NaN            NaN            NaN            NaN   \n",
       "PAY_6_5              NaN            NaN            NaN            NaN   \n",
       "PAY_6_6              NaN            NaN            NaN            NaN   \n",
       "PAY_6_7              NaN            NaN            NaN            NaN   \n",
       "PAY_6_8              NaN            NaN            NaN            NaN   \n",
       "\n",
       "           PAY_AMT2^2  PAY_AMT2 PAY_AMT3  PAY_AMT2 PAY_AMT4  \\\n",
       "LIMIT_BAL    0.039177           0.031239           0.027028   \n",
       "AGE          0.002127           0.006309           0.005862   \n",
       "BILL_AMT1    0.006223           0.018719           0.016851   \n",
       "BILL_AMT2    0.017507           0.027013           0.018732   \n",
       "BILL_AMT3    0.186355           0.051735           0.048540   \n",
       "...               ...                ...                ...   \n",
       "PAY_6_4           NaN                NaN                NaN   \n",
       "PAY_6_5           NaN                NaN                NaN   \n",
       "PAY_6_6           NaN                NaN                NaN   \n",
       "PAY_6_7           NaN                NaN                NaN   \n",
       "PAY_6_8           NaN                NaN                NaN   \n",
       "\n",
       "           PAY_AMT2 PAY_AMT5  PAY_AMT2 PAY_AMT6  PAY_AMT2 per1  PAY_AMT2 per2  \\\n",
       "LIMIT_BAL           0.034074           0.079128       0.075886       0.075680   \n",
       "AGE                 0.000955           0.013576       0.023894       0.017622   \n",
       "BILL_AMT1           0.007917           0.028163       0.331482       0.255554   \n",
       "BILL_AMT2           0.003900           0.028326       0.297159       0.301842   \n",
       "BILL_AMT3           0.184473           0.109008       0.381241       0.311840   \n",
       "...                      ...                ...            ...            ...   \n",
       "PAY_6_4                  NaN                NaN            NaN            NaN   \n",
       "PAY_6_5                  NaN                NaN            NaN            NaN   \n",
       "PAY_6_6                  NaN                NaN            NaN            NaN   \n",
       "PAY_6_7                  NaN                NaN            NaN            NaN   \n",
       "PAY_6_8                  NaN                NaN            NaN            NaN   \n",
       "\n",
       "           PAY_AMT2 per3  PAY_AMT2 per4  PAY_AMT2 per5  PAY_AMT2 per6  \\\n",
       "LIMIT_BAL       0.020009       0.094053       0.085740       0.052753   \n",
       "AGE             0.002333       0.012828       0.015031       0.008198   \n",
       "BILL_AMT1       0.028257       0.186342       0.177915       0.108446   \n",
       "BILL_AMT2       0.026459       0.188127       0.179560       0.108340   \n",
       "BILL_AMT3       0.196637       0.354946       0.321838       0.297814   \n",
       "...                  ...            ...            ...            ...   \n",
       "PAY_6_4              NaN            NaN            NaN            NaN   \n",
       "PAY_6_5              NaN            NaN            NaN            NaN   \n",
       "PAY_6_6              NaN            NaN            NaN            NaN   \n",
       "PAY_6_7              NaN            NaN            NaN            NaN   \n",
       "PAY_6_8              NaN            NaN            NaN            NaN   \n",
       "\n",
       "           PAY_AMT3^2  PAY_AMT3 PAY_AMT4  PAY_AMT3 PAY_AMT5  \\\n",
       "LIMIT_BAL    0.079100           0.038340           0.110562   \n",
       "AGE          0.017160           0.008845           0.014913   \n",
       "BILL_AMT1    0.088587           0.034045           0.080910   \n",
       "BILL_AMT2    0.088181           0.034580           0.072033   \n",
       "BILL_AMT3    0.046870           0.022077           0.104220   \n",
       "...               ...                ...                ...   \n",
       "PAY_6_4           NaN                NaN                NaN   \n",
       "PAY_6_5           NaN                NaN                NaN   \n",
       "PAY_6_6           NaN                NaN                NaN   \n",
       "PAY_6_7           NaN                NaN                NaN   \n",
       "PAY_6_8           NaN                NaN                NaN   \n",
       "\n",
       "           PAY_AMT3 PAY_AMT6  PAY_AMT3 per1  PAY_AMT3 per2  PAY_AMT3 per3  \\\n",
       "LIMIT_BAL           0.097425       0.096016       0.094908       0.112270   \n",
       "AGE                 0.017477       0.022746       0.021761       0.023132   \n",
       "BILL_AMT1           0.077891       0.339820       0.320124       0.345826   \n",
       "BILL_AMT2           0.075796       0.313643       0.341272       0.360717   \n",
       "BILL_AMT3           0.069284       0.257956       0.275341       0.421423   \n",
       "...                      ...            ...            ...            ...   \n",
       "PAY_6_4                  NaN            NaN            NaN            NaN   \n",
       "PAY_6_5                  NaN            NaN            NaN            NaN   \n",
       "PAY_6_6                  NaN            NaN            NaN            NaN   \n",
       "PAY_6_7                  NaN            NaN            NaN            NaN   \n",
       "PAY_6_8                  NaN            NaN            NaN            NaN   \n",
       "\n",
       "           PAY_AMT3 per4  PAY_AMT3 per5  PAY_AMT3 per6  PAY_AMT4^2  \\\n",
       "LIMIT_BAL       0.106460       0.098617       0.097327    0.082141   \n",
       "AGE             0.018485       0.016608       0.014653    0.002984   \n",
       "BILL_AMT1       0.222035       0.230300       0.223244    0.061487   \n",
       "BILL_AMT2       0.218232       0.225236       0.225425    0.054785   \n",
       "BILL_AMT3       0.186303       0.187362       0.189944    0.041409   \n",
       "...                  ...            ...            ...         ...   \n",
       "PAY_6_4              NaN            NaN            NaN         NaN   \n",
       "PAY_6_5              NaN            NaN            NaN         NaN   \n",
       "PAY_6_6              NaN            NaN            NaN         NaN   \n",
       "PAY_6_7              NaN            NaN            NaN         NaN   \n",
       "PAY_6_8              NaN            NaN            NaN         NaN   \n",
       "\n",
       "           PAY_AMT4 PAY_AMT5  PAY_AMT4 PAY_AMT6  PAY_AMT4 per1  PAY_AMT4 per2  \\\n",
       "LIMIT_BAL           0.119093           0.106022       0.076233       0.074689   \n",
       "AGE                 0.015452           0.015007       0.003682       0.006300   \n",
       "BILL_AMT1           0.084578           0.080427       0.329690       0.322576   \n",
       "BILL_AMT2           0.065533           0.068412       0.305280       0.333755   \n",
       "BILL_AMT3           0.119573           0.071053       0.279361       0.301394   \n",
       "...                      ...                ...            ...            ...   \n",
       "PAY_6_4                  NaN                NaN            NaN            NaN   \n",
       "PAY_6_5                  NaN                NaN            NaN            NaN   \n",
       "PAY_6_6                  NaN                NaN            NaN            NaN   \n",
       "PAY_6_7                  NaN                NaN            NaN            NaN   \n",
       "PAY_6_8                  NaN                NaN            NaN            NaN   \n",
       "\n",
       "           PAY_AMT4 per3  PAY_AMT4 per4  PAY_AMT4 per5  PAY_AMT4 per6  \\\n",
       "LIMIT_BAL       0.080390       0.094313       0.089594       0.088009   \n",
       "AGE             0.005695       0.010536       0.003056       0.002330   \n",
       "BILL_AMT1       0.317617       0.321166       0.205528       0.214957   \n",
       "BILL_AMT2       0.324026       0.326616       0.200865       0.212468   \n",
       "BILL_AMT3       0.379722       0.331571       0.192071       0.207662   \n",
       "...                  ...            ...            ...            ...   \n",
       "PAY_6_4              NaN            NaN            NaN            NaN   \n",
       "PAY_6_5              NaN            NaN            NaN            NaN   \n",
       "PAY_6_6              NaN            NaN            NaN            NaN   \n",
       "PAY_6_7              NaN            NaN            NaN            NaN   \n",
       "PAY_6_8              NaN            NaN            NaN            NaN   \n",
       "\n",
       "           PAY_AMT5^2  PAY_AMT5 PAY_AMT6  PAY_AMT5 per1  PAY_AMT5 per2  \\\n",
       "LIMIT_BAL    0.105786           0.130070       0.082259       0.078864   \n",
       "AGE          0.010572           0.019012       0.011232       0.010243   \n",
       "BILL_AMT1    0.084540           0.092018       0.343533       0.336848   \n",
       "BILL_AMT2    0.062537           0.086733       0.314650       0.357311   \n",
       "BILL_AMT3    0.101640           0.104782       0.289432       0.314479   \n",
       "...               ...                ...            ...            ...   \n",
       "PAY_6_4           NaN                NaN            NaN            NaN   \n",
       "PAY_6_5           NaN                NaN            NaN            NaN   \n",
       "PAY_6_6           NaN                NaN            NaN            NaN   \n",
       "PAY_6_7           NaN                NaN            NaN            NaN   \n",
       "PAY_6_8           NaN                NaN            NaN            NaN   \n",
       "\n",
       "           PAY_AMT5 per3  PAY_AMT5 per4  PAY_AMT5 per5  PAY_AMT5 per6  \\\n",
       "LIMIT_BAL       0.051596       0.097408       0.105280       0.096949   \n",
       "AGE             0.005696       0.011987       0.020058       0.008030   \n",
       "BILL_AMT1       0.179771       0.344175       0.355705       0.217894   \n",
       "BILL_AMT2       0.182485       0.354006       0.363207       0.208562   \n",
       "BILL_AMT3       0.328803       0.366762       0.377078       0.238230   \n",
       "...                  ...            ...            ...            ...   \n",
       "PAY_6_4              NaN            NaN            NaN            NaN   \n",
       "PAY_6_5              NaN            NaN            NaN            NaN   \n",
       "PAY_6_6              NaN            NaN            NaN            NaN   \n",
       "PAY_6_7              NaN            NaN            NaN            NaN   \n",
       "PAY_6_8              NaN            NaN            NaN            NaN   \n",
       "\n",
       "           PAY_AMT6^2  PAY_AMT6 per1  PAY_AMT6 per2  PAY_AMT6 per3  \\\n",
       "LIMIT_BAL    0.108208       0.095303       0.092620       0.099153   \n",
       "AGE          0.009263       0.014636       0.017688       0.017981   \n",
       "BILL_AMT1    0.078649       0.352254       0.328955       0.303964   \n",
       "BILL_AMT2    0.080367       0.330099       0.350444       0.316384   \n",
       "BILL_AMT3    0.098689       0.311366       0.322882       0.362188   \n",
       "...               ...            ...            ...            ...   \n",
       "PAY_6_4           NaN            NaN            NaN            NaN   \n",
       "PAY_6_5           NaN            NaN            NaN            NaN   \n",
       "PAY_6_6           NaN            NaN            NaN            NaN   \n",
       "PAY_6_7           NaN            NaN            NaN            NaN   \n",
       "PAY_6_8           NaN            NaN            NaN            NaN   \n",
       "\n",
       "           PAY_AMT6 per4  PAY_AMT6 per5  PAY_AMT6 per6    per1^2  per1 per2  \\\n",
       "LIMIT_BAL       0.103182       0.106545       0.097486  0.238557   0.239503   \n",
       "AGE             0.017935       0.017944       0.018001  0.000595   0.003134   \n",
       "BILL_AMT1       0.296327       0.309282       0.299653  0.382612   0.367453   \n",
       "BILL_AMT2       0.307910       0.319654       0.312045  0.357342   0.377242   \n",
       "BILL_AMT3       0.332871       0.337762       0.323388  0.320172   0.335556   \n",
       "...                  ...            ...            ...       ...        ...   \n",
       "PAY_6_4              NaN            NaN            NaN       NaN        NaN   \n",
       "PAY_6_5              NaN            NaN            NaN       NaN        NaN   \n",
       "PAY_6_6              NaN            NaN            NaN       NaN        NaN   \n",
       "PAY_6_7              NaN            NaN            NaN       NaN        NaN   \n",
       "PAY_6_8              NaN            NaN            NaN       NaN        NaN   \n",
       "\n",
       "           per1 per3  per1 per4  per1 per5  per1 per6    per2^2  per2 per3  \\\n",
       "LIMIT_BAL   0.259073   0.256752   0.248933   0.261696  0.243438   0.265211   \n",
       "AGE         0.011161   0.023017   0.024083   0.026448  0.005388   0.014809   \n",
       "BILL_AMT1   0.381581   0.368841   0.358335   0.392431  0.342046   0.362978   \n",
       "BILL_AMT2   0.388055   0.376183   0.364571   0.399283  0.376666   0.395585   \n",
       "BILL_AMT3   0.400121   0.377485   0.364875   0.399877  0.331028   0.395624   \n",
       "...              ...        ...        ...        ...       ...        ...   \n",
       "PAY_6_4          NaN        NaN        NaN        NaN       NaN        NaN   \n",
       "PAY_6_5          NaN        NaN        NaN        NaN       NaN        NaN   \n",
       "PAY_6_6          NaN        NaN        NaN        NaN       NaN        NaN   \n",
       "PAY_6_7          NaN        NaN        NaN        NaN       NaN        NaN   \n",
       "PAY_6_8          NaN        NaN        NaN        NaN       NaN        NaN   \n",
       "\n",
       "           per2 per4  per2 per5  per2 per6    per3^2  per3 per4  per3 per5  \\\n",
       "LIMIT_BAL   0.261068   0.253307   0.267524  0.152239   0.270064   0.261840   \n",
       "AGE         0.024923   0.026002   0.029741  0.010470   0.030932   0.031216   \n",
       "BILL_AMT1   0.347783   0.338653   0.371877  0.188642   0.333987   0.323810   \n",
       "BILL_AMT2   0.379114   0.368636   0.404541  0.199905   0.360778   0.349618   \n",
       "BILL_AMT3   0.375974   0.364957   0.399598  0.300607   0.392799   0.379460   \n",
       "...              ...        ...        ...       ...        ...        ...   \n",
       "PAY_6_4          NaN        NaN        NaN       NaN        NaN        NaN   \n",
       "PAY_6_5          NaN        NaN        NaN       NaN        NaN        NaN   \n",
       "PAY_6_6          NaN        NaN        NaN       NaN        NaN        NaN   \n",
       "PAY_6_7          NaN        NaN        NaN       NaN        NaN        NaN   \n",
       "PAY_6_8          NaN        NaN        NaN       NaN        NaN        NaN   \n",
       "\n",
       "           per3 per6    per4^2  per4 per5  per4 per6    per5^2  per5 per6  \\\n",
       "LIMIT_BAL   0.266119  0.265682   0.258754   0.275083  0.255874   0.274933   \n",
       "AGE         0.032309  0.037320   0.037497   0.041212  0.040072   0.044338   \n",
       "BILL_AMT1   0.339460  0.305627   0.300582   0.331565  0.271970   0.309126   \n",
       "BILL_AMT2   0.365216  0.329638   0.324231   0.358141  0.293239   0.333687   \n",
       "BILL_AMT3   0.424518  0.352713   0.345987   0.381145  0.312240   0.354263   \n",
       "...              ...       ...        ...        ...       ...        ...   \n",
       "PAY_6_4          NaN       NaN        NaN        NaN       NaN        NaN   \n",
       "PAY_6_5          NaN       NaN        NaN        NaN       NaN        NaN   \n",
       "PAY_6_6          NaN       NaN        NaN        NaN       NaN        NaN   \n",
       "PAY_6_7          NaN       NaN        NaN        NaN       NaN        NaN   \n",
       "PAY_6_8          NaN       NaN        NaN        NaN       NaN        NaN   \n",
       "\n",
       "             per6^2     SEX_2  EDUCATION_2  EDUCATION_3  EDUCATION_4  \\\n",
       "LIMIT_BAL  0.277401  0.021080     0.148857     0.141774     0.010605   \n",
       "AGE        0.048511  0.093937     0.080027     0.226650     0.017191   \n",
       "BILL_AMT1  0.296519  0.037009     0.029336     0.023885     0.032840   \n",
       "BILL_AMT2  0.319579  0.032141     0.028974     0.026259     0.027709   \n",
       "BILL_AMT3  0.343472  0.025418     0.021934     0.025360     0.027688   \n",
       "...             ...       ...          ...          ...          ...   \n",
       "PAY_6_4         NaN       NaN          NaN          NaN          NaN   \n",
       "PAY_6_5         NaN       NaN          NaN          NaN          NaN   \n",
       "PAY_6_6         NaN       NaN          NaN          NaN          NaN   \n",
       "PAY_6_7         NaN       NaN          NaN          NaN          NaN   \n",
       "PAY_6_8         NaN       NaN          NaN          NaN          NaN   \n",
       "\n",
       "           MARRIAGE_2  MARRIAGE_3   PAY_1_0   PAY_1_1   PAY_1_2   PAY_1_3  \\\n",
       "LIMIT_BAL    0.089221    0.049389  0.097790  0.052475  0.134128  0.067959   \n",
       "AGE          0.468115    0.079989  0.056465  0.004277  0.002515  0.005025   \n",
       "BILL_AMT1    0.025045    0.013498  0.360850  0.125751  0.061324  0.021045   \n",
       "BILL_AMT2    0.021019    0.013752  0.344220  0.120726  0.069148  0.020209   \n",
       "BILL_AMT3    0.023328    0.017628  0.317641  0.110904  0.069525  0.019948   \n",
       "...               ...         ...       ...       ...       ...       ...   \n",
       "PAY_6_4           NaN         NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_5           NaN         NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_6           NaN         NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_7           NaN         NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_8           NaN         NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            PAY_1_4   PAY_1_5   PAY_1_6   PAY_1_7   PAY_1_8   PAY_2_0  \\\n",
       "LIMIT_BAL  0.032744  0.020340  0.010672  0.005289  0.008696  0.115974   \n",
       "AGE        0.002918  0.003397  0.007933  0.005986  0.002476  0.062726   \n",
       "BILL_AMT1  0.009327  0.016173  0.011825  0.019063  0.029410  0.382785   \n",
       "BILL_AMT2  0.010214  0.016767  0.011599  0.019221  0.030466  0.372728   \n",
       "BILL_AMT3  0.008492  0.014684  0.011355  0.019287  0.031007  0.340015   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "PAY_6_4         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_5         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_6         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_7         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_8         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            PAY_2_1   PAY_2_2   PAY_2_3   PAY_2_4   PAY_2_5   PAY_2_6  \\\n",
       "LIMIT_BAL  0.007556  0.179362  0.066706  0.041322  0.019725  0.006471   \n",
       "AGE        0.001290  0.003456  0.017519  0.008177  0.008529  0.003169   \n",
       "BILL_AMT1  0.009168  0.000428  0.007138  0.006578  0.010599  0.020365   \n",
       "BILL_AMT2  0.007717  0.004344  0.005206  0.007627  0.010743  0.020880   \n",
       "BILL_AMT3  0.009362  0.011263  0.004374  0.007031  0.011146  0.021074   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "PAY_6_4         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_5         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_6         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_7         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_8         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            PAY_2_7   PAY_2_8   PAY_3_0   PAY_3_1   PAY_3_2   PAY_3_3  \\\n",
       "LIMIT_BAL  0.010180  0.006523  0.116551  0.014678  0.174591  0.065854   \n",
       "AGE        0.006107  0.008262  0.052186  0.000647  0.020546  0.000420   \n",
       "BILL_AMT1  0.028015  0.002285  0.389920  0.011149  0.027221  0.011784   \n",
       "BILL_AMT2  0.029059  0.002205  0.397618  0.011852  0.008144  0.007124   \n",
       "BILL_AMT3  0.029608  0.002080  0.370241  0.013633  0.003988  0.006597   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "PAY_6_4         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_5         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_6         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_7         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_8         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            PAY_3_4   PAY_3_5   PAY_3_6   PAY_3_7   PAY_3_8   PAY_4_0  \\\n",
       "LIMIT_BAL  0.036510  0.009359  0.014540  0.023601  0.008499  0.110370   \n",
       "AGE        0.003983  0.002849  0.001406  0.002287  0.004646  0.062570   \n",
       "BILL_AMT1  0.007988  0.011846  0.022971  0.018897  0.004706  0.365285   \n",
       "BILL_AMT2  0.010496  0.013375  0.024064  0.018312  0.003850  0.375786   \n",
       "BILL_AMT3  0.011789  0.013754  0.024633  0.017834  0.003686  0.379256   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "PAY_6_4         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_5         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_6         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_7         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_8         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            PAY_4_1   PAY_4_2   PAY_4_3   PAY_4_4   PAY_4_5   PAY_4_6  \\\n",
       "LIMIT_BAL  0.015098  0.163705  0.057660  0.032126  0.017839  0.013668   \n",
       "AGE        0.001584  0.007832  0.006975  0.005775  0.001973  0.014603   \n",
       "BILL_AMT1  0.018819  0.016970  0.004030  0.002783  0.013285  0.004501   \n",
       "BILL_AMT2  0.019396  0.003580  0.000170  0.001006  0.014346  0.003330   \n",
       "BILL_AMT3  0.019565  0.011682  0.004370  0.000921  0.015281  0.002554   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "PAY_6_4         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_5         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_6         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_7         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_8         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            PAY_4_7   PAY_4_8   PAY_5_0   PAY_5_2   PAY_5_3   PAY_5_4  \\\n",
       "LIMIT_BAL  0.035394  0.009225  0.101661  0.154219  0.057306  0.035444   \n",
       "AGE        0.002102  0.001074  0.054778  0.020294  0.006504  0.002782   \n",
       "BILL_AMT1  0.026160  0.003294  0.343021  0.001646  0.016814  0.006194   \n",
       "BILL_AMT2  0.025493  0.003207  0.354078  0.012240  0.013955  0.008553   \n",
       "BILL_AMT3  0.023614  0.002364  0.359443  0.024206  0.010792  0.010190   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "PAY_6_4         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_5         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_6         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_7         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_8         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            PAY_5_5   PAY_5_6   PAY_5_7   PAY_5_8   PAY_6_0   PAY_6_2  \\\n",
       "LIMIT_BAL  0.016856  0.003295  0.037118  0.007036  0.095496  0.151656   \n",
       "AGE        0.004903  0.008894  0.002102  0.008338  0.050122  0.016765   \n",
       "BILL_AMT1  0.009829  0.007460  0.028479  0.004392  0.346920  0.001203   \n",
       "BILL_AMT2  0.008852  0.008487  0.027777  0.004354  0.358456  0.009738   \n",
       "BILL_AMT3  0.006956  0.013458  0.026952  0.004257  0.359092  0.021019   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "PAY_6_4         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_5         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_6         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_7         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "PAY_6_8         NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "            PAY_6_3   PAY_6_4   PAY_6_5   PAY_6_6   PAY_6_7   PAY_6_8  \n",
       "LIMIT_BAL  0.054569  0.035408  0.003483  0.013571  0.032157  0.007410  \n",
       "AGE        0.007937  0.000588  0.000729  0.004490  0.010661  0.003115  \n",
       "BILL_AMT1  0.014748  0.014988  0.001720  0.002434  0.027288  0.001764  \n",
       "BILL_AMT2  0.012181  0.013710  0.003008  0.000935  0.027058  0.000387  \n",
       "BILL_AMT3  0.009520  0.011905  0.006865  0.000427  0.026467  0.000180  \n",
       "...             ...       ...       ...       ...       ...       ...  \n",
       "PAY_6_4         NaN       NaN  0.000823  0.001026  0.001692  0.000388  \n",
       "PAY_6_5         NaN       NaN       NaN  0.000499  0.000823  0.000189  \n",
       "PAY_6_6         NaN       NaN       NaN       NaN  0.001026  0.000235  \n",
       "PAY_6_7         NaN       NaN       NaN       NaN       NaN  0.000388  \n",
       "PAY_6_8         NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[207 rows x 207 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = df.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BILL_AMT2',\n",
       " 'BILL_AMT3',\n",
       " 'BILL_AMT4',\n",
       " 'BILL_AMT5',\n",
       " 'BILL_AMT6',\n",
       " 'avg_bill',\n",
       " 'out1',\n",
       " 'out2',\n",
       " 'out3',\n",
       " 'out4',\n",
       " 'out5',\n",
       " 'out6',\n",
       " 'per2',\n",
       " 'per3',\n",
       " 'per5',\n",
       " 'per6',\n",
       " 'LIMIT_BAL^2',\n",
       " 'LIMIT_BAL AGE',\n",
       " 'LIMIT_BAL PAY_AMT1',\n",
       " 'LIMIT_BAL PAY_AMT2',\n",
       " 'LIMIT_BAL PAY_AMT4',\n",
       " 'LIMIT_BAL PAY_AMT5',\n",
       " 'LIMIT_BAL PAY_AMT6',\n",
       " 'LIMIT_BAL per1',\n",
       " 'LIMIT_BAL per2',\n",
       " 'LIMIT_BAL per3',\n",
       " 'LIMIT_BAL per4',\n",
       " 'LIMIT_BAL per5',\n",
       " 'LIMIT_BAL per6',\n",
       " 'AGE^2',\n",
       " 'AGE BILL_AMT1',\n",
       " 'AGE PAY_AMT1',\n",
       " 'AGE PAY_AMT2',\n",
       " 'AGE PAY_AMT3',\n",
       " 'AGE PAY_AMT4',\n",
       " 'AGE PAY_AMT5',\n",
       " 'AGE PAY_AMT6',\n",
       " 'AGE per1',\n",
       " 'AGE per2',\n",
       " 'AGE per3',\n",
       " 'AGE per4',\n",
       " 'AGE per5',\n",
       " 'AGE per6',\n",
       " 'BILL_AMT1^2',\n",
       " 'BILL_AMT1 per1',\n",
       " 'BILL_AMT1 per2',\n",
       " 'BILL_AMT1 per3',\n",
       " 'BILL_AMT1 per4',\n",
       " 'BILL_AMT1 per5',\n",
       " 'BILL_AMT1 per6',\n",
       " 'PAY_AMT1 PAY_AMT4',\n",
       " 'PAY_AMT1 per1',\n",
       " 'PAY_AMT1 per3',\n",
       " 'PAY_AMT1 per5',\n",
       " 'PAY_AMT1 per6',\n",
       " 'PAY_AMT2 PAY_AMT3',\n",
       " 'PAY_AMT2 PAY_AMT4',\n",
       " 'PAY_AMT2 per5',\n",
       " 'PAY_AMT3 PAY_AMT4',\n",
       " 'PAY_AMT3 per2',\n",
       " 'PAY_AMT3 per5',\n",
       " 'PAY_AMT3 per6',\n",
       " 'PAY_AMT4 per2',\n",
       " 'PAY_AMT4 per6',\n",
       " 'PAY_AMT5 per1',\n",
       " 'PAY_AMT5 per2',\n",
       " 'PAY_AMT6 per2',\n",
       " 'PAY_AMT6 per3',\n",
       " 'PAY_AMT6 per4',\n",
       " 'PAY_AMT6 per5',\n",
       " 'per1 per2',\n",
       " 'per1 per3',\n",
       " 'per1 per4',\n",
       " 'per1 per5',\n",
       " 'per2^2',\n",
       " 'per2 per3',\n",
       " 'per2 per4',\n",
       " 'per2 per5',\n",
       " 'per2 per6',\n",
       " 'per3 per4',\n",
       " 'per3 per5',\n",
       " 'per3 per6',\n",
       " 'per4^2',\n",
       " 'per4 per5',\n",
       " 'per4 per6',\n",
       " 'per5^2',\n",
       " 'per5 per6',\n",
       " 'per6^2',\n",
       " 'PAY_2_7',\n",
       " 'PAY_3_6',\n",
       " 'PAY_5_7']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = to_drop, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>AGE</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default</th>\n",
       "      <th>avg_pay</th>\n",
       "      <th>per1</th>\n",
       "      <th>per4</th>\n",
       "      <th>LIMIT_BAL BILL_AMT1</th>\n",
       "      <th>LIMIT_BAL PAY_AMT3</th>\n",
       "      <th>BILL_AMT1 PAY_AMT1</th>\n",
       "      <th>BILL_AMT1 PAY_AMT2</th>\n",
       "      <th>BILL_AMT1 PAY_AMT3</th>\n",
       "      <th>BILL_AMT1 PAY_AMT4</th>\n",
       "      <th>BILL_AMT1 PAY_AMT5</th>\n",
       "      <th>BILL_AMT1 PAY_AMT6</th>\n",
       "      <th>PAY_AMT1^2</th>\n",
       "      <th>PAY_AMT1 PAY_AMT2</th>\n",
       "      <th>PAY_AMT1 PAY_AMT3</th>\n",
       "      <th>PAY_AMT1 PAY_AMT5</th>\n",
       "      <th>PAY_AMT1 PAY_AMT6</th>\n",
       "      <th>PAY_AMT1 per2</th>\n",
       "      <th>PAY_AMT1 per4</th>\n",
       "      <th>PAY_AMT2^2</th>\n",
       "      <th>PAY_AMT2 PAY_AMT5</th>\n",
       "      <th>PAY_AMT2 PAY_AMT6</th>\n",
       "      <th>PAY_AMT2 per1</th>\n",
       "      <th>PAY_AMT2 per2</th>\n",
       "      <th>PAY_AMT2 per3</th>\n",
       "      <th>PAY_AMT2 per4</th>\n",
       "      <th>PAY_AMT2 per6</th>\n",
       "      <th>PAY_AMT3^2</th>\n",
       "      <th>PAY_AMT3 PAY_AMT5</th>\n",
       "      <th>PAY_AMT3 PAY_AMT6</th>\n",
       "      <th>PAY_AMT3 per1</th>\n",
       "      <th>PAY_AMT3 per3</th>\n",
       "      <th>PAY_AMT3 per4</th>\n",
       "      <th>PAY_AMT4^2</th>\n",
       "      <th>PAY_AMT4 PAY_AMT5</th>\n",
       "      <th>PAY_AMT4 PAY_AMT6</th>\n",
       "      <th>PAY_AMT4 per1</th>\n",
       "      <th>PAY_AMT4 per3</th>\n",
       "      <th>PAY_AMT4 per4</th>\n",
       "      <th>PAY_AMT4 per5</th>\n",
       "      <th>PAY_AMT5^2</th>\n",
       "      <th>PAY_AMT5 PAY_AMT6</th>\n",
       "      <th>PAY_AMT5 per3</th>\n",
       "      <th>PAY_AMT5 per4</th>\n",
       "      <th>PAY_AMT5 per5</th>\n",
       "      <th>PAY_AMT5 per6</th>\n",
       "      <th>PAY_AMT6^2</th>\n",
       "      <th>PAY_AMT6 per1</th>\n",
       "      <th>PAY_AMT6 per6</th>\n",
       "      <th>per1^2</th>\n",
       "      <th>per1 per6</th>\n",
       "      <th>per3^2</th>\n",
       "      <th>SEX_2</th>\n",
       "      <th>EDUCATION_2</th>\n",
       "      <th>EDUCATION_3</th>\n",
       "      <th>EDUCATION_4</th>\n",
       "      <th>MARRIAGE_2</th>\n",
       "      <th>MARRIAGE_3</th>\n",
       "      <th>PAY_1_0</th>\n",
       "      <th>PAY_1_1</th>\n",
       "      <th>PAY_1_2</th>\n",
       "      <th>PAY_1_3</th>\n",
       "      <th>PAY_1_4</th>\n",
       "      <th>PAY_1_5</th>\n",
       "      <th>PAY_1_6</th>\n",
       "      <th>PAY_1_7</th>\n",
       "      <th>PAY_1_8</th>\n",
       "      <th>PAY_2_0</th>\n",
       "      <th>PAY_2_1</th>\n",
       "      <th>PAY_2_2</th>\n",
       "      <th>PAY_2_3</th>\n",
       "      <th>PAY_2_4</th>\n",
       "      <th>PAY_2_5</th>\n",
       "      <th>PAY_2_6</th>\n",
       "      <th>PAY_2_8</th>\n",
       "      <th>PAY_3_0</th>\n",
       "      <th>PAY_3_1</th>\n",
       "      <th>PAY_3_2</th>\n",
       "      <th>PAY_3_3</th>\n",
       "      <th>PAY_3_4</th>\n",
       "      <th>PAY_3_5</th>\n",
       "      <th>PAY_3_7</th>\n",
       "      <th>PAY_3_8</th>\n",
       "      <th>PAY_4_0</th>\n",
       "      <th>PAY_4_1</th>\n",
       "      <th>PAY_4_2</th>\n",
       "      <th>PAY_4_3</th>\n",
       "      <th>PAY_4_4</th>\n",
       "      <th>PAY_4_5</th>\n",
       "      <th>PAY_4_6</th>\n",
       "      <th>PAY_4_7</th>\n",
       "      <th>PAY_4_8</th>\n",
       "      <th>PAY_5_0</th>\n",
       "      <th>PAY_5_2</th>\n",
       "      <th>PAY_5_3</th>\n",
       "      <th>PAY_5_4</th>\n",
       "      <th>PAY_5_5</th>\n",
       "      <th>PAY_5_6</th>\n",
       "      <th>PAY_5_8</th>\n",
       "      <th>PAY_6_0</th>\n",
       "      <th>PAY_6_2</th>\n",
       "      <th>PAY_6_3</th>\n",
       "      <th>PAY_6_4</th>\n",
       "      <th>PAY_6_5</th>\n",
       "      <th>PAY_6_6</th>\n",
       "      <th>PAY_6_7</th>\n",
       "      <th>PAY_6_8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000</td>\n",
       "      <td>24</td>\n",
       "      <td>3913</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>114.83</td>\n",
       "      <td>19.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.826000e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2696057.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>474721.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13476.84</td>\n",
       "      <td>10686.39</td>\n",
       "      <td>2370.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>382.5936</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.8336</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20000</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13007</td>\n",
       "      <td>1122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2354.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>169182049.0</td>\n",
       "      <td>14593854.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>845975.28</td>\n",
       "      <td>1258884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>72974.88</td>\n",
       "      <td>78046.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>20000</td>\n",
       "      <td>38</td>\n",
       "      <td>17973</td>\n",
       "      <td>1699</td>\n",
       "      <td>1460</td>\n",
       "      <td>626</td>\n",
       "      <td>1750</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>947.50</td>\n",
       "      <td>89.86</td>\n",
       "      <td>91.20</td>\n",
       "      <td>3.594600e+08</td>\n",
       "      <td>12520000.0</td>\n",
       "      <td>30536127.0</td>\n",
       "      <td>26240580.0</td>\n",
       "      <td>11251098.0</td>\n",
       "      <td>31452750.0</td>\n",
       "      <td>2695950.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2886601.0</td>\n",
       "      <td>2480540.0</td>\n",
       "      <td>1063574.0</td>\n",
       "      <td>254850.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164531.16</td>\n",
       "      <td>154948.8</td>\n",
       "      <td>2131600.0</td>\n",
       "      <td>219000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131195.60</td>\n",
       "      <td>141386.40</td>\n",
       "      <td>142788.00</td>\n",
       "      <td>133152.0</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>391876.0</td>\n",
       "      <td>93900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56252.36</td>\n",
       "      <td>61222.80</td>\n",
       "      <td>57091.20</td>\n",
       "      <td>3062500.0</td>\n",
       "      <td>262500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157255.00</td>\n",
       "      <td>171150.00</td>\n",
       "      <td>159600.00</td>\n",
       "      <td>156870.00</td>\n",
       "      <td>22500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14670.00</td>\n",
       "      <td>13680.00</td>\n",
       "      <td>13446.00</td>\n",
       "      <td>112.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8074.8196</td>\n",
       "      <td>67.395</td>\n",
       "      <td>9564.8400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>120000</td>\n",
       "      <td>25</td>\n",
       "      <td>113348</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>3158</td>\n",
       "      <td>3934</td>\n",
       "      <td>3802</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>2982.33</td>\n",
       "      <td>94.46</td>\n",
       "      <td>69.88</td>\n",
       "      <td>1.360176e+10</td>\n",
       "      <td>378960000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>566740000.0</td>\n",
       "      <td>357952984.0</td>\n",
       "      <td>445911032.0</td>\n",
       "      <td>430949096.0</td>\n",
       "      <td>226696000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25000000.0</td>\n",
       "      <td>19010000.0</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>472300.00</td>\n",
       "      <td>458850.00</td>\n",
       "      <td>465400.00</td>\n",
       "      <td>349400.0</td>\n",
       "      <td>370000.0</td>\n",
       "      <td>9972964.0</td>\n",
       "      <td>12006716.0</td>\n",
       "      <td>6316000.0</td>\n",
       "      <td>298304.68</td>\n",
       "      <td>293946.64</td>\n",
       "      <td>220681.04</td>\n",
       "      <td>15476356.0</td>\n",
       "      <td>14957068.0</td>\n",
       "      <td>7868000.0</td>\n",
       "      <td>371605.64</td>\n",
       "      <td>366176.72</td>\n",
       "      <td>274907.92</td>\n",
       "      <td>283366.02</td>\n",
       "      <td>14455204.0</td>\n",
       "      <td>7604000.0</td>\n",
       "      <td>353890.16</td>\n",
       "      <td>265683.76</td>\n",
       "      <td>273858.06</td>\n",
       "      <td>281348.00</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>188920.0</td>\n",
       "      <td>148000.0</td>\n",
       "      <td>8922.6916</td>\n",
       "      <td>6990.040</td>\n",
       "      <td>8663.8864</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>260000</td>\n",
       "      <td>40</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.500000e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9216</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL  AGE  BILL_AMT1  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  \\\n",
       "ID                                                                         \n",
       "1          20000   24       3913         0       689         0         0   \n",
       "10         20000   35          0         0         0         0     13007   \n",
       "100        20000   38      17973      1699      1460       626      1750   \n",
       "1000      120000   25     113348         0      5000      3158      3934   \n",
       "10001     260000   40       2500         0         0         0         0   \n",
       "\n",
       "       PAY_AMT5  PAY_AMT6  default  avg_pay   per1   per4  \\\n",
       "ID                                                          \n",
       "1             0         0        1   114.83  19.56   0.00   \n",
       "10         1122         0        0  2354.83   0.00   0.00   \n",
       "100         150         0        1   947.50  89.86  91.20   \n",
       "1000       3802      2000        0  2982.33  94.46  69.88   \n",
       "10001         0         0        0     0.00   0.96   0.00   \n",
       "\n",
       "       LIMIT_BAL BILL_AMT1  LIMIT_BAL PAY_AMT3  BILL_AMT1 PAY_AMT1  \\\n",
       "ID                                                                   \n",
       "1             7.826000e+07                 0.0                 0.0   \n",
       "10            0.000000e+00                 0.0                 0.0   \n",
       "100           3.594600e+08          12520000.0          30536127.0   \n",
       "1000          1.360176e+10         378960000.0                 0.0   \n",
       "10001         6.500000e+08                 0.0                 0.0   \n",
       "\n",
       "       BILL_AMT1 PAY_AMT2  BILL_AMT1 PAY_AMT3  BILL_AMT1 PAY_AMT4  \\\n",
       "ID                                                                  \n",
       "1               2696057.0                 0.0                 0.0   \n",
       "10                    0.0                 0.0                 0.0   \n",
       "100            26240580.0          11251098.0          31452750.0   \n",
       "1000          566740000.0         357952984.0         445911032.0   \n",
       "10001                 0.0                 0.0                 0.0   \n",
       "\n",
       "       BILL_AMT1 PAY_AMT5  BILL_AMT1 PAY_AMT6  PAY_AMT1^2  PAY_AMT1 PAY_AMT2  \\\n",
       "ID                                                                             \n",
       "1                     0.0                 0.0         0.0                0.0   \n",
       "10                    0.0                 0.0         0.0                0.0   \n",
       "100             2695950.0                 0.0   2886601.0          2480540.0   \n",
       "1000          430949096.0         226696000.0         0.0                0.0   \n",
       "10001                 0.0                 0.0         0.0                0.0   \n",
       "\n",
       "       PAY_AMT1 PAY_AMT3  PAY_AMT1 PAY_AMT5  PAY_AMT1 PAY_AMT6  PAY_AMT1 per2  \\\n",
       "ID                                                                              \n",
       "1                    0.0                0.0                0.0           0.00   \n",
       "10                   0.0                0.0                0.0           0.00   \n",
       "100            1063574.0           254850.0                0.0      164531.16   \n",
       "1000                 0.0                0.0                0.0           0.00   \n",
       "10001                0.0                0.0                0.0           0.00   \n",
       "\n",
       "       PAY_AMT1 per4  PAY_AMT2^2  PAY_AMT2 PAY_AMT5  PAY_AMT2 PAY_AMT6  \\\n",
       "ID                                                                       \n",
       "1                0.0    474721.0                0.0                0.0   \n",
       "10               0.0         0.0                0.0                0.0   \n",
       "100         154948.8   2131600.0           219000.0                0.0   \n",
       "1000             0.0  25000000.0         19010000.0         10000000.0   \n",
       "10001            0.0         0.0                0.0                0.0   \n",
       "\n",
       "       PAY_AMT2 per1  PAY_AMT2 per2  PAY_AMT2 per3  PAY_AMT2 per4  \\\n",
       "ID                                                                  \n",
       "1           13476.84       10686.39        2370.16            0.0   \n",
       "10              0.00           0.00           0.00            0.0   \n",
       "100        131195.60      141386.40      142788.00       133152.0   \n",
       "1000       472300.00      458850.00      465400.00       349400.0   \n",
       "10001           0.00           0.00           0.00            0.0   \n",
       "\n",
       "       PAY_AMT2 per6  PAY_AMT3^2  PAY_AMT3 PAY_AMT5  PAY_AMT3 PAY_AMT6  \\\n",
       "ID                                                                       \n",
       "1                0.0         0.0                0.0                0.0   \n",
       "10               0.0         0.0                0.0                0.0   \n",
       "100           1095.0    391876.0            93900.0                0.0   \n",
       "1000        370000.0   9972964.0         12006716.0          6316000.0   \n",
       "10001            0.0         0.0                0.0                0.0   \n",
       "\n",
       "       PAY_AMT3 per1  PAY_AMT3 per3  PAY_AMT3 per4   PAY_AMT4^2  \\\n",
       "ID                                                                \n",
       "1               0.00           0.00           0.00          0.0   \n",
       "10              0.00           0.00           0.00  169182049.0   \n",
       "100         56252.36       61222.80       57091.20    3062500.0   \n",
       "1000       298304.68      293946.64      220681.04   15476356.0   \n",
       "10001           0.00           0.00           0.00          0.0   \n",
       "\n",
       "       PAY_AMT4 PAY_AMT5  PAY_AMT4 PAY_AMT6  PAY_AMT4 per1  PAY_AMT4 per3  \\\n",
       "ID                                                                          \n",
       "1                    0.0                0.0           0.00           0.00   \n",
       "10            14593854.0                0.0           0.00           0.00   \n",
       "100             262500.0                0.0      157255.00      171150.00   \n",
       "1000          14957068.0          7868000.0      371605.64      366176.72   \n",
       "10001                0.0                0.0           0.00           0.00   \n",
       "\n",
       "       PAY_AMT4 per4  PAY_AMT4 per5  PAY_AMT5^2  PAY_AMT5 PAY_AMT6  \\\n",
       "ID                                                                   \n",
       "1               0.00           0.00         0.0                0.0   \n",
       "10              0.00      845975.28   1258884.0                0.0   \n",
       "100        159600.00      156870.00     22500.0                0.0   \n",
       "1000       274907.92      283366.02  14455204.0          7604000.0   \n",
       "10001           0.00           0.00         0.0                0.0   \n",
       "\n",
       "       PAY_AMT5 per3  PAY_AMT5 per4  PAY_AMT5 per5  PAY_AMT5 per6  PAY_AMT6^2  \\\n",
       "ID                                                                              \n",
       "1               0.00           0.00           0.00           0.00         0.0   \n",
       "10              0.00           0.00       72974.88       78046.32         0.0   \n",
       "100         14670.00       13680.00       13446.00         112.50         0.0   \n",
       "1000       353890.16      265683.76      273858.06      281348.00   4000000.0   \n",
       "10001           0.00           0.00           0.00           0.00         0.0   \n",
       "\n",
       "       PAY_AMT6 per1  PAY_AMT6 per6     per1^2  per1 per6     per3^2  SEX_2  \\\n",
       "ID                                                                            \n",
       "1                0.0            0.0   382.5936      0.000    11.8336      1   \n",
       "10               0.0            0.0     0.0000      0.000     0.0000      0   \n",
       "100              0.0            0.0  8074.8196     67.395  9564.8400      0   \n",
       "1000        188920.0       148000.0  8922.6916   6990.040  8663.8864      0   \n",
       "10001            0.0            0.0     0.9216      0.000     0.0000      1   \n",
       "\n",
       "       EDUCATION_2  EDUCATION_3  EDUCATION_4  MARRIAGE_2  MARRIAGE_3  PAY_1_0  \\\n",
       "ID                                                                              \n",
       "1                1            0            0           0           0        0   \n",
       "10               0            1            0           1           0        0   \n",
       "100              1            0            0           0           0        1   \n",
       "1000             1            0            0           1           0        0   \n",
       "10001            0            0            0           0           0        0   \n",
       "\n",
       "       PAY_1_1  PAY_1_2  PAY_1_3  PAY_1_4  PAY_1_5  PAY_1_6  PAY_1_7  PAY_1_8  \\\n",
       "ID                                                                              \n",
       "1            0        1        0        0        0        0        0        0   \n",
       "10           0        0        0        0        0        0        0        0   \n",
       "100          0        0        0        0        0        0        0        0   \n",
       "1000         0        1        0        0        0        0        0        0   \n",
       "10001        0        0        0        0        0        0        0        0   \n",
       "\n",
       "       PAY_2_0  PAY_2_1  PAY_2_2  PAY_2_3  PAY_2_4  PAY_2_5  PAY_2_6  PAY_2_8  \\\n",
       "ID                                                                              \n",
       "1            0        0        1        0        0        0        0        0   \n",
       "10           0        0        0        0        0        0        0        0   \n",
       "100          1        0        0        0        0        0        0        0   \n",
       "1000         0        0        1        0        0        0        0        0   \n",
       "10001        0        0        0        0        0        0        0        0   \n",
       "\n",
       "       PAY_3_0  PAY_3_1  PAY_3_2  PAY_3_3  PAY_3_4  PAY_3_5  PAY_3_7  PAY_3_8  \\\n",
       "ID                                                                              \n",
       "1            0        0        0        0        0        0        0        0   \n",
       "10           0        0        0        0        0        0        0        0   \n",
       "100          1        0        0        0        0        0        0        0   \n",
       "1000         1        0        0        0        0        0        0        0   \n",
       "10001        0        0        0        0        0        0        0        0   \n",
       "\n",
       "       PAY_4_0  PAY_4_1  PAY_4_2  PAY_4_3  PAY_4_4  PAY_4_5  PAY_4_6  PAY_4_7  \\\n",
       "ID                                                                              \n",
       "1            0        0        0        0        0        0        0        0   \n",
       "10           0        0        0        0        0        0        0        0   \n",
       "100          1        0        0        0        0        0        0        0   \n",
       "1000         1        0        0        0        0        0        0        0   \n",
       "10001        0        0        0        0        0        0        0        0   \n",
       "\n",
       "       PAY_4_8  PAY_5_0  PAY_5_2  PAY_5_3  PAY_5_4  PAY_5_5  PAY_5_6  PAY_5_8  \\\n",
       "ID                                                                              \n",
       "1            0        0        0        0        0        0        0        0   \n",
       "10           0        0        0        0        0        0        0        0   \n",
       "100          0        1        0        0        0        0        0        0   \n",
       "1000         0        1        0        0        0        0        0        0   \n",
       "10001        0        0        0        0        0        0        0        0   \n",
       "\n",
       "       PAY_6_0  PAY_6_2  PAY_6_3  PAY_6_4  PAY_6_5  PAY_6_6  PAY_6_7  PAY_6_8  \n",
       "ID                                                                             \n",
       "1            0        0        0        0        0        0        0        0  \n",
       "10           0        0        0        0        0        0        0        0  \n",
       "100          0        0        0        0        0        0        0        0  \n",
       "1000         1        0        0        0        0        0        0        0  \n",
       "10001        0        0        0        0        0        0        0        0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22499, 116)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['default']\n",
    "df_features = df.drop(columns = ['default'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LIMIT_BAL', 'AGE', 'BILL_AMT1', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3',\n",
       "       'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'avg_pay',\n",
       "       ...\n",
       "       'PAY_5_6', 'PAY_5_8', 'PAY_6_0', 'PAY_6_2', 'PAY_6_3', 'PAY_6_4',\n",
       "       'PAY_6_5', 'PAY_6_6', 'PAY_6_7', 'PAY_6_8'],\n",
       "      dtype='object', length=115)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIF Factor</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.600000e+00</td>\n",
       "      <td>LIMIT_BAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.300000e+00</td>\n",
       "      <td>AGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.550000e+01</td>\n",
       "      <td>BILL_AMT1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.114890e+12</td>\n",
       "      <td>PAY_AMT1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.409631e+12</td>\n",
       "      <td>PAY_AMT2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1.900000e+00</td>\n",
       "      <td>PAY_6_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1.500000e+00</td>\n",
       "      <td>PAY_6_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2.200000e+00</td>\n",
       "      <td>PAY_6_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1.150000e+01</td>\n",
       "      <td>PAY_6_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>3.200000e+00</td>\n",
       "      <td>PAY_6_8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       VIF Factor   features\n",
       "0    6.600000e+00  LIMIT_BAL\n",
       "1    9.300000e+00        AGE\n",
       "2    1.550000e+01  BILL_AMT1\n",
       "3    1.114890e+12   PAY_AMT1\n",
       "4    2.409631e+12   PAY_AMT2\n",
       "..            ...        ...\n",
       "110  1.900000e+00    PAY_6_4\n",
       "111  1.500000e+00    PAY_6_5\n",
       "112  2.200000e+00    PAY_6_6\n",
       "113  1.150000e+01    PAY_6_7\n",
       "114  3.200000e+00    PAY_6_8\n",
       "\n",
       "[115 rows x 2 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(df_features.values, i) for i in range(df_features.shape[1])]\n",
    "vif[\"features\"] = df_features.columns\n",
    "vif.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AGE', 'BILL_AMT1', 'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', 'avg_pay', 'per1', 'LIMIT_BAL BILL_AMT1', 'LIMIT_BAL PAY_AMT3', 'BILL_AMT1 PAY_AMT2', 'BILL_AMT1 PAY_AMT3', 'BILL_AMT1 PAY_AMT4', 'PAY_AMT1^2', 'PAY_AMT1 PAY_AMT2', 'PAY_AMT1 PAY_AMT3', 'PAY_AMT1 per2', 'PAY_AMT2^2', 'PAY_AMT2 PAY_AMT5', 'PAY_AMT2 per1', 'PAY_AMT2 per2', 'PAY_AMT2 per3', 'PAY_AMT2 per4', 'PAY_AMT2 per6', 'PAY_AMT3^2', 'PAY_AMT3 per1', 'PAY_AMT3 per4', 'PAY_AMT4^2', 'PAY_AMT4 per1', 'PAY_AMT4 per3', 'PAY_AMT4 per5', 'PAY_AMT5 per3', 'PAY_AMT5 per4', 'PAY_AMT5 per6', 'per3^2', 'PAY_4_7', 'PAY_6_7']\n"
     ]
    }
   ],
   "source": [
    "drop_vif =  list(vif[vif['VIF Factor'] > 9]['features'])\n",
    "print(drop_vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.drop( columns = drop_vif, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LIMIT_BAL', 'per4', 'BILL_AMT1 PAY_AMT1', 'BILL_AMT1 PAY_AMT5',\n",
       "       'BILL_AMT1 PAY_AMT6', 'PAY_AMT1 PAY_AMT5', 'PAY_AMT1 PAY_AMT6',\n",
       "       'PAY_AMT1 per4', 'PAY_AMT2 PAY_AMT6', 'PAY_AMT3 PAY_AMT5',\n",
       "       'PAY_AMT3 PAY_AMT6', 'PAY_AMT3 per3', 'PAY_AMT4 PAY_AMT5',\n",
       "       'PAY_AMT4 PAY_AMT6', 'PAY_AMT4 per4', 'PAY_AMT5^2', 'PAY_AMT5 PAY_AMT6',\n",
       "       'PAY_AMT5 per5', 'PAY_AMT6^2', 'PAY_AMT6 per1', 'PAY_AMT6 per6',\n",
       "       'per1^2', 'per1 per6', 'SEX_2', 'EDUCATION_2', 'EDUCATION_3',\n",
       "       'EDUCATION_4', 'MARRIAGE_2', 'MARRIAGE_3', 'PAY_1_0', 'PAY_1_1',\n",
       "       'PAY_1_2', 'PAY_1_3', 'PAY_1_4', 'PAY_1_5', 'PAY_1_6', 'PAY_1_7',\n",
       "       'PAY_1_8', 'PAY_2_0', 'PAY_2_1', 'PAY_2_2', 'PAY_2_3', 'PAY_2_4',\n",
       "       'PAY_2_5', 'PAY_2_6', 'PAY_2_8', 'PAY_3_0', 'PAY_3_1', 'PAY_3_2',\n",
       "       'PAY_3_3', 'PAY_3_4', 'PAY_3_5', 'PAY_3_7', 'PAY_3_8', 'PAY_4_0',\n",
       "       'PAY_4_1', 'PAY_4_2', 'PAY_4_3', 'PAY_4_4', 'PAY_4_5', 'PAY_4_6',\n",
       "       'PAY_4_8', 'PAY_5_0', 'PAY_5_2', 'PAY_5_3', 'PAY_5_4', 'PAY_5_5',\n",
       "       'PAY_5_6', 'PAY_5_8', 'PAY_6_0', 'PAY_6_2', 'PAY_6_3', 'PAY_6_4',\n",
       "       'PAY_6_5', 'PAY_6_6', 'PAY_6_8'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_features\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Fitting and Hyperparameter Tuning\n",
    "KNN, Logistic Regression, Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "scaler = StandardScaler() \n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=9)\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 9)\n",
    "print(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=9)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.8076444444444445\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:' + str(metrics.accuracy_score(y_test, y_pred_class)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4092,  296],\n",
       "       [ 786,  451]])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test,y_pred_class)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN F1: 0.45463709677419356\n"
     ]
    }
   ],
   "source": [
    "knn_f1 = metrics.f1_score(y_test, y_pred_class)\n",
    "print('KNN F1: ' + str(knn_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "results['KNN'] = knn_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8209777777777778\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4181  207]\n",
      " [ 800  437]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log F1: 0.46464646464646475\n"
     ]
    }
   ],
   "source": [
    "log_f1 = metrics.f1_score(y_test, y_pred_class)\n",
    "print('Log F1: ' + str(log_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Logistic Regression'] = log_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>per4</th>\n",
       "      <th>BILL_AMT1 PAY_AMT1</th>\n",
       "      <th>BILL_AMT1 PAY_AMT5</th>\n",
       "      <th>BILL_AMT1 PAY_AMT6</th>\n",
       "      <th>PAY_AMT1 PAY_AMT5</th>\n",
       "      <th>PAY_AMT1 PAY_AMT6</th>\n",
       "      <th>PAY_AMT1 per4</th>\n",
       "      <th>PAY_AMT2 PAY_AMT6</th>\n",
       "      <th>PAY_AMT3 PAY_AMT5</th>\n",
       "      <th>PAY_AMT3 PAY_AMT6</th>\n",
       "      <th>PAY_AMT3 per3</th>\n",
       "      <th>PAY_AMT4 PAY_AMT5</th>\n",
       "      <th>PAY_AMT4 PAY_AMT6</th>\n",
       "      <th>PAY_AMT4 per4</th>\n",
       "      <th>PAY_AMT5^2</th>\n",
       "      <th>PAY_AMT5 PAY_AMT6</th>\n",
       "      <th>PAY_AMT5 per5</th>\n",
       "      <th>PAY_AMT6^2</th>\n",
       "      <th>PAY_AMT6 per1</th>\n",
       "      <th>PAY_AMT6 per6</th>\n",
       "      <th>per1^2</th>\n",
       "      <th>per1 per6</th>\n",
       "      <th>SEX_2</th>\n",
       "      <th>EDUCATION_2</th>\n",
       "      <th>EDUCATION_3</th>\n",
       "      <th>EDUCATION_4</th>\n",
       "      <th>MARRIAGE_2</th>\n",
       "      <th>MARRIAGE_3</th>\n",
       "      <th>PAY_1_0</th>\n",
       "      <th>PAY_1_1</th>\n",
       "      <th>PAY_1_2</th>\n",
       "      <th>PAY_1_3</th>\n",
       "      <th>PAY_1_4</th>\n",
       "      <th>PAY_1_5</th>\n",
       "      <th>PAY_1_6</th>\n",
       "      <th>PAY_1_7</th>\n",
       "      <th>PAY_1_8</th>\n",
       "      <th>PAY_2_0</th>\n",
       "      <th>PAY_2_1</th>\n",
       "      <th>PAY_2_2</th>\n",
       "      <th>PAY_2_3</th>\n",
       "      <th>PAY_2_4</th>\n",
       "      <th>PAY_2_5</th>\n",
       "      <th>PAY_2_6</th>\n",
       "      <th>PAY_2_8</th>\n",
       "      <th>PAY_3_0</th>\n",
       "      <th>PAY_3_1</th>\n",
       "      <th>PAY_3_2</th>\n",
       "      <th>PAY_3_3</th>\n",
       "      <th>PAY_3_4</th>\n",
       "      <th>PAY_3_5</th>\n",
       "      <th>PAY_3_7</th>\n",
       "      <th>PAY_3_8</th>\n",
       "      <th>PAY_4_0</th>\n",
       "      <th>PAY_4_1</th>\n",
       "      <th>PAY_4_2</th>\n",
       "      <th>PAY_4_3</th>\n",
       "      <th>PAY_4_4</th>\n",
       "      <th>PAY_4_5</th>\n",
       "      <th>PAY_4_6</th>\n",
       "      <th>PAY_4_8</th>\n",
       "      <th>PAY_5_0</th>\n",
       "      <th>PAY_5_2</th>\n",
       "      <th>PAY_5_3</th>\n",
       "      <th>PAY_5_4</th>\n",
       "      <th>PAY_5_5</th>\n",
       "      <th>PAY_5_6</th>\n",
       "      <th>PAY_5_8</th>\n",
       "      <th>PAY_6_0</th>\n",
       "      <th>PAY_6_2</th>\n",
       "      <th>PAY_6_3</th>\n",
       "      <th>PAY_6_4</th>\n",
       "      <th>PAY_6_5</th>\n",
       "      <th>PAY_6_6</th>\n",
       "      <th>PAY_6_8</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5832</th>\n",
       "      <td>140000</td>\n",
       "      <td>71.66</td>\n",
       "      <td>523255000.0</td>\n",
       "      <td>418604000.0</td>\n",
       "      <td>3.770576e+08</td>\n",
       "      <td>20000000.0</td>\n",
       "      <td>18015000.0</td>\n",
       "      <td>358300.00</td>\n",
       "      <td>12970800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16000000.0</td>\n",
       "      <td>14412000.0</td>\n",
       "      <td>286640.00</td>\n",
       "      <td>16000000.0</td>\n",
       "      <td>14412000.0</td>\n",
       "      <td>293560.00</td>\n",
       "      <td>1.298161e+07</td>\n",
       "      <td>269324.25</td>\n",
       "      <td>266225.67</td>\n",
       "      <td>5587.5625</td>\n",
       "      <td>5523.2775</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28546</th>\n",
       "      <td>50000</td>\n",
       "      <td>32.24</td>\n",
       "      <td>50508000.0</td>\n",
       "      <td>50508000.0</td>\n",
       "      <td>2.520349e+07</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>1996000.0</td>\n",
       "      <td>64480.00</td>\n",
       "      <td>508980.0</td>\n",
       "      <td>32242000.0</td>\n",
       "      <td>16088758.0</td>\n",
       "      <td>16443.42</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>1996000.0</td>\n",
       "      <td>64480.00</td>\n",
       "      <td>4000000.0</td>\n",
       "      <td>1996000.0</td>\n",
       "      <td>70160.00</td>\n",
       "      <td>9.960040e+05</td>\n",
       "      <td>50408.98</td>\n",
       "      <td>38103.64</td>\n",
       "      <td>2551.2601</td>\n",
       "      <td>1928.4718</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11325</th>\n",
       "      <td>70000</td>\n",
       "      <td>12.63</td>\n",
       "      <td>55118400.0</td>\n",
       "      <td>34449000.0</td>\n",
       "      <td>5.167350e+07</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>2400000.0</td>\n",
       "      <td>20208.00</td>\n",
       "      <td>1950000.0</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>15220.00</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>12630.00</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>11620.00</td>\n",
       "      <td>2.250000e+06</td>\n",
       "      <td>73815.00</td>\n",
       "      <td>16140.00</td>\n",
       "      <td>2421.6241</td>\n",
       "      <td>529.4996</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17642</th>\n",
       "      <td>140000</td>\n",
       "      <td>80.04</td>\n",
       "      <td>551686698.0</td>\n",
       "      <td>514243056.0</td>\n",
       "      <td>5.239554e+08</td>\n",
       "      <td>17371608.0</td>\n",
       "      <td>17699700.0</td>\n",
       "      <td>345532.68</td>\n",
       "      <td>17174900.0</td>\n",
       "      <td>21773864.0</td>\n",
       "      <td>22185100.0</td>\n",
       "      <td>449870.54</td>\n",
       "      <td>15291200.0</td>\n",
       "      <td>15580000.0</td>\n",
       "      <td>304152.00</td>\n",
       "      <td>16192576.0</td>\n",
       "      <td>16498400.0</td>\n",
       "      <td>308600.56</td>\n",
       "      <td>1.681000e+07</td>\n",
       "      <td>374248.00</td>\n",
       "      <td>315577.00</td>\n",
       "      <td>8332.0384</td>\n",
       "      <td>7025.8216</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6631</th>\n",
       "      <td>120000</td>\n",
       "      <td>57.22</td>\n",
       "      <td>229465600.0</td>\n",
       "      <td>71708000.0</td>\n",
       "      <td>4.881450e+09</td>\n",
       "      <td>3200000.0</td>\n",
       "      <td>217836800.0</td>\n",
       "      <td>183104.00</td>\n",
       "      <td>204222000.0</td>\n",
       "      <td>3700000.0</td>\n",
       "      <td>251873800.0</td>\n",
       "      <td>206830.00</td>\n",
       "      <td>3500000.0</td>\n",
       "      <td>238259000.0</td>\n",
       "      <td>200270.00</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>68074000.0</td>\n",
       "      <td>57840.00</td>\n",
       "      <td>4.634069e+09</td>\n",
       "      <td>4068102.24</td>\n",
       "      <td>162016.12</td>\n",
       "      <td>3571.2576</td>\n",
       "      <td>142.2288</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23083</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.41</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-2.100000e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7500000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.250000e+06</td>\n",
       "      <td>-200.00</td>\n",
       "      <td>-925.00</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0296</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3756</th>\n",
       "      <td>260000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6765521.0</td>\n",
       "      <td>6632516.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>582169.0</td>\n",
       "      <td>570724.0</td>\n",
       "      <td>2601.83</td>\n",
       "      <td>5.595040e+05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>216.92</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16233</th>\n",
       "      <td>260000</td>\n",
       "      <td>6.49</td>\n",
       "      <td>430500000.0</td>\n",
       "      <td>299054000.0</td>\n",
       "      <td>3.596684e+08</td>\n",
       "      <td>156300000.0</td>\n",
       "      <td>187980000.0</td>\n",
       "      <td>97350.00</td>\n",
       "      <td>125320000.0</td>\n",
       "      <td>31260000.0</td>\n",
       "      <td>37596000.0</td>\n",
       "      <td>33000.00</td>\n",
       "      <td>132469460.0</td>\n",
       "      <td>159319316.0</td>\n",
       "      <td>82507.37</td>\n",
       "      <td>108576400.0</td>\n",
       "      <td>130583440.0</td>\n",
       "      <td>50953.80</td>\n",
       "      <td>1.570510e+08</td>\n",
       "      <td>138353.28</td>\n",
       "      <td>50253.32</td>\n",
       "      <td>121.8816</td>\n",
       "      <td>44.2704</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24562</th>\n",
       "      <td>70000</td>\n",
       "      <td>55.03</td>\n",
       "      <td>290077376.0</td>\n",
       "      <td>511484200.0</td>\n",
       "      <td>1.295422e+08</td>\n",
       "      <td>14463200.0</td>\n",
       "      <td>3663056.0</td>\n",
       "      <td>157605.92</td>\n",
       "      <td>3198779.0</td>\n",
       "      <td>7155850.0</td>\n",
       "      <td>1812343.0</td>\n",
       "      <td>135493.54</td>\n",
       "      <td>7575000.0</td>\n",
       "      <td>1918500.0</td>\n",
       "      <td>82545.00</td>\n",
       "      <td>25502500.0</td>\n",
       "      <td>6458950.0</td>\n",
       "      <td>246339.00</td>\n",
       "      <td>1.635841e+06</td>\n",
       "      <td>185058.51</td>\n",
       "      <td>70933.34</td>\n",
       "      <td>20935.1961</td>\n",
       "      <td>8024.5074</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10273</th>\n",
       "      <td>210000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16874 rows  77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LIMIT_BAL   per4  BILL_AMT1 PAY_AMT1  BILL_AMT1 PAY_AMT5  \\\n",
       "ID                                                                \n",
       "5832      140000  71.66         523255000.0         418604000.0   \n",
       "28546      50000  32.24          50508000.0          50508000.0   \n",
       "11325      70000  12.63          55118400.0          34449000.0   \n",
       "17642     140000  80.04         551686698.0         514243056.0   \n",
       "6631      120000  57.22         229465600.0          71708000.0   \n",
       "...          ...    ...                 ...                 ...   \n",
       "23083     100000   0.41                -0.0                -0.0   \n",
       "3756      260000   0.00                 0.0                 0.0   \n",
       "16233     260000   6.49         430500000.0         299054000.0   \n",
       "24562      70000  55.03         290077376.0         511484200.0   \n",
       "10273     210000   0.00                 0.0                 0.0   \n",
       "\n",
       "       BILL_AMT1 PAY_AMT6  PAY_AMT1 PAY_AMT5  PAY_AMT1 PAY_AMT6  \\\n",
       "ID                                                                \n",
       "5832         3.770576e+08         20000000.0         18015000.0   \n",
       "28546        2.520349e+07          4000000.0          1996000.0   \n",
       "11325        5.167350e+07          1600000.0          2400000.0   \n",
       "17642        5.239554e+08         17371608.0         17699700.0   \n",
       "6631         4.881450e+09          3200000.0        217836800.0   \n",
       "...                   ...                ...                ...   \n",
       "23083       -2.100000e+05                0.0                0.0   \n",
       "3756         0.000000e+00                0.0                0.0   \n",
       "16233        3.596684e+08        156300000.0        187980000.0   \n",
       "24562        1.295422e+08         14463200.0          3663056.0   \n",
       "10273        0.000000e+00                0.0                0.0   \n",
       "\n",
       "       PAY_AMT1 per4  PAY_AMT2 PAY_AMT6  PAY_AMT3 PAY_AMT5  PAY_AMT3 PAY_AMT6  \\\n",
       "ID                                                                              \n",
       "5832       358300.00         12970800.0                0.0                0.0   \n",
       "28546       64480.00           508980.0         32242000.0         16088758.0   \n",
       "11325       20208.00          1950000.0           500000.0           750000.0   \n",
       "17642      345532.68         17174900.0         21773864.0         22185100.0   \n",
       "6631       183104.00        204222000.0          3700000.0        251873800.0   \n",
       "...              ...                ...                ...                ...   \n",
       "23083           0.00          7500000.0                0.0                0.0   \n",
       "3756            0.00                0.0                0.0                0.0   \n",
       "16233       97350.00        125320000.0         31260000.0         37596000.0   \n",
       "24562      157605.92          3198779.0          7155850.0          1812343.0   \n",
       "10273           0.00                0.0                0.0                0.0   \n",
       "\n",
       "       PAY_AMT3 per3  PAY_AMT4 PAY_AMT5  PAY_AMT4 PAY_AMT6  PAY_AMT4 per4  \\\n",
       "ID                                                                          \n",
       "5832            0.00         16000000.0         14412000.0      286640.00   \n",
       "28546       16443.42          4000000.0          1996000.0       64480.00   \n",
       "11325       15220.00          1000000.0          1500000.0       12630.00   \n",
       "17642      449870.54         15291200.0         15580000.0      304152.00   \n",
       "6631       206830.00          3500000.0        238259000.0      200270.00   \n",
       "...              ...                ...                ...            ...   \n",
       "23083           0.00                0.0                0.0           0.00   \n",
       "3756            0.00          6765521.0          6632516.0           0.00   \n",
       "16233       33000.00        132469460.0        159319316.0       82507.37   \n",
       "24562      135493.54          7575000.0          1918500.0       82545.00   \n",
       "10273           0.00                0.0                0.0           0.00   \n",
       "\n",
       "        PAY_AMT5^2  PAY_AMT5 PAY_AMT6  PAY_AMT5 per5    PAY_AMT6^2  \\\n",
       "ID                                                                   \n",
       "5832    16000000.0         14412000.0      293560.00  1.298161e+07   \n",
       "28546    4000000.0          1996000.0       70160.00  9.960040e+05   \n",
       "11325    1000000.0          1500000.0       11620.00  2.250000e+06   \n",
       "17642   16192576.0         16498400.0      308600.56  1.681000e+07   \n",
       "6631     1000000.0         68074000.0       57840.00  4.634069e+09   \n",
       "...            ...                ...            ...           ...   \n",
       "23083          0.0                0.0           0.00  6.250000e+06   \n",
       "3756      582169.0           570724.0        2601.83  5.595040e+05   \n",
       "16233  108576400.0        130583440.0       50953.80  1.570510e+08   \n",
       "24562   25502500.0          6458950.0      246339.00  1.635841e+06   \n",
       "10273          0.0                0.0           0.00  0.000000e+00   \n",
       "\n",
       "       PAY_AMT6 per1  PAY_AMT6 per6      per1^2  per1 per6  SEX_2  \\\n",
       "ID                                                                  \n",
       "5832       269324.25      266225.67   5587.5625  5523.2775      0   \n",
       "28546       50408.98       38103.64   2551.2601  1928.4718      1   \n",
       "11325       73815.00       16140.00   2421.6241   529.4996      0   \n",
       "17642      374248.00      315577.00   8332.0384  7025.8216      1   \n",
       "6631      4068102.24      162016.12   3571.2576   142.2288      1   \n",
       "...              ...            ...         ...        ...    ...   \n",
       "23083        -200.00        -925.00      0.0064     0.0296      1   \n",
       "3756            0.00         216.92      0.0000     0.0000      0   \n",
       "16233      138353.28       50253.32    121.8816    44.2704      1   \n",
       "24562      185058.51       70933.34  20935.1961  8024.5074      0   \n",
       "10273           0.00           0.00      0.0000     0.0000      1   \n",
       "\n",
       "       EDUCATION_2  EDUCATION_3  EDUCATION_4  MARRIAGE_2  MARRIAGE_3  PAY_1_0  \\\n",
       "ID                                                                              \n",
       "5832             0            0            0           0           0        0   \n",
       "28546            1            0            0           1           0        1   \n",
       "11325            1            0            0           1           0        1   \n",
       "17642            1            0            0           0           0        1   \n",
       "6631             1            0            0           1           0        1   \n",
       "...            ...          ...          ...         ...         ...      ...   \n",
       "23083            0            0            0           0           0        0   \n",
       "3756             0            0            0           1           0        0   \n",
       "16233            1            0            0           0           0        1   \n",
       "24562            1            0            0           1           0        1   \n",
       "10273            0            0            0           1           0        0   \n",
       "\n",
       "       PAY_1_1  PAY_1_2  PAY_1_3  PAY_1_4  PAY_1_5  PAY_1_6  PAY_1_7  PAY_1_8  \\\n",
       "ID                                                                              \n",
       "5832         0        1        0        0        0        0        0        0   \n",
       "28546        0        0        0        0        0        0        0        0   \n",
       "11325        0        0        0        0        0        0        0        0   \n",
       "17642        0        0        0        0        0        0        0        0   \n",
       "6631         0        0        0        0        0        0        0        0   \n",
       "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "23083        1        0        0        0        0        0        0        0   \n",
       "3756         0        0        0        0        0        0        0        0   \n",
       "16233        0        0        0        0        0        0        0        0   \n",
       "24562        0        0        0        0        0        0        0        0   \n",
       "10273        1        0        0        0        0        0        0        0   \n",
       "\n",
       "       PAY_2_0  PAY_2_1  PAY_2_2  PAY_2_3  PAY_2_4  PAY_2_5  PAY_2_6  PAY_2_8  \\\n",
       "ID                                                                              \n",
       "5832         0        0        1        0        0        0        0        0   \n",
       "28546        1        0        0        0        0        0        0        0   \n",
       "11325        1        0        0        0        0        0        0        0   \n",
       "17642        1        0        0        0        0        0        0        0   \n",
       "6631         1        0        0        0        0        0        0        0   \n",
       "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "23083        0        0        0        0        0        0        0        0   \n",
       "3756         0        0        0        0        0        0        0        0   \n",
       "16233        1        0        0        0        0        0        0        0   \n",
       "24562        1        0        0        0        0        0        0        0   \n",
       "10273        0        0        0        0        0        0        0        0   \n",
       "\n",
       "       PAY_3_0  PAY_3_1  PAY_3_2  PAY_3_3  PAY_3_4  PAY_3_5  PAY_3_7  PAY_3_8  \\\n",
       "ID                                                                              \n",
       "5832         0        0        1        0        0        0        0        0   \n",
       "28546        0        0        0        0        0        0        0        0   \n",
       "11325        1        0        0        0        0        0        0        0   \n",
       "17642        1        0        0        0        0        0        0        0   \n",
       "6631         1        0        0        0        0        0        0        0   \n",
       "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "23083        0        0        0        0        0        0        0        0   \n",
       "3756         0        0        0        0        0        0        0        0   \n",
       "16233        1        0        0        0        0        0        0        0   \n",
       "24562        1        0        0        0        0        0        0        0   \n",
       "10273        0        0        0        0        0        0        0        0   \n",
       "\n",
       "       PAY_4_0  PAY_4_1  PAY_4_2  PAY_4_3  PAY_4_4  PAY_4_5  PAY_4_6  PAY_4_8  \\\n",
       "ID                                                                              \n",
       "5832         0        0        1        0        0        0        0        0   \n",
       "28546        0        0        0        0        0        0        0        0   \n",
       "11325        1        0        0        0        0        0        0        0   \n",
       "17642        1        0        0        0        0        0        0        0   \n",
       "6631         1        0        0        0        0        0        0        0   \n",
       "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "23083        0        0        1        0        0        0        0        0   \n",
       "3756         0        0        0        0        0        0        0        0   \n",
       "16233        1        0        0        0        0        0        0        0   \n",
       "24562        1        0        0        0        0        0        0        0   \n",
       "10273        0        0        0        0        0        0        0        0   \n",
       "\n",
       "       PAY_5_0  PAY_5_2  PAY_5_3  PAY_5_4  PAY_5_5  PAY_5_6  PAY_5_8  PAY_6_0  \\\n",
       "ID                                                                              \n",
       "5832         1        0        0        0        0        0        0        1   \n",
       "28546        1        0        0        0        0        0        0        1   \n",
       "11325        1        0        0        0        0        0        0        1   \n",
       "17642        1        0        0        0        0        0        0        1   \n",
       "6631         1        0        0        0        0        0        0        1   \n",
       "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "23083        0        1        0        0        0        0        0        0   \n",
       "3756         0        0        0        0        0        0        0        0   \n",
       "16233        0        0        0        0        0        0        0        0   \n",
       "24562        1        0        0        0        0        0        0        1   \n",
       "10273        0        0        0        0        0        0        0        0   \n",
       "\n",
       "       PAY_6_2  PAY_6_3  PAY_6_4  PAY_6_5  PAY_6_6  PAY_6_8  default  \n",
       "ID                                                                    \n",
       "5832         0        0        0        0        0        0        1  \n",
       "28546        0        0        0        0        0        0        0  \n",
       "11325        0        0        0        0        0        0        1  \n",
       "17642        0        0        0        0        0        0        0  \n",
       "6631         0        0        0        0        0        0        0  \n",
       "...        ...      ...      ...      ...      ...      ...      ...  \n",
       "23083        1        0        0        0        0        0        1  \n",
       "3756         0        0        0        0        0        0        0  \n",
       "16233        0        0        0        0        0        0        0  \n",
       "24562        0        0        0        0        0        0        0  \n",
       "10273        0        0        0        0        0        0        0  \n",
       "\n",
       "[16874 rows x 77 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepping data for imbalance handling\n",
    "training  = pd.concat([X_train, y_train], axis=1)\n",
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate minority and majority classes\n",
    "default = training[training.default == 1]\n",
    "not_default = training[training.default == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default count: 3791\n",
      "not_default count: 13083\n"
     ]
    }
   ],
   "source": [
    "print('default count: '+ str(len(default)))\n",
    "print('not_default count: '+ str(len(not_default)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_upsampled = resample(default,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(not_default), # match number in majority class\n",
    "                          random_state=23) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13083, 77)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_upsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled = pd.concat([not_default, default_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    13083\n",
       "0    13083\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsampled.default.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26166"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score:  0.6933333333333334\n",
      "upsample F1 score:  0.33882713683403604\n"
     ]
    }
   ],
   "source": [
    "# trying logistic regression again with the balanced dataset\n",
    "y_train = upsampled.default\n",
    "X_train = upsampled.drop('default', axis=1)\n",
    "\n",
    "# upsampled_dt = DecisionTreeClassifier(max_depth=5)\n",
    "upsampled_lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "\n",
    "# upsampled_dt.fit(X_train, y_train)\n",
    "upsampled_lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# upsampled_pred = upsampled_dt.predict(X_test)\n",
    "upsampled_pred = upsampled_lr.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# checking accuracy\n",
    "print('Test Accuracy score: ', metrics.accuracy_score(y_test, upsampled_pred))\n",
    "\n",
    "\n",
    "# checking accuracy\n",
    "upsample_f1 =  metrics.f1_score(y_test, upsampled_pred)\n",
    "print('upsample F1 score: ', metrics.f1_score(y_test, upsampled_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Logistic Upsampled'] = upsample_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_downsampled = resample(not_default,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = len(default), # match minority n\n",
    "                                random_state = 23) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3791, 77)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_downsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled = pd.concat([default, default_downsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3791\n",
       "0    3791\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsampled.default.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7582"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(downsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score:  0.7050666666666666\n",
      "downsample F1 score:  0.30498533724340177\n"
     ]
    }
   ],
   "source": [
    "# trying logistic regression again with the balanced dataset\n",
    "y_train = downsampled.default\n",
    "X_train = downsampled.drop('default', axis=1)\n",
    "\n",
    "# upsampled_dt = DecisionTreeClassifier(max_depth=5)\n",
    "downsampled_lr = LogisticRegression(solver='liblinear')\n",
    "\n",
    "\n",
    "# upsampled_dt.fit(X_train, y_train)\n",
    "downsampled_lr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# upsampled_pred = upsampled_dt.predict(X_test)\n",
    "downsampled_pred = downsampled_lr.predict(X_test)\n",
    "\n",
    "\n",
    "# checking accuracy\n",
    "print('Test Accuracy score: ', metrics.accuracy_score(y_test, downsampled_pred))\n",
    "\n",
    "\n",
    "# checking accuracy\n",
    "downsample_f1 =  metrics.f1_score(y_test, downsampled_pred)\n",
    "print('downsample F1 score: ', metrics.f1_score(y_test, downsampled_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Logistic Downsampled'] = downsample_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Class weight balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=23 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score:  0.7130666666666666\n",
      "Test F1 score:  0.2807486631016043\n"
     ]
    }
   ],
   "source": [
    "lr_clf_weighted = LogisticRegression(solver='liblinear', class_weight='balanced')\n",
    "\n",
    "lr_clf_weighted.fit(X_train, y_train)\n",
    "\n",
    "y_weighted_test = lr_clf_weighted.predict(X_test)\n",
    "\n",
    "\n",
    "# checking accuracy\n",
    "print('Test Accuracy score: ', metrics.accuracy_score(y_test, y_weighted_test))\n",
    "\n",
    "\n",
    "# checking accuracy\n",
    "cwb = metrics.f1_score(y_test, y_weighted_test)\n",
    "print('Test F1 score: ', cwb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Logistic class weight'] = cwb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNN': 0.4396344396344396,\n",
       " 'Logistic Regression': 0.46464646464646475,\n",
       " 'Logistic Upsampled': 0.33882713683403604,\n",
       " 'Logistic Downsampled': 0.30498533724340177,\n",
       " 'Logistic class weight': 0.2807486631016043,\n",
       " 'Decision Tree': 0.4069767441860465,\n",
       " 'Decision Tree with Grid Search': 0.5138601572196939,\n",
       " 'Random Forest': 0.3108433734939759,\n",
       " 'Random Forest with Grid search': 0.5247964470762398}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score: 0.9905838041431262\n",
      "Testing F1 Score: 0.4069767441860465\n"
     ]
    }
   ],
   "source": [
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#predict the training set\n",
    "y_pred_train = clf.predict(X_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred_test = clf.predict(X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Training F1 Score:\",metrics.f1_score(y_train, y_pred_train))\n",
    "df1 = metrics.f1_score(y_test, y_pred_test)\n",
    "print(\"Testing F1 Score:\",df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Decision Tree'] = df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree with Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = DecisionTreeClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'criterion': ['gini', 'entropy'],\n",
    "            'max_depth': range(1,10,2),\n",
    "             'class_weight':['balanced', 'None']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tree = GridSearchCV(dc, parameters, cv=10, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n",
      "/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\", line 200, in fit\n",
      "    self.class_weight, y_original)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\", line 72, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/singh/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/class_weight.py\", line 123, in compute_sample_weight\n",
      "    '\"balanced\". Given \"%s\".' % class_weight)\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeClassifier(random_state=1),\n",
       "             param_grid={'class_weight': ['balanced', 'None'],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': range(1, 10, 2)},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5213900956647717\n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5}\n",
      "DecisionTreeClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=5, random_state=1)\n"
     ]
    }
   ],
   "source": [
    "print(grid_tree.best_score_)\n",
    "print(grid_tree.best_params_)\n",
    "print(grid_tree.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7911111111111111\n",
      "F1: 0.5138601572196939\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_tree.best_estimator_.predict(X_test)\n",
    "dcg = metrics.f1_score(y_test, y_pred)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"F1:\",dcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Decision Tree with Grid Search'] = dcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNN': 0.4396344396344396,\n",
       " 'Logistic Regression': 0.46464646464646475,\n",
       " 'Logistic Upsampled': 0.33882713683403604,\n",
       " 'Logistic Downsampled': 0.30498533724340177,\n",
       " 'Logistic class weight': 0.2807486631016043,\n",
       " 'Decision Tree': 0.4069767441860465,\n",
       " 'Decision Tree with Grid Search': 0.5138601572196939}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=23 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state = 1, n_estimators = 1000, max_depth=4, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=4, n_estimators=1000, n_jobs=-1,\n",
       "                       random_state=1)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 score:  0.3108433734939759\n"
     ]
    }
   ],
   "source": [
    "rfc_preds = rfc.predict(X_test)\n",
    "rfc_f1 = metrics.f1_score(y_test, rfc_preds)\n",
    "print('Test F1 score: ', rfc_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Random Forest'] = rfc_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { \n",
    "    'n_estimators': [500,1000],\n",
    "    'max_depth': [2,5,7],\n",
    "    'max_features': [0.6, 0.7, 0.8],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "     'class_weight': [None, 'balanced']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 54.4min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 109.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'class_weight': [None, 'balanced'],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [2, 5, 7],\n",
       "                         'max_features': [0.6, 0.7, 0.8],\n",
       "                         'n_estimators': [500, 1000]},\n",
       "             scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "grid_tree = GridSearchCV(rf, params, cv=5, scoring='f1', n_jobs =-1, verbose = 1)\n",
    "grid_tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5369076012401257\n",
      "{'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 5, 'max_features': 0.6, 'n_estimators': 1000}\n",
      "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
      "                       max_depth=5, max_features=0.6, n_estimators=1000)\n"
     ]
    }
   ],
   "source": [
    "print(grid_tree.best_score_)\n",
    "\n",
    "print(grid_tree.best_params_)\n",
    "\n",
    "print(grid_tree.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7717333333333334\n",
      "F1: 0.5247964470762398\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_tree.best_estimator_.predict(X_test)\n",
    "\n",
    "# checking accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"F1:\",metrics.f1_score(y_test, y_pred))\n",
    "rgs = metrics.f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Random Forest with Grid search'] = rgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNN': 0.4396344396344396,\n",
       " 'Logistic Regression': 0.46464646464646475,\n",
       " 'Logistic Upsampled': 0.33882713683403604,\n",
       " 'Logistic Downsampled': 0.30498533724340177,\n",
       " 'Logistic class weight': 0.2807486631016043,\n",
       " 'Decision Tree': 0.4069767441860465,\n",
       " 'Decision Tree with Grid Search': 0.5138601572196939,\n",
       " 'Random Forest': 0.3108433734939759,\n",
       " 'Random Forest with Grid search': 0.5247964470762398}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Classifier with LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   43.9s remaining:   43.9s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   44.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=LogisticRegression(), max_features=0.6,\n",
       "                  max_samples=0.8, n_estimators=500, n_jobs=-1, oob_score=True,\n",
       "                  verbose=1)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_lr = BaggingClassifier(\n",
    "            base_estimator=LogisticRegression(), \n",
    "            n_estimators= 500,\n",
    "            max_samples= 0.80,\n",
    "            max_features= 0.6,\n",
    "            oob_score= True,verbose = 1, n_jobs = -1 )\n",
    "bc_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7778831338153372"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_lr.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0015564202334630351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "bc_lr_preds = bc_lr.predict(X_test)\n",
    "\n",
    "bc_lr_f1 = metrics.f1_score(y_test, bc_lr_preds)\n",
    "\n",
    "print(bc_lr_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "#scaler = StandardScaler() \n",
    "#scaler.fit(X_train)\n",
    "#X_train = scaler.transform(X_train)  \n",
    "#X_test = scaler.transform(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bc_lr = BaggingClassifier(\n",
    "#            base_estimator = KNeighborsClassifier(n_neighbors=5), \n",
    "#            n_estimators= 100,\n",
    "#            max_samples= 0.6,\n",
    "#            max_features= 0.5,\n",
    "#            oob_score= True,verbose = 1, n_jobs = -1 )\n",
    "#bc_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bc_lr.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bc_lr_preds = bc_lr.predict(X_test)\n",
    "\n",
    "#bc_lr_f1 = metrics.f1_score(y_test, bc_lr_preds)\n",
    "\n",
    "#print(bc_lr_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running voting classifier on best three models so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45463709677419356\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_preds = knn.predict(X_test)\n",
    "knn_f1 = metrics.f1_score(y_test, knn_preds)\n",
    "print(knn_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score: 0.5313457787684592\n",
      "Testing F1 Score: 0.5327062847370672\n"
     ]
    }
   ],
   "source": [
    "dst = DecisionTreeClassifier(class_weight='balanced', criterion='entropy', max_depth=5, random_state=1)\n",
    "dst.fit(X_train,y_train)\n",
    "y_pred_train = dst.predict(X_train)\n",
    "y_pred_test = dst.predict(X_test)\n",
    "print(\"Training F1 Score:\",metrics.f1_score(y_train, y_pred_train))\n",
    "df1 = metrics.f1_score(y_test, y_pred_test)\n",
    "print(\"Testing F1 Score:\",df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   29.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   37.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score: 0.54925\n",
      "Testing F1 Score: 0.5389312977099237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced', criterion='entropy', max_depth=5, max_features=0.6, n_estimators=1000, verbose = 1, n_jobs = -1)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred_train = rf.predict(X_train)\n",
    "y_pred_test = rf.predict(X_test)\n",
    "print(\"Training F1 Score:\",metrics.f1_score(y_train, y_pred_train))\n",
    "rf1 = metrics.f1_score(y_test, y_pred_test)\n",
    "print(\"Testing F1 Score:\",rf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   32.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5337895637296834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "                estimators=[('Decision Tree', dst), ('knneighbors', knn), ('Random Forest', rf)], \n",
    "                voting='hard')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "vc_preds = voting_clf.predict(X_test)\n",
    "\n",
    "vc_f1 = metrics.f1_score(y_test, vc_preds)\n",
    "\n",
    "print(vc_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Voting Classifier'] = vc_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNN': 0.45463709677419356,\n",
       " 'Voting Classifier': 0.5337895637296834,\n",
       " 'Random Forest': 0.3108433734939759,\n",
       " 'Decision Tree with Grid Search': 0.5138601572196939,\n",
       " 'Decision Tree': 0.5327062847370672,\n",
       " 'Logistic class weight': 0.2807486631016043,\n",
       " 'Logistic Downsampled': 0.30498533724340177,\n",
       " 'Logistic Upsampled': 0.33882713683403604,\n",
       " 'Logistic Regression': 0.46464646464646475}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   38.9s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    0.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score: 0.5458836858006042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(class_weight='balanced', criterion='entropy', max_depth=5, max_features=0.6, n_estimators=1000, verbose = 1, n_jobs = -1)\n",
    "rf.fit(X, y)\n",
    "y_pred_train = rf.predict(X)\n",
    "#y_pred_test = rf.predict(X_test)\n",
    "print(\"Training F1 Score:\",metrics.f1_score(y, y_pred_train))\n",
    "#rf1 = metrics.f1_score(y_test, y_pred_test)\n",
    "#print(\"Testing F1 Score:\",rf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
